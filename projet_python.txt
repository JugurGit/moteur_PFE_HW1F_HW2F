### FILE: export_python.py
import os

ROOT = os.path.dirname(os.path.abspath(__file__))
OUTPUT = os.path.join(ROOT, "projet_python.txt")

EXCLUDE_DIRS = {".git", "venv", "__pycache__"}

with open(OUTPUT, "w", encoding="utf-8") as out:
    for dirpath, dirnames, filenames in os.walk(ROOT):
        # enlever les dossiers à exclure
        dirnames[:] = [d for d in dirnames if d not in EXCLUDE_DIRS]

        for filename in filenames:
            if not filename.endswith((".py", ".ipynb")):
                continue

            full_path = os.path.join(dirpath, filename)
            rel_path = os.path.relpath(full_path, ROOT)

            out.write(f"### FILE: {rel_path}\n")
            try:
                with open(full_path, "r", encoding="utf-8") as f:
                    out.write(f.read())
            except UnicodeDecodeError:
                out.write("[UNICODE ERROR: impossible de lire ce fichier]\n")

            out.write("\n\n")

print(f"Export terminé dans {OUTPUT}")


### FILE: test2 copy.ipynb
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "notebook_workflows_simple.py\n",
    "\n",
    "Version \"notebook-like\" (linéaire, très simple) :\n",
    "1) HW 1F : load -> curve -> pricer -> calibrate -> compare plots -> PFE plot\n",
    "2) HW 2F : load -> curve -> pricer -> calibrate -> compare plots -> PFE plot\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Lecture des fichiers Excel (courbe + template swaptions)\n",
    "from ir.market.loaders_excel import load_curve_xlsx, load_swaption_template_xlsx\n",
    "\n",
    "# Fonctions de plots \"notebook-friendly\" (affichage direct)\n",
    "from ir.market.plots import plot_curve, plot_prices_by_tenor, plot_vols_by_tenor\n",
    "\n",
    "# Outil pour impliciter une vol normale (Bachelier) à partir d'un prix (forward premium)\n",
    "from ir.calibration.vol import black_normal_vol\n",
    "\n",
    "# HW1F : pricer + calibrateur (a, sigma)\n",
    "from ir.pricers.hw1f_pricer import HullWhitePricer\n",
    "from ir.calibration.hw1f_calibration import HullWhiteCalibrator\n",
    "\n",
    "# HW2F : pricer + calibrateur \"profile\" (outer: a,b,rho ; inner: sigma,eta)\n",
    "from ir.pricers.hw2f_pricer import HullWhite2FPricer\n",
    "from ir.calibration.hw2f_profile import HullWhite2FProfileCalibrator\n",
    "\n",
    "# PFE : simulateur 2F et moteur d'exposition swap\n",
    "from ir.risk.hw2f_sim import HW2FCurveSim\n",
    "from ir.risk.pfe_swap import pfe_profile_swap\n",
    "from ir.risk.pfe_plot import plot_pfe_profile\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG \n",
    "# ============================================================\n",
    "# Chemin du template Excel (contient une feuille \"Curve\" et une feuille \"Template\")\n",
    "CURVE_XLSX = r\"Calibration_Templates\\SWPN_Calibration_Template_30092025_USD.xlsx\"\n",
    "TEMPLATE_XLSX = CURVE_XLSX\n",
    "\n",
    "# Monte Carlo pour la partie PFE \n",
    "N_PATHS = 20000\n",
    "SEED = 2025\n",
    "\n",
    "# Paramètres de swap pour l'expo / PFE\n",
    "PFE_TAU = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "PFE_NOTIONAL = 1_000_000.0\n",
    "PFE_PAYER = True\n",
    "PFE_Q = 0.95\n",
    "PFE_GRID_N = 21\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2-3 mini helpers \n",
    "# ============================================================\n",
    "def par_rate(curve, Tau):\n",
    "    \"\"\"\n",
    "    Calcule :\n",
    "    - A0 = annuité (somme des DF pondérés par les accruals)\n",
    "    - S0 = taux swap par (par swap rate) à t=0\n",
    "    pour un schedule Tau = [T0, T1, ..., Tn].\n",
    "    \"\"\"\n",
    "    Tau = [float(x) for x in Tau]\n",
    "    T0, Tn = Tau[0], Tau[-1]\n",
    "    A0 = 0.0\n",
    "    for i in range(1, len(Tau)):\n",
    "        Ti = Tau[i]\n",
    "        d = Tau[i] - Tau[i - 1]\n",
    "        A0 += d * float(curve.discount(Ti))\n",
    "    # S0 = (P(0,T0) - P(0,Tn)) / A0\n",
    "    S0 = (float(curve.discount(T0)) - float(curve.discount(Tn))) / (A0 + 1e-18)\n",
    "    return A0, S0  # annuity, par swap rate\n",
    "\n",
    "\n",
    "def ensure_expiry_tenor(df, dates_col=\"Payment_Dates\"):\n",
    "    \"\"\"\n",
    "    Ajoute des colonnes \"Expiry\" et \"Tenor\" si elles n'existent pas déjà.\n",
    "    - Expiry = première date de paiement (souvent = option expiry / swap start)\n",
    "    - Tenor  = dernière - première (maturité du swap sous-jacent)\n",
    "    \"\"\"\n",
    "    if \"Expiry\" not in df.columns:\n",
    "        df[\"Expiry\"] = df[dates_col].apply(lambda L: float(L[0]))\n",
    "    if \"Tenor\" not in df.columns:\n",
    "        df[\"Tenor\"] = df[dates_col].apply(lambda L: float(L[-1]) - float(L[0]))\n",
    "\n",
    "\n",
    "def add_implied_normal_vols_forward_premium(\n",
    "    df,\n",
    "    curve,\n",
    "    price_col=\"Price\",\n",
    "    model_col=\"Model_Price\",\n",
    "    strike_col=\"Strike\",\n",
    "    dates_col=\"Payment_Dates\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Convertit les PRIX (ici: forward premium) en vols normales implicites (Bachelier),\n",
    "    pour comparer Market vs Model en \"vol space\".\n",
    "\n",
    "    Convention utilisée :\n",
    "      forward premium = PV / DF(T0)\n",
    "    donc on reconstruit l'annuité \"forward\" A_fwd = A0 / DF(T0).\n",
    "\n",
    "    Attention :\n",
    "    - strike_col est en % (ex: 2.5 signifie 2.5%)\n",
    "    - forward_pct est aussi en % (on multiplie S0 par 100)\n",
    "    \"\"\"\n",
    "    mkt_vol, mdl_vol = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        Tau = row[dates_col]\n",
    "        T0 = float(Tau[0])                 # expiry\n",
    "        DF0 = float(curve.discount(T0))    # DF(0,T0)\n",
    "\n",
    "        # quantités swap à t=0\n",
    "        A0, S0 = par_rate(curve, Tau)\n",
    "\n",
    "        # passage en \"forward measure\" (cohérent avec forward premium)\n",
    "        annuity_fwd = A0 / (DF0 + 1e-18)\n",
    "\n",
    "        strike_pct = float(row[strike_col])      # % (ATM typiquement)\n",
    "        forward_pct = 100.0 * float(S0)          # % (S0 en units -> %)\n",
    "        notional = float(row.get(\"Notional\", 1.0))\n",
    "\n",
    "        # prix market vs modèle (en forward premium si forward_premium=True)\n",
    "        p_mkt = float(row[price_col])\n",
    "        p_mdl = float(row[model_col])\n",
    "\n",
    "        # inversion Bachelier : price -> sigma_N (en bps dans ton helper)\n",
    "        mkt_vol.append(black_normal_vol(p_mkt, forward_pct, strike_pct, T0, notional, annuity_fwd))\n",
    "        mdl_vol.append(black_normal_vol(p_mdl, forward_pct, strike_pct, T0, notional, annuity_fwd))\n",
    "\n",
    "    df[\"Market_Vol (Bps)\"] = mkt_vol\n",
    "    df[\"Model_Vol (Bps)\"] = mdl_vol\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) LOAD DATA\n",
    "# ============================================================\n",
    "print(\"\\n=== LOAD curve + swaptions template ===\")\n",
    "\n",
    "# Lecture de la courbe de discount (P(0,T)) depuis Excel\n",
    "curve = load_curve_xlsx(CURVE_XLSX)\n",
    "\n",
    "# Lecture du template de swaptions (expiries/tenors/strikes/prices)\n",
    "swpn = load_swaption_template_xlsx(TEMPLATE_XLSX)\n",
    "\n",
    "# Plot de sanity check : DF(t) + f(0,t)\n",
    "plot_curve(curve, title_prefix=\"Market\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) HW 1F : pricer -> calibrate -> compare -> PFE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HW 1F\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"[1F] init pricer\")\n",
    "# On construit le pricer 1F à partir de la courbe.\n",
    "# Le pricer embarque un curve_sim (HW1F) utilisé ensuite pour le PFE.\n",
    "pricer_1f = HullWhitePricer(curve, n_paths=N_PATHS, seed=SEED)\n",
    "\n",
    "print(\"[1F] calibrate (a,sigma) on swaptions (forward premium)\")\n",
    "# On met le template sous forme de dict utilisable par le calibrateur\n",
    "mkt_dict = swpn.to_market_dict()\n",
    "\n",
    "# Calibrage de (a, sigma) sur les swaptions (prix en forward premium)\n",
    "cal_1f = HullWhiteCalibrator(pricer_1f, mkt_dict, calibrate_to=\"Swaptions\")\n",
    "\n",
    "# Point de départ \n",
    "cal_1f.calibrate(init_a=0.01, init_sigma=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[1F] compare market vs model (plots)\")\n",
    "\n",
    "# Repricing du set de swaptions avec le modèle HW1F calibré\n",
    "# forward_premium=True \n",
    "df_1f = swpn.with_model_prices_1f(pricer_1f, forward_premium=True)\n",
    "\n",
    "# Ajout Expiry/Tenor\n",
    "ensure_expiry_tenor(df_1f)\n",
    "\n",
    "# Plot 2x2 : plusieurs tenors, prix en fonction de l'expiry\n",
    "plot_prices_by_tenor(df_1f, mkt_col=\"Price\", model_col=\"Model_Price\", ylabel=\"Forward Premium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819becc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des prix (forward premium) en vols normales implicites (Bachelier)\n",
    "add_implied_normal_vols_forward_premium(df_1f, curve)\n",
    "\n",
    "# Plot 2x2 des vols : \"Market vol\" vs \"Model vol\"\n",
    "plot_vols_by_tenor(\n",
    "    df_1f,\n",
    "    mkt_col=\"Market_Vol (Bps)\",\n",
    "    model_col=\"Model_Vol (Bps)\",\n",
    "    ylabel=\"Normal Vol (Bps)\",\n",
    "    title=\"HW1F | Swaption Normal Vols (implied, forward premium)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca88566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1F] PFE (swap)\n"
     ]
    }
   ],
   "source": [
    "print(\"[1F] PFE (swap)\")\n",
    "\n",
    "# Par rate du swap choisi \n",
    "A0, K_par = par_rate(curve, PFE_TAU)\n",
    "\n",
    "# Grille temps où on calcule les exposures\n",
    "grid = np.linspace(0.0, float(PFE_TAU[-1]), int(PFE_GRID_N))\n",
    "\n",
    "# Calcul du profil PFE/EPE :\n",
    "# - On simule P(t,Ti) via curve_sim (HW1F)\n",
    "# - On reconstruit V(t) du swap sur chaque path\n",
    "# - PFE = quantile de V+(t) ; EPE = moyenne de V+(t)\n",
    "pfe_1f, epe_1f = pfe_profile_swap(\n",
    "    curve_sim=pricer_1f.curve_sim,\n",
    "    grid=grid,\n",
    "    Tau=PFE_TAU,\n",
    "    K=0.03,\n",
    "    N=PFE_NOTIONAL,\n",
    "    payer=PFE_PAYER,\n",
    "    q=PFE_Q,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitle_1f = f\"Tau={PFE_TAU} | N={PFE_NOTIONAL:,.0f} | K(par)={K_par*100:.3f}% | params={pricer_1f.model.parameters}\"\n",
    "\n",
    "# Plot propre du profil PFE/EPE\n",
    "plot_pfe_profile(\n",
    "    grid,\n",
    "    pfe_1f,\n",
    "    epe=epe_1f,\n",
    "    q=PFE_Q,\n",
    "    title=\"HW1F | PFE profile (swap)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a58b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) HW 2F : pricer -> calibrate -> compare -> PFE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HW 2F (G2++)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"[2F] init pricer\")\n",
    "# Pricer 2F : construit le modèle G2++ (a,b,rho,sigma,eta)\n",
    "pricer_2f = HullWhite2FPricer(curve)\n",
    "\n",
    "print(\"[2F] calibrate profile on swaptions (forward premium)\")\n",
    "# Calibrage \"profil\" :\n",
    "# - outer = (a,b,rho) via une grille (coarse search)\n",
    "# - inner = (sigma,eta) via une optimisation locale (pour chaque candidat outer)\n",
    "cal_2f = HullWhite2FProfileCalibrator(pricer_2f, mkt_dict, use_forward_premium=True)\n",
    "\n",
    "# Grilles \"petites\" \n",
    "grid_a = [0.01, 0.02, 0.05, 0.10, 0.20]\n",
    "grid_b = [0.001, 0.003, 0.01, 0.02, 0.05]\n",
    "grid_rho = [-0.8, -0.5, -0.2, 0.0, 0.2]\n",
    "\n",
    "cal_2f.calibrate_profile(\n",
    "    grid_a=grid_a,\n",
    "    grid_b=grid_b,\n",
    "    grid_rho=grid_rho,\n",
    "    init_sigma=0.01,\n",
    "    init_eta=0.008,\n",
    "    verbose_inner=False,   \n",
    "    top_k=3,               \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad88dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[2F] compare market vs model (plots)\")\n",
    "\n",
    "# Repricing avec HW2F calibré\n",
    "df_2f = swpn.with_model_prices_2f(pricer_2f, forward_premium=True)\n",
    "ensure_expiry_tenor(df_2f)\n",
    "\n",
    "plot_prices_by_tenor(df_2f, mkt_col=\"Price\", model_col=\"Model_Price\", ylabel=\"Forward Premium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en vols normales implicites (Bachelier)\n",
    "add_implied_normal_vols_forward_premium(df_2f, curve)\n",
    "\n",
    "plot_vols_by_tenor(\n",
    "    df_2f,\n",
    "    mkt_col=\"Market_Vol (Bps)\",\n",
    "    model_col=\"Model_Vol (Bps)\",\n",
    "    ylabel=\"Normal Vol (Bps)\",\n",
    "    title=\"HW2F | Swaption Normal Vols (implied, forward premium)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2F] PFE (swap)\n"
     ]
    }
   ],
   "source": [
    "print(\"[2F] PFE (swap)\")\n",
    "\n",
    "# Simulateur 2F minimal : génère des distributions de P(t,T)\n",
    "curve_sim_2f = HW2FCurveSim(\n",
    "    curve=curve,\n",
    "    model=pricer_2f.model,\n",
    "    n_paths=N_PATHS,\n",
    "    seed=SEED,\n",
    "    use_legacy_global_seed=True,\n",
    ")\n",
    "\n",
    "# Même routine d'expo que pour 1F : seul le curve_sim change\n",
    "pfe_2f, epe_2f = pfe_profile_swap(\n",
    "    curve_sim=curve_sim_2f,\n",
    "    grid=grid,\n",
    "    Tau=PFE_TAU,\n",
    "    K=0.03,\n",
    "    N=PFE_NOTIONAL,\n",
    "    payer=PFE_PAYER,\n",
    "    q=PFE_Q,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtitle_2f = f\"Tau={PFE_TAU} | N={PFE_NOTIONAL:,.0f} | K(par)={K_par*100:.3f}% | params={pricer_2f.model.parameters}\"\n",
    "\n",
    "plot_pfe_profile(\n",
    "    grid,\n",
    "    pfe_2f,\n",
    "    epe=epe_2f,\n",
    "    q=PFE_Q,\n",
    "    title=\"HW2F | PFE profile (swap)\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


### FILE: test2.ipynb
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "notebook_workflows_simple.py\n",
    "\n",
    "Version \"notebook-like\" (linéaire, très simple) :\n",
    "1) HW 1F : load -> curve -> pricer -> calibrate -> compare plots -> PFE plot\n",
    "2) HW 2F : load -> curve -> pricer -> calibrate -> compare plots -> PFE plot\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# --- imports projet ---\n",
    "from ir.market.loaders_excel import load_curve_xlsx, load_swaption_template_xlsx\n",
    "from ir.market.plots import plot_curve, plot_prices_by_tenor, plot_vols_by_tenor\n",
    "from ir.calibration.vol import black_normal_vol\n",
    "\n",
    "from ir.pricers.hw1f_pricer import HullWhitePricer\n",
    "from ir.calibration.hw1f_calibration import HullWhiteCalibrator\n",
    "\n",
    "from ir.pricers.hw2f_pricer import HullWhite2FPricer\n",
    "from ir.calibration.hw2f_profile import HullWhite2FProfileCalibrator\n",
    "\n",
    "from ir.risk.hw2f_sim import HW2FCurveSim\n",
    "from ir.risk.pfe_swap import pfe_profile_swap\n",
    "from ir.risk.pfe_plot import plot_pfe_profile\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG (modifie juste ça)\n",
    "# ============================================================\n",
    "CURVE_XLSX = r\"Calibration_Templates\\SWPN_Calibration_Template_30092025_USD.xlsx\"\n",
    "TEMPLATE_XLSX = CURVE_XLSX\n",
    "\n",
    "N_PATHS = 20000\n",
    "SEED = 2025\n",
    "\n",
    "PFE_TAU = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "PFE_NOTIONAL = 1_000_000.0\n",
    "PFE_PAYER = True\n",
    "PFE_Q = 0.95\n",
    "PFE_GRID_N = 21\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2-3 mini helpers (sinon on répète trop)\n",
    "# ============================================================\n",
    "def par_rate(curve, Tau):\n",
    "    Tau = [float(x) for x in Tau]\n",
    "    T0, Tn = Tau[0], Tau[-1]\n",
    "    A0 = 0.0\n",
    "    for i in range(1, len(Tau)):\n",
    "        Ti = Tau[i]\n",
    "        d = Tau[i] - Tau[i - 1]\n",
    "        A0 += d * float(curve.discount(Ti))\n",
    "    S0 = (float(curve.discount(T0)) - float(curve.discount(Tn))) / (A0 + 1e-18)\n",
    "    return A0, S0  # annuity, par swap rate\n",
    "\n",
    "\n",
    "def ensure_expiry_tenor(df, dates_col=\"Payment_Dates\"):\n",
    "    if \"Expiry\" not in df.columns:\n",
    "        df[\"Expiry\"] = df[dates_col].apply(lambda L: float(L[0]))\n",
    "    if \"Tenor\" not in df.columns:\n",
    "        df[\"Tenor\"] = df[dates_col].apply(lambda L: float(L[-1]) - float(L[0]))\n",
    "\n",
    "\n",
    "def add_implied_normal_vols_forward_premium(df, curve,\n",
    "                                           price_col=\"Price\",\n",
    "                                           model_col=\"Model_Price\",\n",
    "                                           strike_col=\"Strike\",\n",
    "                                           dates_col=\"Payment_Dates\"):\n",
    "    # Convention: forward premium = PV / DF(T0)\n",
    "    mkt_vol, mdl_vol = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        Tau = row[dates_col]\n",
    "        T0 = float(Tau[0])\n",
    "        DF0 = float(curve.discount(T0))\n",
    "        A0, S0 = par_rate(curve, Tau)\n",
    "        annuity_fwd = A0 / (DF0 + 1e-18)\n",
    "\n",
    "        strike_pct = float(row[strike_col])      # %\n",
    "        forward_pct = 100.0 * float(S0)          # %\n",
    "        notional = float(row.get(\"Notional\", 1.0))\n",
    "\n",
    "        p_mkt = float(row[price_col])\n",
    "        p_mdl = float(row[model_col])\n",
    "\n",
    "        mkt_vol.append(black_normal_vol(p_mkt, forward_pct, strike_pct, T0, notional, annuity_fwd))\n",
    "        mdl_vol.append(black_normal_vol(p_mdl, forward_pct, strike_pct, T0, notional, annuity_fwd))\n",
    "\n",
    "    df[\"Market_Vol (Bps)\"] = mkt_vol\n",
    "    df[\"Model_Vol (Bps)\"] = mdl_vol\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) LOAD DATA\n",
    "# ============================================================\n",
    "print(\"\\n=== LOAD curve + swaptions template ===\")\n",
    "curve = load_curve_xlsx(CURVE_XLSX)\n",
    "swpn = load_swaption_template_xlsx(TEMPLATE_XLSX)\n",
    "\n",
    "plot_curve(curve, title_prefix=\"Market\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 2) HW 1F : pricer -> calibrate -> compare -> PFE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HW 1F\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"[1F] init pricer\")\n",
    "pricer_1f = HullWhitePricer(curve, n_paths=N_PATHS, seed=SEED)\n",
    "\n",
    "print(\"[1F] calibrate (a,sigma) on swaptions (forward premium)\")\n",
    "mkt_dict = swpn.to_market_dict()\n",
    "cal_1f = HullWhiteCalibrator(pricer_1f, mkt_dict, calibrate_to=\"Swaptions\")\n",
    "cal_1f.calibrate(init_a=0.01, init_sigma=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[1F] compare market vs model (plots)\")\n",
    "df_1f = swpn.with_model_prices_1f(pricer_1f, forward_premium=True)\n",
    "ensure_expiry_tenor(df_1f)\n",
    "\n",
    "plot_prices_by_tenor(df_1f, mkt_col=\"Price\", model_col=\"Model_Price\", ylabel=\"Forward Premium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819becc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_implied_normal_vols_forward_premium(df_1f, curve)\n",
    "plot_vols_by_tenor(df_1f,\n",
    "                   mkt_col=\"Market_Vol (Bps)\",\n",
    "                   model_col=\"Model_Vol (Bps)\",\n",
    "                   ylabel=\"Normal Vol (Bps)\",\n",
    "                   title=\"HW1F | Swaption Normal Vols (implied, forward premium)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aca88566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1F] PFE (swap)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[1F] PFE (swap)\")\n",
    "A0, K_par = par_rate(curve, PFE_TAU)\n",
    "grid = np.linspace(0.0, float(PFE_TAU[-1]), int(PFE_GRID_N))\n",
    "\n",
    "pfe_1f, epe_1f = pfe_profile_swap(\n",
    "    curve_sim=pricer_1f.curve_sim,\n",
    "    grid=grid,\n",
    "    Tau=PFE_TAU,\n",
    "    K=0.03,\n",
    "    N=PFE_NOTIONAL,\n",
    "    payer=PFE_PAYER,\n",
    "    q=PFE_Q,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f205ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subtitle_1f = f\"Tau={PFE_TAU} | N={PFE_NOTIONAL:,.0f} | K(par)={K_par*100:.3f}% | params={pricer_1f.model.parameters}\"\n",
    "plot_pfe_profile(grid, pfe_1f, epe=epe_1f, q=PFE_Q, title=\"HW1F | PFE profile (swap)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a58b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 3) HW 2F : pricer -> calibrate -> compare -> PFE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HW 2F (G2++)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"[2F] init pricer\")\n",
    "pricer_2f = HullWhite2FPricer(curve)\n",
    "\n",
    "print(\"[2F] calibrate profile on swaptions (forward premium)\")\n",
    "cal_2f = HullWhite2FProfileCalibrator(pricer_2f, mkt_dict, use_forward_premium=True)\n",
    "\n",
    "# grids \"petites\" (lisible). Tu élargiras ensuite.\n",
    "grid_a = [0.01, 0.02, 0.05, 0.10, 0.20]\n",
    "grid_b = [0.001, 0.003, 0.01, 0.02, 0.05]\n",
    "grid_rho = [-0.8, -0.5, -0.2, 0.0, 0.2]\n",
    "\n",
    "cal_2f.calibrate_profile(\n",
    "    grid_a=grid_a,\n",
    "    grid_b=grid_b,\n",
    "    grid_rho=grid_rho,\n",
    "    init_sigma=0.01,\n",
    "    init_eta=0.008,\n",
    "    verbose_inner=False,\n",
    "    top_k=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad88dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[2F] compare market vs model (plots)\")\n",
    "df_2f = swpn.with_model_prices_2f(pricer_2f, forward_premium=True)\n",
    "ensure_expiry_tenor(df_2f)\n",
    "\n",
    "plot_prices_by_tenor(df_2f, mkt_col=\"Price\", model_col=\"Model_Price\", ylabel=\"Forward Premium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_implied_normal_vols_forward_premium(df_2f, curve)\n",
    "plot_vols_by_tenor(df_2f,\n",
    "                   mkt_col=\"Market_Vol (Bps)\",\n",
    "                   model_col=\"Model_Vol (Bps)\",\n",
    "                   ylabel=\"Normal Vol (Bps)\",\n",
    "                   title=\"HW2F | Swaption Normal Vols (implied, forward premium)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8353d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2F] PFE (swap)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"[2F] PFE (swap)\")\n",
    "curve_sim_2f = HW2FCurveSim(\n",
    "    curve=curve,\n",
    "    model=pricer_2f.model,\n",
    "    n_paths=N_PATHS,\n",
    "    seed=SEED,\n",
    "    use_legacy_global_seed=True,\n",
    ")\n",
    "\n",
    "pfe_2f, epe_2f = pfe_profile_swap(\n",
    "    curve_sim=curve_sim_2f,\n",
    "    grid=grid,\n",
    "    Tau=PFE_TAU,\n",
    "    K=0.03,\n",
    "    N=PFE_NOTIONAL,\n",
    "    payer=PFE_PAYER,\n",
    "    q=PFE_Q,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subtitle_2f = f\"Tau={PFE_TAU} | N={PFE_NOTIONAL:,.0f} | K(par)={K_par*100:.3f}% | params={pricer_2f.model.parameters}\"\n",
    "plot_pfe_profile(grid, pfe_2f, epe=epe_2f, q=PFE_Q, title=\"HW2F | PFE profile (swap)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


### FILE: ir\calibration\hw1f_calibration.py
from scipy.optimize import minimize, brentq
import numpy as np
from scipy.stats import norm
import itertools
from typing import Callable, Optional, Dict, Any


class HullWhiteCalibrator:
    """
    Calibre les paramètres (a, sigma) du modèle de Hull–White 1 facteur
    à partir de prix de marché de caplets ou de swaptions.

    Notes
    -----
    - Utilise une paramétrisation en log pour imposer la positivité :
      a = exp(x[0]), sigma = exp(x[1]).
    - Fonction objectif : RMSRE (root mean squared relative error) sur les prix
      (ou sur la prime forward pour les swaptions).
    - Conserve des impressions détaillées (callback + rapport final instrument par instrument)

    Patch (progression Streamlit)
    -----------------------------
    - progress_cb : callable optionnel appelé à chaque itération de l’optimiseur (via callback).
      Il reçoit un dict : {"iter": int, "a": float, "sigma": float, "rmsre": float}
    """

    def __init__(
        self,
        pricer,
        market_prices,
        calibrate_to="Caplets",
        progress_cb: Optional[Callable[[Dict[str, Any]], None]] = None,  
    ):
        # Pricer HW (contient model + curve + formules caplet/swaption)
        self.pricer = pricer
        self.model = pricer.model

        # Dictionnaire-like de données de marché (strikes, maturités, prix, etc.)
        self.market_prices = market_prices

        # Type de calibration : "Caplets" ou "Swaptions"
        self.calibrate_to = calibrate_to

        # Historique des évaluations de l’objectif : (a, sigma, rmsre)
        # Utile pour debug, graphiques, ou affichage streamlit
        self.history = []

        # Callback optionnel pour faire remonter la progression dans une UI (Streamlit)
        self.progress_cb = progress_cb  

        # Compteur d’itérations basé sur le nombre d’appels au callback
        self._cb_iter = 0  

    # -------- helpers internes -------- #

    def _set_params(self, a: float, sigma: float) -> None:
        # Met à jour les paramètres du modèle dans l’objet pricer.model
        self.model.parameters["a"] = float(a)
        self.model.parameters["sigma"] = float(sigma)

    def _price_instrument(self, i: int) -> float:
        """
        Retourne le prix modèle (ou la prime forward pour les swaptions) pour l’instrument i,
        en utilisant les paramètres courants (a, sigma).
        """
        # Conversion du strike stocké en pourcentage vers un taux décimal (ex: 3% -> 0.03)
        K = self.market_prices["Strike"][i] / 100.0

        # Notional de l’instrument (le pricer attend généralement N explicite)
        N = self.market_prices["Notional"][i]

        if self.calibrate_to == "Caplets":
            # Caplet défini par (Expiry, Maturity) dans ton format de données
            T = self.market_prices["Expiry"][i]
            S = self.market_prices["Maturity"][i]
            return self.pricer.caplet(T, S, N, K)

        elif self.calibrate_to == "Swaptions":
            # Swaption définie par une grille de dates Tau = [T0, T1, ..., Tn]
            Tau = self.market_prices["Dates"][i]

            # Discount factor au début du swap (utile pour convertir en "prime forward")
            DF = self.pricer.curve.discount(Tau[0])

            # Cohérence de convention : vérifier que market_prices['Prices'] est bien défini
            # selon cette convention de "prime forward" (prix / DF).
            return self.pricer.swaption(Tau, N, K) / DF

        # Protection : évite un calibrage silencieux sur un type non supporté
        raise ValueError("Calibration implémentée uniquement pour 'Caplets' et 'Swaptions'.")

    # -------- objectif d’optimisation + callback -------- #

    def objective(self, x):
        """
        Fonction objectif J(x) avec x = (log(a), log(sigma)).
        Retourne la RMSRE sur l’ensemble des instruments.

        RMSRE = sqrt( (1/n) * sum_i ((model_i - mkt_i)^2 / (mkt_i^2 + eps)) )
        """
        # Paramétrisation en log : garantit a>0 et sigma>0
        a = np.exp(x[0])
        sigma = np.exp(x[1])

        # On “pousse” les paramètres dans le modèle avant de price
        self._set_params(a, sigma)

        # Prix de marché (même convention que _price_instrument)
        prices = self.market_prices["Prices"]
        n = len(prices)

        # Terme de stabilisation pour éviter division par ~0 si un prix marché est très petit
        eps = 1e-6

        # Accumulation de l’erreur relative au carré (moyennée)
        err = 0.0
        for i in range(n):
            # Prix observé marché pour l’instrument i
            market_price = prices[i]

            # Prix modèle donné les paramètres courants
            model_price = self._price_instrument(i)

            # Contribution RMSRE : (model-mkt)^2 / (mkt^2 + eps), moyennée sur n
            err += (1.0 / n) * ((model_price - market_price) ** 2) / (market_price**2 + eps)

        # RMSRE finale
        rmsre = float(np.sqrt(err))

        # On stocke l’évaluation : utile pour callback + debug
        self.history.append((a, sigma, rmsre))

        return rmsre

    def callback(self, x):
        """
        Affiche les paramètres (a, sigma) et l’erreur durant l’optimisation
        (comme dans ton callback d’origine).
        Appelle aussi progress_cb si fourni (pour mise à jour live dans l’UI Streamlit).
        """
        # Cas rare : callback appelé avant la première évaluation “history”
        if not self.history:
            return

        # Incrémente le compteur d’itérations "UI"
        self._cb_iter += 1 

        # Dernière valeur évaluée par objective()
        a, sigma, err = self.history[-1]

        # Impression console (capturable via ton capture_stdout)
        print(f"a: {a:.6f}, sigma: {sigma:.6f}, RMSRE: {err:.5e}")

        # On encapsule dans try/except pour ne jamais casser l’optimisation si l’UI plante.
        if self.progress_cb is not None:
            try:
                self.progress_cb(
                    {
                        "iter": int(self._cb_iter),
                        "a": float(a),
                        "sigma": float(sigma),
                        "rmsre": float(err),
                    }
                )
            except Exception:
                # Ne pas casser l’optimisation si la mise à jour UI échoue
                pass

    # -------- point d’entrée principal -------- #

    def calibrate(
        self,
        init_a=0.01,
        init_sigma=0.01,
        bounds_a=(1e-4, 1.0),
        bounds_sigma=(1e-4, 0.5),
        method="L-BFGS-B",
        ftol=1e-6,
    ):
        """
        Lance l’optimisation pour calibrer a et sigma.

        Retourne
        --------
        scipy.optimize.OptimizeResult
        """
        # Réinitialise le compteur d’itérations du callback à chaque run
        self._cb_iter = 0

        # Point de départ : on passe en log-space (compat avec objective)
        x0 = np.log([init_a, init_sigma])

        # Bornes en log-space (cohérent avec x = (log(a), log(sigma)))
        bounds = [
            (np.log(bounds_a[0]), np.log(bounds_a[1])),
            (np.log(bounds_sigma[0]), np.log(bounds_sigma[1])),
        ]

        # Lance l’optimiseur SciPy
        # - objective: calcule RMSRE
        # - callback: affichage + UI
        # - options ftol: tolérance sur la convergence (peut dépendre de la version SciPy)
        result = minimize(
            self.objective,
            x0,
            bounds=bounds,
            method=method,
            callback=self.callback,
            options={"ftol": ftol},
        )

        if result.success:
            # Reconvertit les paramètres optimaux depuis log-space
            a_opt = float(np.exp(result.x[0]))
            sigma_opt = float(np.exp(result.x[1]))

            # Fige les paramètres optimaux dans le modèle
            self._set_params(a_opt, sigma_opt)

            # Résumé console
            print("\nCalibration réussie :")
            print(f"Itérations : {result.nit}")
            print(f"Nombre d’instruments : {len(self.market_prices['Prices'])}")
            print(f"Erreur totale (RMSRE) : {result.fun:>+8.3%}\n")
            print("Paramètres :")
            print(f"a optimal : {a_opt:.6f}")
            print(f"sigma optimal : {sigma_opt:.6f}\n")

            # Rapport instrument par instrument : compare prix modèle vs marché
            for i in range(len(self.market_prices["Prices"])):
                market_price = self.market_prices["Prices"][i]
                model_price = self._price_instrument(i)

                # Différence relative (attention: division stabilisée)
                dif = model_price / (market_price + 1e-12) - 1.0

                if self.calibrate_to == "Caplets":
                    # Détail des dates caplets pour lecture humaine
                    T = self.market_prices["Expiry"][i]
                    S = self.market_prices["Maturity"][i]
                    print(
                        f"Caplet {i:>2}: {T:>5.2f}Y à {S:<5.2f}Y | "
                        f"Modèle: {model_price:>8.2f} | Marché: {market_price:>8.2f} | Écart: {dif:>+8.3%}"
                    )

                elif self.calibrate_to == "Swaptions":
                    # Swaption : affiche seulement début/fin de Tau
                    Tau = self.market_prices["Dates"][i]
                    print(
                        f"Swaption {i:>3}: {Tau[0]:>5.2f}Y à {Tau[-1]:<5.2f}Y | "
                        f"Modèle: {model_price:>8.2f} | Marché: {market_price:>8.2f} | Écart: {dif:>+8.3%}"
                    )

        else:
            # Message d’erreur de l’optimiseur (bornes, non convergence, etc.)
            print("Calibration échouée :", result.message)

        return result


### FILE: ir\calibration\hw2f_profile.py
from __future__ import annotations

from scipy.optimize import minimize, brentq
import numpy as np
from scipy.stats import norm
import itertools
from typing import Callable, Optional


class HullWhite2FProfileCalibrator:
    """
    Calibrage "profilé" du modèle Hull–White 2 facteurs (G2++)
    sur des swaptions, via :
      - une approximation gaussienne du taux de swap
      - une valorisation en Bachelier (normal model) sur le taux de swap

    Boucle externe : (a, b, rho)
    Boucle interne : (sigma, eta)

    Données de marché attendues dans market_prices :
        - "Prices": list[float]  (PV ou prime forward, cf. use_forward_premium)
        - "Strike": list[float]  (en % -> sera divisé par 100)
        - "Notional": list[float]
        - "Dates": list[list[float]]  où Dates[i] = [T0, T1, ..., Tn]

    Options
    -------
    use_forward_premium : bool
        - Si True : on compare model_price / DF(T0) au prix marché
          (cohérent avec ta convention 1F en calibration "Swaptions").
        - Si False : on compare directement les PV.

    payer : bool
        Hypothèse "payer swaption" pour tous les instruments, sauf si tu fournis
        explicitement "Payer" dans market_prices.
    """

    def __init__(
        self,
        pricer,
        market_prices,
        use_forward_premium=True,
        progress_cb: Optional[Callable[[dict], None]] = None,
    ):
        # Pricer 2F (contient curve + model + conventions)
        self.pricer = pricer
        self.model = pricer.model
        self.curve = pricer.curve

        # Dictionnaire de données de marché (swaptions)
        self.market_prices = market_prices

        # Convention de comparaison (PV vs prime forward)
        self.use_forward_premium = bool(use_forward_premium)

        # Callback UI optionnel (Streamlit, barre de progrès, etc.)
        self.progress_cb = progress_cb

        # Présence éventuelle d'un flag Payer/Receiver par instrument
        self.has_payer_flags = ("Payer" in market_prices)

        # Historique boucle externe : dicts (a,b,rho,sigma,eta,rmsre)
        self.outer_history = []

        # Historique boucle interne : tuples (sigma, eta, rmsre) pour le candidat outer courant
        self.inner_history = []

        # Pré-calcul des objets "statiques" par instrument (ne dépend pas de a,b,rho,sigma,eta)
        # => permet d'éviter de recalculer Tau, A0, S0, poids c, DF(T0) à chaque évaluation.
        self._instr = self._precompute_instruments()

    # -------------------------
    # Gestion des paramètres du modèle
    # -------------------------

    def _set_params(self, a, b, rho, sigma, eta):
        # Met à jour les paramètres du modèle en float (robuste aux types numpy)
        self.model.parameters["a"] = float(a)
        self.model.parameters["b"] = float(b)
        self.model.parameters["rho"] = float(rho)
        self.model.parameters["sigma"] = float(sigma)
        self.model.parameters["eta"] = float(eta)

    # -------------------------
    # Pré-calcul par swaption
    # -------------------------

    def _annuity_and_swap_rate_0(self, Tau):
        """
        Calcule, avec les mêmes conventions que ton pricer :
          - Delta_i = Tau[i] - Tau[i-1]
          - A0 = somme_i Delta_i * P(0, Ti)   (annuité)
          - S0 = (P(0,T0) - P(0,Tn)) / A0     (taux de swap forward à t=0)

        Retourne
        --------
        (A0, S0) en float
        """
        T0 = float(Tau[0])
        Tn = float(Tau[-1])

        # Annuité A0 (pondération des DF par les accruals)
        A0 = 0.0
        for i in range(1, len(Tau)):
            Ti = float(Tau[i])
            delta = float(Tau[i] - Tau[i - 1])
            A0 += delta * self.curve.discount(Ti)

        # Sécurité : une annuité nulle/negative signale un problème de courbe/dates
        if A0 <= 0:
            raise ValueError("Annuity A0 must be > 0.")

        # Swap rate forward S0 (standard)
        S0 = (self.curve.discount(T0) - self.curve.discount(Tn)) / A0
        return float(A0), float(S0)

    def _frozen_weights(self, Tau, A0, S0):
        """
        Construit les poids "frozen" c associés à la variable :
          S(T) ≈ somme_j c_j * P(T, U_j)
        sur la grille U = Tau.

        Formules (approximation gaussienne du taux de swap) :
          c[T0] += +P(0,T0)/A0
          c[Tn] += -P(0,Tn)/A0
          c[Ti] += -(S0/A0) * Delta_i * P(0,Ti), i=1..n

        Retourne
        --------
        U : list[float]  (copie de Tau en float)
        c : np.ndarray   (poids gelés)
        """
        # U est la grille des dates (en float)
        U = [float(x) for x in Tau]
        m = len(U)

        # Poids c_j
        c = np.zeros(m, dtype=float)

        # Terme "numérateur" du swap rate (P(0,T0) - P(0,Tn))
        c[0] += self.curve.discount(U[0]) / A0
        c[-1] += -self.curve.discount(U[-1]) / A0

        # Terme "annuité" : contribution des cashflows fixes via S0
        for i in range(1, m):
            Ti = U[i]
            delta = U[i] - U[i - 1]
            c[i] += -(S0 / A0) * delta * self.curve.discount(Ti)

        return U, c

    def _precompute_instruments(self):
        """
        Pré-calcul, pour chaque swaption i :
          - Tau, U, c
          - expiry T = Tau[0], DF(T)
          - A0, S0
          - K (en taux décimal), N
          - prix marché mkt
          - flag payer (si fourni)

        Objectif
        --------
        Isoler ce qui ne dépend pas des paramètres HW2F, pour accélérer la calibration.
        """
        prices = self.market_prices["Prices"]
        strikes = self.market_prices["Strike"]
        notionals = self.market_prices["Notional"]
        dates = self.market_prices["Dates"]

        n = len(prices)
        instr = []

        for i in range(n):
            # Dates de paiement du swap sous-jacent
            Tau = [float(x) for x in dates[i]]
            if len(Tau) < 2:
                raise ValueError(f"Instrument {i}: Tau must contain at least [T0, Tn].")

            # Expiry de la swaption = début du swap (T0)
            T = float(Tau[0])
            DF = float(self.curve.discount(T))

            # A0 et S0 à t=0
            A0, S0 = self._annuity_and_swap_rate_0(Tau)

            # Poids frozen (approx swap rate gaussien)
            U, c = self._frozen_weights(Tau, A0, S0)

            # Strike (% -> décimal) + notional + prix marché
            K = float(strikes[i]) / 100.0
            N = float(notionals[i])
            mkt = float(prices[i])

            # Payer/Receiver (par défaut payer)
            payer = True
            if self.has_payer_flags:
                payer = bool(self.market_prices["Payer"][i])

            instr.append(
                {
                    "Tau": Tau,
                    "U": U,
                    "c": c,
                    "T": T,
                    "DF": DF,
                    "A0": A0,
                    "S0": S0,
                    "K": K,
                    "N": N,
                    "mkt": mkt,
                    "payer": payer,
                }
            )

        return instr

    # -------------------------
    # Quantités dépendantes de la boucle externe (a, b)
    # -------------------------

    def _compute_Qs_for_outer(self, a, b):
        """
        Pour un couple (a, b) donné (boucle externe), calcule pour chaque instrument :
            Qaa = c^T I_aa c
            Qbb = c^T I_bb c
            Qab = c^T I_ab c

        Ces Q sont des “matrices quadratiques compressées” qui capturent la variance/covariance
        des log-bonds dans l'approximation gaussienne du taux de swap.

        Détails
        -------
        - I_aa, I_bb, I_ab sont des intégrales fermées (closed-form) en HW2F,
          implémentées dans HullWhite2FModel.
        - Une fois Qaa/Qbb/Qab connus, la valorisation est très rapide pour (sigma, eta).
        """
        # Tableaux Q par instrument
        Qaa = np.zeros(len(self._instr), dtype=float)
        Qbb = np.zeros(len(self._instr), dtype=float)
        Qab = np.zeros(len(self._instr), dtype=float)

        # Récupération des fonctions d'intégrales (selon où elles sont définies)
        I_aa = self.model.__class__.I_aa if hasattr(self.model.__class__, "I_aa") else None
        I_bb = self.model.__class__.I_bb if hasattr(self.model.__class__, "I_bb") else None
        I_ab = self.model.__class__.I_ab if hasattr(self.model.__class__, "I_ab") else None

        # Fallback si jamais le modèle courant ne porte pas ces méthodes
        if I_aa is None or I_bb is None or I_ab is None:
            from models.hw2f import HullWhite2FModel
            I_aa = HullWhite2FModel.I_aa
            I_bb = HullWhite2FModel.I_bb
            I_ab = HullWhite2FModel.I_ab

        # Pour chaque instrument, on calcule la forme quadratique c^T I c
        for k, ins in enumerate(self._instr):
            T = ins["T"]   # expiry
            U = ins["U"]   # grille dates
            c = ins["c"]   # poids frozen

            qaa = 0.0
            qbb = 0.0
            qab = 0.0

            # Double somme (i,j) sur les dates U
            for i, Ui in enumerate(U):
                ci = c[i]
                if ci == 0.0:
                    continue
                for j, Uj in enumerate(U):
                    cj = c[j]
                    if cj == 0.0:
                        continue
                    # Intégrales fermées HW2F
                    qaa += ci * cj * I_aa(T, Ui, Uj, a)
                    qbb += ci * cj * I_bb(T, Ui, Uj, b)
                    qab += ci * cj * I_ab(T, Ui, Uj, a, b)

            # Stockage pour l'instrument k
            Qaa[k] = qaa
            Qbb[k] = qbb
            Qab[k] = qab

        return Qaa, Qbb, Qab

    # -------------------------
    # Objectif interne (sigma, eta)
    # -------------------------

    def _price_swaption_from_Qs(self, ins, rho, sigma, eta, qaa, qbb, qab):
        """
        Pricing rapide d'une swaption en utilisant Qaa/Qbb/Qab pré-calculés :

          Var[S(T)] = sigma^2 * qaa + eta^2 * qbb + 2 * rho * sigma * eta * qab

        Puis valorisation Bachelier sur le taux de swap :
          PV = N * A0 * BachelierPrice(S0, K, sigma_N, T)

        Remarques
        ---------
        - On travaille sur la variance du taux de swap à l'échéance T, puis on en déduit
          une volatilité normale (sigma_N).
        - payer/receiver géré via w = +1 (payer) ou -1 (receiver).
        """
        T = ins["T"]
        A0 = ins["A0"]
        S0 = ins["S0"]
        K = ins["K"]
        N = ins["N"]
        payer = ins["payer"]

        # Variance du taux de swap à l'échéance (clamp à 0 pour stabilité numérique)
        varS = (sigma * sigma) * qaa + (eta * eta) * qbb + 2.0 * rho * sigma * eta * qab
        varS = float(max(varS, 0.0))

        # Signe pour payer/receiver (payer = +, receiver = -)
        w = 1.0 if payer else -1.0

        # Cas T <= 0 : payoff immédiat (théorique, rare en calibration)
        if T <= 0:
            return float(N * A0 * max(w * (S0 - K), 0.0))

        # Cas de variance quasi nulle : on retombe sur l'intrinsèque
        if varS < 1e-30:
            return float(N * A0 * max(w * (S0 - K), 0.0))

        # Volatilité normale sur le taux (approx) : sigma_N = sqrt(Var / T)
        sigmaN = np.sqrt(varS / T)

        # d de Bachelier : (S0-K)/(sigmaN*sqrt(T))
        d = (S0 - K) / (sigmaN * np.sqrt(T))

        # Formule Bachelier (normal model)
        price = N * A0 * (w * (S0 - K) * norm.cdf(w * d) + sigmaN * np.sqrt(T) * norm.pdf(d))
        return float(price)

    def _inner_objective(self, x, rho, Qaa, Qbb, Qab):
        """
        Fonction objectif interne, où x = (log(sigma), log(eta)).

        - On fixe (a,b,rho) dans la boucle externe
        - On calibre (sigma, eta) en minimisant la RMSRE
        - Selon use_forward_premium :
            * True  => compare PV/DF(T0) à mkt
            * False => compare PV à mkt
        """
        # Paramétrisation log pour garantir sigma>0 et eta>0
        sigma = float(np.exp(x[0]))
        eta = float(np.exp(x[1]))

        eps = 1e-6
        n = len(self._instr)

        # Accumulation RMSRE
        err = 0.0
        for k, ins in enumerate(self._instr):
            # PV modèle (Bachelier sur taux de swap)
            model_pv = self._price_swaption_from_Qs(ins, rho, sigma, eta, Qaa[k], Qbb[k], Qab[k])

            # Conversion PV -> prime forward si demandé
            if self.use_forward_premium:
                model_val = model_pv / (ins["DF"] + 1e-18)
            else:
                model_val = model_pv

            # Prix marché associé
            mkt = ins["mkt"]

            # Erreur relative au carré (stabilisée)
            err += (1.0 / n) * ((model_val - mkt) ** 2) / (mkt * mkt + eps)

        rmsre = float(np.sqrt(err))

        # Historise pour debug / verbose
        self.inner_history.append((sigma, eta, rmsre))

        return rmsre

    def _inner_callback(self, x):
        # Callback interne (optionnel) : affiche l’avancement de la calibration (sigma, eta)
        # Utilisé seulement si verbose_inner=True dans calibrate_profile()
        if not self.inner_history:
            return
        sigma, eta, err = self.inner_history[-1]
        print(f"    sigma: {sigma:.6f}, eta: {eta:.6f}, RMSRE: {err:.5e}")

    def _run_inner_calibration(
        self,
        rho,
        Qaa,
        Qbb,
        Qab,
        init_sigma=0.01,
        init_eta=0.008,
        bounds_sigma=(1e-4, 0.5),
        bounds_eta=(1e-4, 0.5),
        method="L-BFGS-B",
        ftol=1e-6,
        verbose=False,
    ):
        """
        Lance la calibration interne de (sigma, eta) pour un rho fixé
        et des Q pré-calculés (donc pour un (a,b) fixé).

        Retourne
        --------
        (res, sigma_opt, eta_opt)
          - res : OptimizeResult SciPy
          - sigma_opt, eta_opt : paramètres optimaux (reconvertis depuis log-space)
        """
        # Reset de l'historique interne à chaque candidat outer
        self.inner_history = []

        # Point de départ en log-space
        x0 = np.log([init_sigma, init_eta])

        # Bornes en log-space
        bounds = [
            (np.log(bounds_sigma[0]), np.log(bounds_sigma[1])),
            (np.log(bounds_eta[0]), np.log(bounds_eta[1])),
        ]

        # Callback interne seulement en mode verbose (sinon None = pas d'affichage)
        cb = self._inner_callback if verbose else None

        # Optimisation SciPy : minimise la RMSRE interne
        res = minimize(
            lambda x: self._inner_objective(x, rho, Qaa, Qbb, Qab),
            x0,
            bounds=bounds,
            method=method,
            callback=cb,
            options={"ftol": ftol},
        )

        # Reconvertit les paramètres optimaux depuis log-space
        sigma_opt = float(np.exp(res.x[0]))
        eta_opt = float(np.exp(res.x[1]))
        return res, sigma_opt, eta_opt

    # -------------------------
    # API publique : calibrage profilé
    # -------------------------

    def calibrate_profile(
        self,
        # grilles boucle externe
        grid_a=None,
        grid_b=None,
        grid_rho=None,
        # init/bornes boucle interne
        init_sigma=0.01,
        init_eta=0.008,
        bounds_sigma=(1e-4, 0.5),
        bounds_eta=(1e-4, 0.5),
        # settings optim interne
        inner_method="L-BFGS-B",
        inner_ftol=1e-6,
        verbose_inner=False,
        top_k=3,
    ):
        """
        Lance le calibrage profilé :
          1) On parcourt une grille de (a,b,rho)
          2) Pour chaque triplet, on calcule Qaa/Qbb/Qab
          3) On calibre (sigma, eta) en interne
          4) On conserve le meilleur candidat (RMSRE minimale)

        Retourne
        -------
        dict :
          - "best"    : meilleur candidat (paramètres + rmsre + inner_result)
          - "ranking" : liste triée de tous les candidats
        """
        # Grilles par défaut si non fournies (pédagogiques / robustes)
        if grid_a is None:
            grid_a = [0.01, 0.02, 0.05, 0.10, 0.20, 0.30]
        if grid_b is None:
            grid_b = [0.001, 0.003, 0.01, 0.02, 0.05, 0.10]
        if grid_rho is None:
            grid_rho = [-0.95, -0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4]

        # Contrainte d’identification fréquente : b < a
        outer_candidates = []
        for a, b, rho in itertools.product(grid_a, grid_b, grid_rho):
            if b < a:
                outer_candidates.append((float(a), float(b), float(rho)))

        # Si la contrainte b<a vide la grille, c’est un problème de choix de grilles
        if not outer_candidates:
            raise ValueError("Empty outer grid after applying constraint b < a.")

        outer_total = len(outer_candidates)

        # Messages de contexte (log console)
        print(f"Calibration profilé sur {len(self._instr)} swaptions.")
        print(f"Candidats grille externe : {outer_total}")

        results = []
        best_rmsre = float("inf")

        # Boucle externe : évalue chaque triplet (a,b,rho)
        for idx, (a, b, rho) in enumerate(outer_candidates, start=1):
            # --- progress: début d’un candidat ---
            if self.progress_cb is not None:
                try:
                    self.progress_cb(
                        {
                            "stage": "outer_start",
                            "outer_idx": int(idx),
                            "outer_total": int(outer_total),
                            "a": float(a),
                            "b": float(b),
                            "rho": float(rho),
                            "best_rmsre": None if best_rmsre == float("inf") else float(best_rmsre),
                        }
                    )
                except Exception:
                    # Ne jamais casser la calibration à cause du callback UI
                    pass

            # Affichage du candidat courant
            print(f"\n[Outer {idx}/{outer_total}] a={a:.4f}, b={b:.4f}, rho={rho:+.2f}")

            # Mise à jour des paramètres "outer" dans le modèle (sigma,eta seront calibrés ensuite)
            self.model.parameters["a"] = a
            self.model.parameters["b"] = b
            self.model.parameters["rho"] = rho

            # Calcul Qaa/Qbb/Qab (dépend uniquement de a et b)
            Qaa, Qbb, Qab = self._compute_Qs_for_outer(a, b)

            # Calibration interne (sigma,eta) avec rho fixé + Q's fixés
            res_in, sigma_opt, eta_opt = self._run_inner_calibration(
                rho=rho,
                Qaa=Qaa,
                Qbb=Qbb,
                Qab=Qab,
                init_sigma=init_sigma,
                init_eta=init_eta,
                bounds_sigma=bounds_sigma,
                bounds_eta=bounds_eta,
                method=inner_method,
                ftol=inner_ftol,
                verbose=verbose_inner,
            )

            # Résultat interne : RMSRE associée au candidat outer
            rmsre = float(res_in.fun)
            print(f"  -> inner best: sigma={sigma_opt:.6f}, eta={eta_opt:.6f}, RMSRE={rmsre:.5e}")

            # Mise à jour du meilleur à date
            improved = rmsre < best_rmsre
            if improved:
                best_rmsre = rmsre

            # --- progress: fin d’un candidat ---
            if self.progress_cb is not None:
                try:
                    self.progress_cb(
                        {
                            "stage": "outer_done",
                            "outer_idx": int(idx),
                            "outer_total": int(outer_total),
                            "a": float(a),
                            "b": float(b),
                            "rho": float(rho),
                            "cand_rmsre": float(rmsre),
                            "best_rmsre": float(best_rmsre),
                            "improved": bool(improved),
                        }
                    )
                except Exception:
                    pass

            # Stocke le candidat complet (utile pour ranking + top_k)
            results.append(
                {
                    "a": a,
                    "b": b,
                    "rho": rho,
                    "sigma": sigma_opt,
                    "eta": eta_opt,
                    "rmsre": rmsre,
                    "inner_result": res_in,
                }
            )

        # Trie tous les candidats par erreur croissante
        results.sort(key=lambda d: d["rmsre"])
        best = results[0]

        # Fixe les paramètres finaux (best) dans le modèle
        self._set_params(best["a"], best["b"], best["rho"], best["sigma"], best["eta"])

        # Résumé final console
        print("\n=== Résultat calibration profilé (best) ===")
        print(f"RMSRE: {best['rmsre']:>+8.3%}")
        print("Paramètres:")
        print(f"  a    : {best['a']:.6f}")
        print(f"  b    : {best['b']:.6f}")
        print(f"  rho  : {best['rho']:+.6f}")
        print(f"  sigma: {best['sigma']:.6f}")
        print(f"  eta  : {best['eta']:.6f}")

        print("\nRapport par instrument:")

        # Recalcule Q's pour le meilleur (a,b) afin de produire le report
        Qaa_best, Qbb_best, Qab_best = self._compute_Qs_for_outer(best["a"], best["b"])

        rho = best["rho"]
        sigma = best["sigma"]
        eta = best["eta"]

        # Rapport instrument par instrument : compare modèle vs marché
        for k, ins in enumerate(self._instr):
            model_pv = self._price_swaption_from_Qs(ins, rho, sigma, eta, Qaa_best[k], Qbb_best[k], Qab_best[k])

            # Applique la même convention que dans l’objectif (PV vs prime forward)
            if self.use_forward_premium:
                model_val = model_pv / (ins["DF"] + 1e-18)
            else:
                model_val = model_pv

            mkt = ins["mkt"]
            dif = model_val / (mkt + 1e-12) - 1.0

            Tau = ins["Tau"]
            print(
                f"Swaption {k:>3}: {Tau[0]:>5.2f}Y à {Tau[-1]:<5.2f}Y | "
                f"Modèle: {model_val:>10.4f} | Marché: {mkt:>10.4f} | Diff: {dif:>+8.3%}"
            )

        # Affiche un mini-classement des top_k meilleurs candidats 
        if top_k and top_k > 1:
            print(f"\nTop {min(top_k, len(results))} candidats:")
            for j in range(min(top_k, len(results))):
                r = results[j]
                print(
                    f"  {j+1:>2}. a={r['a']:.4f}, b={r['b']:.4f}, rho={r['rho']:+.2f} | "
                    f"sigma={r['sigma']:.5f}, eta={r['eta']:.5f} | RMSRE={r['rmsre']:.5e}"
                )

        # Retourne le meilleur + le ranking complet 
        return {"best": best, "ranking": results}


### FILE: ir\calibration\vol.py
from scipy.optimize import minimize, brentq
import numpy as np
from scipy.stats import norm
import itertools


# ----------------------------
# Vol implicite Bachelier (normal) à partir d'un prix
# ----------------------------
def black_normal_vol(price, forward, strike, expiry, notional, annuity):
    """
    Calcule la volatilité implicite normale (Bachelier) à partir d'un prix de marché
    (swaption ou caplet).

    Conventions
    ----------
    - forward et strike sont supposés fournis en % (ex: 3.25), puis convertis en taux (0.0325).
    - La volatilité sigma retournée est une volatilité normale "en taux" puis convertie en bps.

    Paramètres
    ----------
    price : float
        Prix de marché (PV) de l'instrument.
    forward : float
        Taux forward (swap rate forward ou forward caplet), exprimé en %.
    strike : float
        Strike, exprimé en %.
    expiry : float
        Maturité/échéance en années (T).
    notional : float
        Nominal de l'instrument.
    annuity : float
        Facteur d'annuité (souvent somme des DF * accruals pour swaptions),
        ou DF*yearfrac pour un caplet, selon ta convention de pricing.

    Retourne
    --------
    float
        Volatilité implicite normale en basis points (bps).
    """
    # Conversion : % -> taux décimaux
    forward = forward / 100.0
    strike = strike / 100.0

    def bachelier_price(sigma):
        """
        Prix Bachelier (normal model) pour une option de type call sur taux :
          PV = annuity * notional * [ (F-K) * N(d) + sigma*sqrt(T) * n(d) ]
        avec d = (F-K)/(sigma*sqrt(T))

        Remarque : ici on ne gère pas explicitement payer/receiver (w),
        on est sur la formule "call" standard (payer swaption).
        """
        # Sécurité : vol <= 0 => prix nul (pour éviter divisions par zéro)
        if sigma <= 0:
            return 0.0

        # d de Bachelier
        d = (forward - strike) / (sigma * np.sqrt(expiry))

        # Prix modèle (PV)
        price_model = annuity * notional * (
            (forward - strike) * norm.cdf(d)
            + sigma * np.sqrt(expiry) * norm.pdf(d)
        )
        return float(price_model)

    def objective(sigma):
        """
        Équation d'inversion : on cherche sigma tel que
        bachelier_price(sigma) = price  <=> objective(sigma) = 0
        """
        return bachelier_price(sigma) - price

    # Bornes raisonnables pour sigma en "taux" (unités décimales).
    # 1e-6 évite les divisions par zéro ; 5.0 est volontairement large.
    try:
        sigma_normal = brentq(objective, 1e-6, 5.0)
    except ValueError as e:
        sigma_normal = np.nan
        print(f"Warning: Impossible de résoudre la vol implicite : {e}")

    # Conversion taux -> bps : 1.0 = 10000 bps
    return sigma_normal * 10000.0


### FILE: ir\instruments\base.py
# -*- coding: utf-8 -*-
"""
ir/instruments/base.py

Couche "métier" :
- Instrument (base) : wrapper pour pricing (sans toucher aux formules)
- QuoteSet : encapsule un DataFrame et produit les dicts attendus par les calibrators
- SwaptionQuoteSet / CapletQuoteSet : implémentations concrètes

"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional, Any

import numpy as np
import pandas as pd


# -------------------------
# Instruments (base)
# -------------------------

@dataclass(frozen=True)
class Instrument:
    """
    Instrument abstrait : expose uniquement une API commune.

    Idée :
    - chaque instrument concret (caplet, swaption, swap, etc.) héritera de cette classe
    - il devra implémenter price(pricer) et déléguer le calcul à un pricer existant
    - on standardise juste l’interface
    """
    def price(self, pricer: Any) -> float:
        # Méthode à implémenter par les classes filles
        raise NotImplementedError


# -------------------------
# QuoteSets (calibration / comparaison)
# -------------------------

@dataclass
class QuoteSet:
    """
    Classe de base : "wrappe" un DataFrame et définit une interface standard.

    Hypothèse :
    - df contient au minimum les colonnes nécessaires (définies par les attributs *_col)
    - les classes filles fourniront des méthodes utilitaires (to_market_dict, pricing, etc.)
    """
    df: pd.DataFrame

    def copy_df(self) -> pd.DataFrame:
        # Copie profonde : évite les effets de bord quand on ajoute des colonnes (Model_Price, erreurs, etc.)
        return self.df.copy(deep=True)


@dataclass
class SwaptionQuoteSet(QuoteSet):
    """
    Wrapper pour un template de calibration swaptions.

    Colonnes requises (par défaut) :
      - price_col, strike_col, notional_col, dates_col
    Colonne optionnelle :
      - payer_col (bool) : True=payer, False=receiver

    Objectif :
    - fournir le dict EXACT attendu par les calibrators
    - fournir des helpers de comparaison modèle vs marché (1F et 2F)
    """
    price_col: str = "Price"
    strike_col: str = "Strike"
    notional_col: str = "Notional"
    dates_col: str = "Payment_Dates"
    payer_col: Optional[str] = None

    def to_market_dict(self) -> dict:
        """
        Produit le dict EXACT attendu par les calibrators (1F et 2F profile) :
          - "Prices", "Strike", "Notional", "Dates" (+ éventuellement "Payer")

        Important :
        - Strike est gardé en % (ex: 3.0) car les calibrators font eux-mêmes /100.
        - Dates doit être une liste de listes (list[list[float]]).
        """
        # Conversion explicite en float pour éviter des types pandas/numpy inattendus
        d = {
            "Prices": self.df[self.price_col].astype(float).tolist(),
            "Strike": self.df[self.strike_col].astype(float).tolist(),
            "Notional": self.df[self.notional_col].astype(float).tolist(),
            "Dates": self.df[self.dates_col].tolist(),  # list[list[float]]
        }

        # Ajoute le flag payer si la colonne est fournie et existe
        if self.payer_col and self.payer_col in self.df.columns:
            d["Payer"] = self.df[self.payer_col].astype(bool).tolist()

        return d

    # ---- comparaison mkt vs modèle (pricing) ---- #

    def with_model_prices_1f(
        self,
        pricer: Any,
        forward_premium: bool = True,
        payer_default: bool = True
    ) -> pd.DataFrame:
        """
        Calcule les prix modèle pour toutes les lignes en utilisant un pricer HW1F.

        Convention :
        - Si forward_premium=True : retourne PV / DF(T0)
          (cohérent avec le notebook et la convention de calibration swaptions 1F)
        - Sinon : retourne PV directement

        Sortie :
        - Ajoute deux colonnes :
          * "Model_Price" : prix modèle selon la convention choisie
          * "Rel_Error"   : erreur relative (Model/Market - 1)
        """
        out = self.copy_df()
        model_prices = []

        # Boucle sur chaque swaption (ligne du DataFrame)
        for i in range(len(out)):
            # Dates du swap sous-jacent (T0, ..., Tn)
            Tau = out.loc[i, self.dates_col]

            # Notional
            N = float(out.loc[i, self.notional_col])

            # Strike (% -> taux)
            K = float(out.loc[i, self.strike_col]) / 100.0

            # Détermine payer/receiver : par défaut payer, sinon lecture depuis colonne
            payer = payer_default
            if self.payer_col and self.payer_col in out.columns:
                payer = bool(out.loc[i, self.payer_col])

            # PV modèle (swaption) via pricer 1F
            pv = float(pricer.swaption(Tau, N, K, payer=payer))

            # Conversion éventuelle PV -> prime forward (division par DF(T0))
            if forward_premium:
                T0 = float(Tau[0])
                df0 = float(pricer.curve.discount(T0))
                model_prices.append(pv / (df0 + 1e-18))
            else:
                model_prices.append(pv)

        # Ajout des colonnes de sortie
        out["Model_Price"] = model_prices

        # Erreur relative stabilisée (évite div par 0)
        out["Rel_Error"] = out["Model_Price"] / (out[self.price_col].astype(float) + 1e-12) - 1.0
        return out

    def with_model_prices_2f(
        self,
        pricer2f: Any,
        forward_premium: bool = True,
        payer_default: bool = True
    ) -> pd.DataFrame:
        """
        Calcule les prix modèle pour toutes les lignes avec un pricer HW2F (approx gaussienne).

        Méthode utilisée :
          pv = pricer2f.swaption_approx_hw2f(Tau, N, K, payer=?)

        Convention :
        - Si forward_premium=True : retourne PV / DF(T0)
        - Sinon : retourne PV

        Sortie :
        - Ajoute :
          * "Model_Price"
          * "Rel_Error"
        """
        out = self.copy_df()
        model_prices = []

        # Boucle sur les instruments
        for i in range(len(out)):
            Tau = out.loc[i, self.dates_col]
            N = float(out.loc[i, self.notional_col])
            K = float(out.loc[i, self.strike_col]) / 100.0

            payer = payer_default
            if self.payer_col and self.payer_col in out.columns:
                payer = bool(out.loc[i, self.payer_col])

            # PV modèle via approximation HW2F
            pv = float(pricer2f.swaption_approx_hw2f(Tau, N, K, payer=payer))

            # Conversion PV -> prime forward si demandé
            if forward_premium:
                T0 = float(Tau[0])
                df0 = float(pricer2f.curve.discount(T0))
                model_prices.append(pv / (df0 + 1e-18))
            else:
                model_prices.append(pv)

        out["Model_Price"] = model_prices
        out["Rel_Error"] = out["Model_Price"] / (out[self.price_col].astype(float) + 1e-12) - 1.0
        return out


@dataclass
class CapletQuoteSet(QuoteSet):
    """
    Wrapper pour un template de calibration caplets.

    Colonnes requises (par défaut) :
      - price_col, strike_col, notional_col, expiry_col, maturity_col

    Les calibrators attendent le dict :
      Prices, Strike, Notional, Expiry, Maturity
    """
    price_col: str = "Price"
    strike_col: str = "Strike"
    notional_col: str = "Notional"
    expiry_col: str = "Expiry"
    maturity_col: str = "Maturity"

    def to_market_dict(self) -> dict:
        """
        Produit le dict attendu par le calibrator 1F pour caplets.

        Important :
        - Strike est gardé en % car le calibrator fait /100 en interne.
        """
        return {
            "Prices": self.df[self.price_col].astype(float).tolist(),
            "Strike": self.df[self.strike_col].astype(float).tolist(),
            "Notional": self.df[self.notional_col].astype(float).tolist(),
            "Expiry": self.df[self.expiry_col].astype(float).tolist(),
            "Maturity": self.df[self.maturity_col].astype(float).tolist(),
        }

    def with_model_prices_1f(self, pricer: Any) -> pd.DataFrame:
        """
        Calcule les PV modèle des caplets via HW1F :
          PV = pricer.caplet(T1, T2, N, K)

        Sortie :
        - Ajoute :
          * "Model Price"
          * "Rel_Error"
        """
        out = self.copy_df()
        model_prices = []

        # Boucle sur les caplets (ligne par instrument)
        for i in range(len(out)):
            T1 = float(out.loc[i, self.expiry_col])
            T2 = float(out.loc[i, self.maturity_col])
            N = float(out.loc[i, self.notional_col])
            K = float(out.loc[i, self.strike_col]) / 100.0

            # Prix modèle caplet
            model_prices.append(float(pricer.caplet(T1, T2, N, K)))

        out["Model Price"] = model_prices
        out["Rel_Error"] = out["Model Price"] / (out[self.price_col].astype(float) + 1e-12) - 1.0
        return out

    def with_model_prices_2f(self, pricer2f: Any) -> pd.DataFrame:
        """
        Calcule les PV modèle des caplets via HW2F :
          PV = pricer2f.caplet_hw2f(T1, T2, N, K)

        Sortie :
        - Ajoute :
          * "Model Price"
          * "Rel_Error"
        """
        out = self.copy_df()
        model_prices = []

        for i in range(len(out)):
            T1 = float(out.loc[i, self.expiry_col])
            T2 = float(out.loc[i, self.maturity_col])
            N = float(out.loc[i, self.notional_col])
            K = float(out.loc[i, self.strike_col]) / 100.0

            # Prix modèle caplet 2F
            model_prices.append(float(pricer2f.caplet_hw2f(T1, T2, N, K)))

        out["Model Price"] = model_prices
        out["Rel_Error"] = out["Model Price"] / (out[self.price_col].astype(float) + 1e-12) - 1.0
        return out


# -------------------------
# util simple
# -------------------------

def worst_rows_by_abs_relerr(df: pd.DataFrame, relerr_col: str = "Rel_Error", n: int = 10) -> pd.DataFrame:
    """
    Renvoie les n lignes avec les plus grosses erreurs relatives en valeur absolue.

    Utile pour diagnostiquer une calibration/pricing :
    - on repère rapidement les instruments les plus mal "fit"
    - on peut ensuite inspecter leurs caractéristiques (maturité, strike, etc.)

    Paramètres
    ----------
    df : pd.DataFrame
        DataFrame contenant au moins la colonne relerr_col.
    relerr_col : str
        Nom de la colonne d’erreur relative (par défaut "Rel_Error").
    n : int
        Nombre de lignes à renvoyer.

    Retourne
    --------
    pd.DataFrame
        Sous-ensemble trié par erreur absolue décroissante.
    """
    out = df.copy()
    out["AbsRelErr"] = np.abs(out[relerr_col].astype(float))
    return out.sort_values("AbsRelErr", ascending=False).head(int(n))


### FILE: ir\instruments\rates.py
# -*- coding: utf-8 -*-
"""
ir/instruments/rates.py

Instruments IR : wrappers "POO" qui délèguent aux pricers existants.

Idée :
- uniformiser le pricing (instrument.price(pricer))
- construire des portfolios (list[Instrument])

"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Sequence

from ir.instruments.base import Instrument


@dataclass(frozen=True)
class Caplet(Instrument):
    """
    Caplet (un seul coupon de cap) défini par :
    - période [T1, T2]
    - nominal N
    - strike K (en taux, ex 0.03)

    Objectif :
    - fournir une interface unique Instrument.price(pricer)
    - déléguer au pricer 1F ou 2F selon ce qui est disponible
    """
    T1: float
    T2: float
    N: float
    K: float  # en taux (0.03)

    def price(self, pricer: Any) -> float:
        # Si le pricer expose une méthode 2F dédiée, on l'utilise
        # Sinon, fallback sur la méthode 1F.
        if hasattr(pricer, "caplet_hw2f"):
            return float(pricer.caplet_hw2f(self.T1, self.T2, self.N, self.K))
        return float(pricer.caplet(self.T1, self.T2, self.N, self.K))


@dataclass(frozen=True)
class Floorlet(Instrument):
    """
    Floorlet (un seul coupon de floor) défini par :
    - période [T1, T2]
    - nominal N
    - strike K

    """
    T1: float
    T2: float
    N: float
    K: float

    def price(self, pricer: Any) -> float:
        # Si une méthode 2F explicite existe, on la privilégie
        if hasattr(pricer, "floorlet_hw2f"):
            return float(pricer.floorlet_hw2f(self.T1, self.T2, self.N, self.K))

        # Sinon, on appelle le pricer.floor sur 2 dates pour représenter un seul coupon
        Tau = [float(self.T1), float(self.T2)]
        return float(pricer.floor(Tau, self.N, self.K))


@dataclass(frozen=True)
class Cap(Instrument):
    """
    Cap (ensemble de caplets) défini par :
    - Tau : séquence de dates [T0, T1, ..., Tn]
    - nominal N
    - strike K

    Remarque :
    - Délègue à pricer.cap (1F) ou pricer.cap_hw2f (2F) si disponible.
    """
    Tau: Sequence[float]
    N: float
    K: float

    def price(self, pricer: Any) -> float:
        # Si le pricer 2F existe, on l'utilise
        if hasattr(pricer, "cap_hw2f"):
            return float(pricer.cap_hw2f(list(self.Tau), self.N, self.K))
        # Sinon 1F
        return float(pricer.cap(list(self.Tau), self.N, self.K))


@dataclass(frozen=True)
class Floor(Instrument):
    """
    Floor (ensemble de floorlets) défini par :
    - Tau : séquence de dates [T0, T1, ..., Tn]
    - nominal N
    - strike K

    Remarque :
    - Délègue à pricer.floor (1F) ou pricer.floor_hw2f (2F) si disponible.
    """
    Tau: Sequence[float]
    N: float
    K: float

    def price(self, pricer: Any) -> float:
        # Si le pricer 2F existe, on l'utilise
        if hasattr(pricer, "floor_hw2f"):
            return float(pricer.floor_hw2f(list(self.Tau), self.N, self.K))
        # Sinon 1F
        return float(pricer.floor(list(self.Tau), self.N, self.K))


@dataclass(frozen=True)
class Swap(Instrument):
    """
    Swap vanilla (jambe fixe vs flottante) défini par :
    - Tau : séquence de dates [T0, T1, ..., Tn] (échéances de paiement)
    - nominal N
    - taux fixe K
    - payer : True si payer fixe / receive float, False sinon

    Note :
    - Ici, on suppose que pricer.swap est disponible et gère payer/receiver.
    """
    Tau: Sequence[float]
    N: float
    K: float
    payer: bool = True

    def price(self, pricer: Any) -> float:
        # Délégation directe : aucun calcul ici
        return float(pricer.swap(list(self.Tau), self.N, self.K, payer=self.payer))


@dataclass(frozen=True)
class Swaption(Instrument):
    """
    Swaption (option sur swap) définie par :
    - Tau : dates du swap sous-jacent [T0, T1, ..., Tn]
    - nominal N
    - strike K
    - payer : True (payer swaption) ou False (receiver swaption)
    - forward_premium : si True, retourne PV / DF(T0) pour coller à la convention de calibration

    Remarque :
    - Si un pricer 2F approx est disponible (swaption_approx_hw2f), on l'utilise.
    - Sinon, fallback sur pricer.swaption (1F).
    """
    Tau: Sequence[float]
    N: float
    K: float
    payer: bool = True
    forward_premium: bool = True  # pour matcher le notebook/calibration

    def price(self, pricer: Any) -> float:
        Tau = list(self.Tau)

        # --- Cas 2F : pricer expose une approximation gaussienne dédiée ---
        if hasattr(pricer, "swaption_approx_hw2f"):
            # PV 2F approx
            pv = float(pricer.swaption_approx_hw2f(Tau, self.N, self.K, payer=self.payer))

            # Optionnel : conversion PV -> prime forward (division par DF(T0))
            if self.forward_premium:
                df0 = float(pricer.curve.discount(float(Tau[0])))
                return pv / (df0 + 1e-18)
            return pv

        # --- Cas 1F : méthode swaption "classique" ---
        pv = float(pricer.swaption(Tau, self.N, self.K, payer=self.payer))

        # Optionnel : conversion PV -> prime forward (même convention que ci-dessus)
        if self.forward_premium:
            df0 = float(pricer.curve.discount(float(Tau[0])))
            return pv / (df0 + 1e-18)
        return pv


### FILE: ir\market\curve.py
from scipy.interpolate import interp1d
from scipy.interpolate import UnivariateSpline
import numpy as np


class Curve:
    """
    Classe pour manipuler une courbe de marché, notamment :
    - les facteurs d’actualisation P(0,t)
    - les taux forwards instantanés f(0,t)
    avec :
    - interpolation cubique des discount factors
    - spline (lissée) sur log(P(0,t)) pour dériver un forward instantané stable
    """

    def __init__(self, time, discount_factors, smooth=1e-7):
        """
        Initialise une courbe de marché (discount curve) et construit en même temps
        les objets d’interpolation nécessaires.

        Paramètres
        ----------
        time : array_like
            Maturités (en années) des nœuds de la courbe.
        discount_factors : array_like
            Facteurs d’actualisation P(0, T) aux maturités fournies.
        smooth : float, optionnel
            Paramètre de lissage de la spline sur log(P).
        """
        self.time = np.array(time)
        self.discount_factors = np.array(discount_factors)
        self.smooth = smooth

        # Construction des interpolateurs (DF + spline de forwards instantanés)
        self._build_interpolators()

    def _build_interpolators(self):
        """
        Construit en une fois :
        1) une fonction d’interpolation des discount factors P(0,t)
        2) une spline sur ln(P(0,t)) permettant d’obtenir f(0,t) par dérivation

        Pourquoi une spline sur ln(P) ?
        -------------------------------
        En théorie :
          f(0,t) = - d/dt ln P(0,t)
        Donc si on approxime ln(P) par une spline suffisamment régulière,
        la dérivée donne un forward instantané plus stable numériquement.
        """

        self.discount_func = interp1d(
            self.time,
            self.discount_factors,
            kind="cubic",
            fill_value="extrapolate",
            bounds_error=False,
        )

        lnP = np.log(self.discount_factors)
        self.forward_spline = UnivariateSpline(self.time, lnP, s=self.smooth)

    def discount(self, t):
        """
        Retourne le facteur d’actualisation interpolé P(0,t).

        Paramètres
        ----------
        t : float ou array_like
            Temps / maturité(s) en années.

        Retourne
        --------
        float ou np.ndarray
            Valeur(s) P(0,t) interpolée(s).
        """
        return self.discount_func(t)

    def inst_forward_rate(self, t):
        """
        Retourne le taux forward instantané interpolé f(0,t).

        Formule
        -------
          f(0,t) = - d/dt ln P(0,t)

        Paramètres
        ----------
        t : float ou array_like
            Temps / maturité(s) en années.

        Retourne
        --------
        float ou np.ndarray
            Valeur(s) du forward instantané.
        """
        t = np.array(t)

        return -self.forward_spline.derivative(1)(t)

    def forward_rate(self, T1, T2):
        """
        Calcule le taux forward simple F(0; T1, T2) implicite de la courbe de DF.

        Convention (forward simple)
        ---------------------------
          F(0;T1,T2) = ( P(0,T1)/P(0,T2) - 1 ) / (T2 - T1)

        Paramètres
        ----------
        T1 : float
            Début de la période.
        T2 : float
            Fin de la période.

        Retourne
        --------
        float
            Taux forward simple entre T1 et T2.
        """
        # Récupération des DF interpolés
        P1 = self.discount(T1)
        P2 = self.discount(T2)

        # Application de la formule du forward simple (suppose T2 > T1)
        return (P1 / P2 - 1.0) / (T2 - T1)


### FILE: ir\market\loaders_excel.py
# -*- coding: utf-8 -*-
"""
ir/market/loaders_excel.py

Loaders Excel -> objets "propres" (Curve + QuoteSets) pour notebooks.

Usage typique notebook :
    curve = load_curve_xlsx(path)
    swpn = load_swaption_template_xlsx(path)
    market_dict = swpn.to_market_dict()
"""

from __future__ import annotations

import ast
from typing import Optional
import pandas as pd
from ir.market.curve import Curve
from ir.instruments.base import SwaptionQuoteSet, CapletQuoteSet



def _parse_list_cell(x) -> list[float]:
    """
    Parse une cellule Excel supposée contenir une liste de dates (year fractions).

    Retourne
    --------
    list[float]

    Erreurs
    -------
    - ValueError si la cellule ne peut pas être interprétée comme une liste de floats.
    """
    # Cas 1 : déjà une liste/tuple (certains exports Excel ou pré-traitements peuvent faire ça)
    if isinstance(x, (list, tuple)):
        return [float(v) for v in x]

    # Cas 2 : string contenant une représentation de liste
    if isinstance(x, str):
        s = x.strip()
        if not s:
            return []
        try:
            obj = ast.literal_eval(s)
            if isinstance(obj, (list, tuple)):
                return [float(v) for v in obj]
        except Exception:
            pass

    # Fallback : format non reconnu
    raise ValueError(f"Format de dates de paiement non reconnu: {x!r}")


def load_curve_xlsx(
    path: str,
    sheet: str = "Curve",
    time_col: str = "Year_Frac",
    df_col: str = "Discount_Factor",
    smooth: float = 1e-7,
) -> Curve:
    """
    Lit une feuille Excel contenant les nœuds de courbe et construit un objet Curve.

    Paramètres
    ----------
    path : str
        Chemin du fichier Excel (.xlsx).
    sheet : str
        Nom de la feuille contenant la courbe (par défaut "Curve").
    time_col : str
        Colonne contenant les maturités en années (year fractions).
    df_col : str
        Colonne contenant les discount factors P(0,T).
    smooth : float
        Paramètre de lissage transmis à Curve (utilisé pour la spline des forwards instantanés).

    Retourne
    --------
    Curve
        Objet courbe (interpolation DF + spline forward).
    """
    # Lecture Excel (pandas gère l'engine automatiquement dans la plupart des cas)
    df = pd.read_excel(path, sheet_name=sheet)

    # Extraction + cast explicite en float (sécurité type)
    time = df[time_col].astype(float).values
    disc = df[df_col].astype(float).values

    # Construction de la courbe
    return Curve(time, disc, smooth=smooth)


def load_swaption_template_xlsx(
    path: str,
    sheet: str = "Template",
    payment_dates_col: str = "Payment_Dates",
    price_col: str = "Price",
    strike_col: str = "Strike",
    notional_col: str = "Notional",
    payer_col: Optional[str] = None,
) -> SwaptionQuoteSet:
    """
    Lit un fichier template de calibration swaptions (type SWPN_Calibration_Template_...xlsx)
    et retourne un SwaptionQuoteSet prêt à l’emploi.

    Colonnes attendues (minimum)
    ----------------------------
    - Price, Strike, Notional, Payment_Dates

    Optionnel
    ---------
    - Payer (bool) :
        * soit fourni via le paramètre payer_col (nom de colonne)
        * soit déjà présent dans le fichier sous le nom "Payer"

    """
    # Lecture de la feuille template
    df = pd.read_excel(path, sheet_name=sheet)

    if payment_dates_col in df.columns:
        df[payment_dates_col] = [_parse_list_cell(v) for v in df[payment_dates_col].tolist()]
    else:
        raise KeyError(f"Missing column '{payment_dates_col}' in {sheet}.")

    # --- Gestion du flag payer/receiver (optionnel) ---
    # Objectif : exposer une colonne standard "Payer" si possible
    if payer_col and payer_col in df.columns:
        # Si l'utilisateur indique une colonne, on la copie/normalise
        df["Payer"] = df[payer_col].astype(bool)
    elif "Payer" in df.columns:
        # Sinon, si la colonne s'appelle déjà "Payer", on la cast en bool
        df["Payer"] = df["Payer"].astype(bool)

    # Construction du QuoteSet avec la référence de colonnes
    return SwaptionQuoteSet(
        df=df,
        price_col=price_col,
        strike_col=strike_col,
        notional_col=notional_col,
        dates_col=payment_dates_col,
        payer_col=("Payer" if "Payer" in df.columns else None),
    )


def load_caplet_template_xlsx(
    path: str,
    sheet: str = "Template",
    drop_first_row_if_empty: bool = True,
    price_col: str = "Price",
    strike_col: str = "Strike",
    notional_col: str = "Notional",
    expiry_col: str = "Expiry",
    maturity_col: str = "Maturity",
) -> CapletQuoteSet:
    """
    Lit un fichier template de calibration caplets (type CAP_Calibration_Template_...xlsx)
    et retourne un CapletQuoteSet prêt à l’emploi.

    """
    # Lecture du template
    df = pd.read_excel(path, sheet_name=sheet)

    # Option : suppression heuristique de la première ligne si elle est "vide" sur les champs essentiels
    if drop_first_row_if_empty and len(df) >= 1:
        essentials = [price_col, strike_col, notional_col, expiry_col, maturity_col]
        # Petite protection : on ne lance l'heuristique que si au moins une colonne essentielle existe
        if any(col in df.columns for col in essentials):
            row0 = df.iloc[0]
            # On considère la ligne 0 "mauvaise" si toutes les colonnes essentielles sont NaN
            bad = True
            for col in essentials:
                if col in df.columns and pd.notna(row0[col]):
                    bad = False
                    break
            # Si la ligne 0 semble inutile, on la drop et on réindexe proprement
            if bad:
                df = df.iloc[1:, :].reset_index(drop=True)

    # Construction du QuoteSet caplets avec les colonnes configurées
    return CapletQuoteSet(
        df=df.reset_index(drop=True),
        price_col=price_col,
        strike_col=strike_col,
        notional_col=notional_col,
        expiry_col=expiry_col,
        maturity_col=maturity_col,
    )


def load_cap_market_data_xlsx(path: str) -> pd.DataFrame:
    """
    Lit un fichier de données de marché caplets OTM (type CAP_Market_Data_...xlsx)
    et renvoie le DataFrame tel quel.
    """
    return pd.read_excel(path)


### FILE: ir\market\plots.py
# -*- coding: utf-8 -*-
"""
ir/market/plots.py

Fonctions de plotting réutilisables dans notebooks.
But : garder le notebook lisible, en centralisant l'affichage.

Fonctions proposées :
- plot_curve(curve)
- plot_prices_by_tenor(df, ...)
- plot_vols_by_tenor(df, ...)
- plot_smile_by_expiry(df, ...)  (caplets OTM)
"""

from __future__ import annotations

from typing import Sequence, Optional

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


def plot_curve(curve, t_max: float = 30.0, n: int = 300, title_prefix: str = "Market") -> None:
    """
    Trace la courbe de marché :
    - à gauche : la courbe des discount factors P(0,t)
    - à droite : la courbe des forwards instantanés f(0,t)

    Paramètres
    ----------
    curve : objet Curve-like
    t_max : float
        Horizon maximal en années (par défaut 30 ans).
    n : int
        Nombre de points de discrétisation pour les courbes.
    title_prefix : str
        Préfixe ajouté au titre 
    """
    # Grille de temps
    t = np.linspace(0.01, float(t_max), int(n))

    # 2 panneaux côte à côte : DF et forward instantané
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    # --- Discount curve ---
    axes[0].plot(t, curve.discount(t), linewidth=2)
    axes[0].set_title(f"{title_prefix} Courbe d'actualisation", fontsize=14, fontweight="bold")
    axes[0].set_xlabel("Temps (Années)")
    axes[0].set_ylabel("Facteur d'actualisation")
    axes[0].grid(alpha=0.3)

    # --- Instantaneous forward curve ---
    axes[1].plot(t, curve.inst_forward_rate(t), linewidth=2)
    axes[1].set_title(f"{title_prefix} Taux forward instantané", fontsize=14, fontweight="bold")
    axes[1].set_xlabel("Temps (Années)")
    axes[1].set_ylabel("Taux")
    axes[1].grid(alpha=0.3)

    # Ajustements visuels
    plt.tight_layout()
    plt.show()


def plot_prices_by_tenor(
    df: pd.DataFrame,
    tenors: Optional[Sequence[float]] = None,
    tenor_col: str = "Tenor",
    x_col: str = "Expiry",
    mkt_col: str = "Price",
    model_col: str = "Model_Price",
    ylabel: str = "Forward Premium",
    title: str = "Swaption Price Term Structure",
) -> None:
    """
    Trace les prix (marché vs modèle) en fonction de l'expiry, pour plusieurs tenors.

    Usage typique :
    - df contient un ensemble de swaptions ATM
    - on veut comparer la term structure des prix pour des tenors fixes (5Y, 10Y, 20Y, 30Y)

    Paramètres
    ----------
    df : pd.DataFrame
        Doit contenir :
          - tenor_col (ex: "Tenor")
          - x_col (ex: "Expiry")
          - mkt_col (prix marché)
          - model_col (prix modèle)
    tenors : list[float] | None
        Tenors à afficher. Si None, valeurs par défaut [5, 10, 20, 30].
    tenor_col : str
        Nom de la colonne identifiant le tenor.
    x_col : str
        Nom de la colonne en abscisse (souvent Expiry).
    mkt_col : str
        Nom de la colonne prix marché.
    model_col : str
        Nom de la colonne prix modèle.
    ylabel : str
        Label axe Y (ex: "Forward Premium" si tu compares PV/DF(T0)).
    title : str
        Titre générique (complété par le tenor).
    """
    # Tenors par défaut si non fournis
    if tenors is None:
        tenors = [5.0, 10.0, 20.0, 30.0]

    # Layout 2x2 adapté au cas standard de 4 tenors
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    axes = axes.flatten()

    # Boucle sur les tenors à afficher
    for idx, tenor in enumerate(tenors):
        ax = axes[idx]
        dft = df[df[tenor_col] == tenor].copy()
        if len(dft) == 0:
            ax.set_axis_off()
            continue
        dft = dft.sort_values(x_col)

        # Courbe marché vs modèle
        ax.plot(dft[x_col], dft[mkt_col], linewidth=2, label="Marché")
        ax.plot(dft[x_col], dft[model_col], linestyle="--", linewidth=2, label="Modèle")

        # Mise en forme
        ax.set_title(f"{title} (ATM, {int(tenor)}Y Tenor)", fontsize=13, fontweight="bold")
        ax.set_xlabel("Maturité (Années)")
        ax.set_ylabel(ylabel)
        ax.grid(True, alpha=0.3)
        ax.legend()

    plt.tight_layout()
    plt.show()


def plot_vols_by_tenor(
    df: pd.DataFrame,
    tenors: Optional[Sequence[float]] = None,
    tenor_col: str = "Tenor",
    x_col: str = "Expiry",
    mkt_col: str = "Volatility (Bps)",
    model_col: str = "Model_Vol (Bps)",
    ylabel: str = "Normal Vol (Bps)",
    title: str = "Swaption Vol Term Structure",
) -> None:
    """
    Trace les volatilités normales (marché vs modèle) en fonction de l'expiry,
    pour plusieurs tenors.

    Usage typique :
    - df contient des vols implicites en bps (Bachelier) pour des swaptions ATM
    - on veut vérifier que le modèle reproduit bien la term structure des vols

    Paramètres
    ----------
    df : pd.DataFrame
        Doit contenir :
          - tenor_col, x_col
          - mkt_col : volatilité marché (en bps)
          - model_col : volatilité modèle (en bps)
    tenors : list[float] | None
        Tenors à afficher. Si None, valeurs par défaut [5, 10, 20, 30].
    tenor_col : str
        Colonne tenor.
    x_col : str
        Colonne expiry (abscisse).
    mkt_col : str
        Colonne vol marché.
    model_col : str
        Colonne vol modèle.
    ylabel : str
        Label axe Y.
    title : str
        Titre générique (complété par le tenor).
    """
    if tenors is None:
        tenors = [5.0, 10.0, 20.0, 30.0]

    # Layout 2x2 adapté au cas standard de 4 tenors
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    axes = axes.flatten()

    for idx, tenor in enumerate(tenors):
        ax = axes[idx]
        dft = df[df[tenor_col] == tenor].copy()
        if len(dft) == 0:
            ax.set_axis_off()
            continue
        dft = dft.sort_values(x_col)

        ax.plot(dft[x_col], dft[mkt_col], linewidth=2, label="Marché")
        ax.plot(dft[x_col], dft[model_col], linestyle="--", linewidth=2, label="Modèle")

        ax.set_title(f"{title} (ATM, {int(tenor)}Y Tenor)", fontsize=13, fontweight="bold")
        ax.set_xlabel("Maturité (Années)")
        ax.set_ylabel(ylabel)
        ax.grid(True, alpha=0.3)
        ax.legend()

    plt.tight_layout()
    plt.show()


def plot_smile_by_expiry(
    df: pd.DataFrame,
    expiry_col: str = "Expiry",
    x_col: str = "Moneyness",
    mkt_col: str = "Volatility (Bps)",
    model_col: str = "Model Vol",
    n_panels: int = 4,
    title_prefix: str = "Caplet Smile",
) -> None:
    """
    Trace des smiles (caplets OTM) en regroupant par expiry.

    Données attendues
    -----------------
    df doit contenir au moins :
      - expiry_col : maturité (Expiry)
      - x_col : moneyness (souvent en % ou en bps selon le format)
      - mkt_col : vol implicite marché (en bps)
      - model_col : vol implicite modèle (même unité que mkt_col)

    Paramètres
    ----------
    expiry_col : str
        Colonne identifiant l'expiry.
    x_col : str
        Colonne en abscisse (moneyness).
    mkt_col : str
        Colonne vol marché.
    model_col : str
        Colonne vol modèle.
    n_panels : int
        Nombre de panneaux (expiries) à afficher, en choisissant des expiries "réparties".
    title_prefix : str
        Préfixe de titre (utile si plusieurs types de smiles).
    """
    # Liste triée des expiries disponibles
    expiries = np.sort(df[expiry_col].dropna().unique())
    if len(expiries) == 0:
        raise ValueError("Pas de maturités trouvés pour le graphique du smile.")

    n_panels = int(n_panels)

    if len(expiries) >= n_panels:
        exp_indices = np.linspace(0, len(expiries) - 1, n_panels, dtype=int)
    else:
        exp_indices = np.arange(len(expiries))

    # Layout 
    if len(exp_indices) <= 4:
        nrows, ncols = 2, 2
    else:
        ncols = int(np.ceil(np.sqrt(len(exp_indices))))
        nrows = int(np.ceil(len(exp_indices) / ncols))

    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 8))
    axs = np.array(axs).reshape(-1)

    # Tracé panneau par panneau
    for k, idx in enumerate(exp_indices):
        ax = axs[k]
        expiry = expiries[idx]
        mask = df[expiry_col] == expiry
        dft = df[mask].sort_values(x_col)

        # Tracé marché vs modèle
        ax.plot(dft[x_col], dft[mkt_col], linewidth=2, label="Smile Marché")
        ax.plot(dft[x_col], dft[model_col], linestyle="--", linewidth=2, label="Smile Modèle")

        # Mise en forme
        ax.set_title(f"{title_prefix} | Maturité: {expiry:.2f}Y", fontsize=12, fontweight="bold")
        ax.set_xlabel("Moneyness (%)")
        ax.set_ylabel("Vol Impli (Bps)")
        ax.grid(alpha=0.3)
        ax.legend(fontsize=9)

    for j in range(len(exp_indices), len(axs)):
        axs[j].set_axis_off()

    plt.tight_layout()
    plt.show()


### FILE: ir\models\hw1f.py
import pandas as pd
import numpy as np


class HullWhiteModel:
    """
    Modèle de taux court Hull–White 1 facteur

    Cette classe implémente les formules analytiques du modèle de Vasicek étendu / Hull–White :
        dr(t) = a * (θ(t) - r(t)) dt + σ dW(t)
    où :
        a     = vitesse de retour à la moyenne (mean reversion)
        σ     = volatilité du taux court
        θ(t)  = drift déterministe (dépendant du temps) ajusté pour coller à la courbe initiale

    Attributs
    ---------
    curve : Curve
        Instance représentant la courbe d'actualisation initiale P(0,T).
    parameters : dict
        Dictionnaire de paramètres du modèle :
            - 'a' : float, vitesse de retour à la moyenne
            - 'sigma' : float, volatilité
            - 'r0' : float, taux court initial
    """

    def __init__(self, curve, parameters=None):
        """
        Initialise le modèle Hull–White à partir d'une courbe de discount et d'un jeu de paramètres.

        Paramètres
        ----------
        curve : Curve
            Courbe d'actualisation utilisée pour obtenir P(0,t) et f(0,t).
        parameters : dict, optionnel
            Dictionnaire optionnel avec les clés 'a', 'sigma', 'r0'.
            Si None, on utilise des valeurs par défaut :
              - a = 0.01
              - sigma = 0.01
              - r0 = curve.inst_forward_rate(0)
        """
        self.curve = curve

        # Valeurs par défaut : permettent un "quick start" sans calibration
        defaults = {"a": 0.01, "sigma": 0.01, "r0": curve.inst_forward_rate(0)}

        if parameters is None:
            parameters = {}

        # Construction du dict final (avec fallback sur defaults si clé absente)
        self.parameters = {
            "a": parameters.get("a", defaults["a"]),
            "sigma": parameters.get("sigma", defaults["sigma"]),
            "r0": parameters.get("r0", defaults["r0"]),
        }

    def inst_forward_rate(self, t):
        """
        Renvoie le taux forward instantané f(0,t) (dérivé de la courbe).

        Paramètres
        ----------
        t : float
            Temps (en années).

        Retourne
        --------
        float
            f(0,t) à la date t.
        """
        # Délégation directe à la courbe
        return self.curve.inst_forward_rate(t)

    def discount_factor(self, t):
        """
        Renvoie le facteur d'actualisation P(0,t) (interpolé via la courbe).

        Paramètres
        ----------
        t : float
            Temps (en années).

        Retourne
        --------
        float
            P(0,t).
        """
        # Délégation directe à la courbe
        return self.curve.discount(t)

    def forward_rate(self, T1, T2):
        """
        Renvoie le taux forward simple F(0; T1, T2) implicite de la courbe.

        Convention (forward simple) :
          F(0;T1,T2) = ( P(0,T1)/P(0,T2) - 1 ) / (T2 - T1)

        Paramètres
        ----------
        T1 : float
            Début de la période.
        T2 : float
            Fin de la période.

        Retourne
        --------
        float
            Taux forward entre T1 et T2.
        """
        return self.curve.forward_rate(T1, T2)

    def alpha(self, t):
        """
        Calcule α(t), la fonction de décalage déterministe dans Hull–White.

        Formule :
            α(t) = f(0,t) + (σ² / (2a²)) * (1 - e^{-a t})²

        Interprétation :
        - α(t) intervient dans l'expression de l'espérance de r(t)
        - elle "force" le modèle à coller à la courbe initiale

        Paramètres
        ----------
        t : float
            Temps (en années).

        Retourne
        --------
        float
            Valeur α(t).
        """
        a = self.parameters["a"]
        sigma = self.parameters["sigma"]
        fwd = self.inst_forward_rate(t)

        return fwd + (sigma**2) / (2 * a**2) * (1 - np.exp(-a * t)) ** 2

    def B(self, t, T):
        """
        Calcule la fonction B(t,T) utilisée dans le pricing des ZC bonds en HW.

        Formule :
            B(t,T) = (1 - e^{-a (T - t)}) / a

        Paramètres
        ----------
        t : float
            Temps courant.
        T : float
            Maturité.

        Retourne
        --------
        float
            Valeur B(t,T).
        """
        a = self.parameters["a"]
        return (1 - np.exp(-a * (T - t))) / a

    def A(self, t, T):
        """
        Calcule la fonction A(t,T) utilisée dans le pricing des obligations zéro-coupon.

        Formule :
            A(t,T) = [P(0,T)/P(0,t)] * exp( B(t,T)*f(0,t)
                     - (σ²/(4a))*(1 - e^{-2at})*B(t,T)² )

        Paramètres
        ----------
        t : float
            Temps courant.
        T : float
            Maturité.

        Retourne
        --------
        float
            Valeur A(t,T).
        """
        a = self.parameters["a"]
        sigma = self.parameters["sigma"]

        # Facteurs d'actualisation initiaux
        P_t = self.discount_factor(t)
        P_T = self.discount_factor(T)

        # Forward instantané à t
        fwd = self.inst_forward_rate(t)

        # Fonction B(t,T)
        B = self.B(t, T)

        # Formule fermée pour A(t,T)
        return (P_T / P_t) * np.exp(
            B * fwd - (sigma**2 / (4 * a)) * (1 - np.exp(-2 * a * t)) * B**2
        )

    def short_rate(self, t, z=None):
        """
        Simule r(t) sous la mesure risque-neutre via la distribution exacte.

        Propriété clé (HW1F gaussian) :
            r(t) ~ Normal( E[r(t)], V[r(t)] )

        Paramètres
        ----------
        t : float
            Temps (en années).
        z : float, optionnel
            Tirage N(0,1). Si None, un tirage est généré.

        Retourne
        --------
        float
            Une réalisation du taux court r(t).
        """
        # Génère un tirage standard normal si pas fourni
        if z is None:
            z = np.random.normal()

        r0 = self.parameters["r0"]
        a = self.parameters["a"]
        sigma = self.parameters["sigma"]

        # Variance exacte de r(t) en HW
        V = (sigma**2 / (2 * a)) * (1 - np.exp(-2 * a * t))

        # Espérance exacte de r(t) 
        # NB : alpha(t) dépend de la courbe initiale
        E = r0 * np.exp(-a * t) + self.alpha(t) - np.exp(-a * t) * self.alpha(0)

        # Construction de r(t) = E + sqrt(V)*z
        return E + np.sqrt(V) * z


class HullWhiteSimulation:
    """
    Moteur de simulation Monte Carlo pour Hull–White 1 facteur.

    Fournit :
      - simulation exacte de r(T) à une maturité 

    Attributs
    ---------
    model : HullWhiteModel
        Instance du modèle HW contenant courbe et paramètres.
    n_paths : int
        Nombre de scénarios Monte Carlo.
    n_steps : int
    seed : int
        Graine aléatoire pour reproductibilité.
    """

    def __init__(self, model: HullWhiteModel, n_paths=10**5, n_steps=100, seed=2025):
        """
        Initialise le moteur de simulation.

        Paramètres
        ----------
        model : HullWhiteModel
            Modèle Hull–White.
        n_paths : int
            Nombre de simulations (scénarios).
        n_steps : int
        seed : int
            Graine RNG pour reproductibilité.
        """
        self.model = model
        self.n_paths = n_paths
        self.n_steps = n_steps

        # Initialise le RNG global numpy 
        self.seed = np.random.seed(seed)

    def simulate_short_rate_direct(self, T):
        """
        Simule r(T) en utilisant la distribution exacte (gaussienne) sous Q.

        Paramètres
        ----------
        T : float
            Horizon en années.

        Retourne
        --------
        ndarray
            Vecteur de taille (n_paths,) contenant les r(T) simulés.
        """
        # Tirages gaussiens indépendants
        z = np.random.normal(size=self.n_paths)

        # Simulation exacte instrument par instrument 
        r = np.array([self.model.short_rate(T, z=z_i) for z_i in z])
        return r


class HullWhiteCurveBuilder:
    """
    "Curve builder" Hull–White : centralise :
      - les formules analytiques (A, B, etc.) via HullWhiteModel
      - des utilitaires Monte Carlo via HullWhiteSimulation
      - un accès pratique à la courbe initiale

    Objectif :
    - offrir une interface simple pour obtenir :
        * r(t) simulé
        * prix de ZC bond P(t,T) (distribution via MC)
    - en s’appuyant sur une courbe P(0,T) déjà construite

    Attributs
    ---------
    model : HullWhiteModel
        Modèle HW construit avec curve + params.
    sim : HullWhiteSimulation
        Moteur MC construit à partir du modèle HW.
    curve : Curve
        Courbe initiale (discount curve).
    """

    def __init__(self, curve, params=None, n_paths=10**5, n_steps=100, seed=2025, smooth=1e-7):
        """
        Initialise le builder HW à partir d'une courbe existante et de paramètres.

        Paramètres
        ----------
        curve : Curve
            Courbe d'actualisation pré-initialisée (times + discount factors).
        params : dict, optionnel
            Paramètres HW : {'a', 'sigma', 'r0'}.
            Si None, defaults (dans HullWhiteModel) sont utilisés.
        n_paths : int
            Nombre de trajectoires/scénarios Monte Carlo.
        n_steps : int
        seed : int
            Graine RNG.
        smooth : float
            Paramètre de lissage 

        Workflow
        --------
        1) Réutilise la curve pour P(0,T) et f(0,t)
        2) Construit HullWhiteModel(curve, params)
        3) Construit HullWhiteSimulation(model, ...)
        """
        self.curve = curve
        self.model = HullWhiteModel(self.curve, params)
        self.sim = HullWhiteSimulation(self.model, n_paths=n_paths, n_steps=n_steps, seed=seed)

    def short_rate(self, t):
        """
        Simule r(t) à une date t via la simulation directe (distribution exacte).

        Paramètres
        ----------
        t : float
            Temps en années.

        Retourne
        --------
        ndarray
            Vecteur (n_paths,) de taux courts simulés.
        """
        return self.sim.simulate_short_rate_direct(t)

    def zero_coupon_bond(self, t, T):
        """
        Calcule la distribution (Monte Carlo) du prix P(t,T) d'un zéro-coupon
        sous la mesure risque-neutre.

        Formule analytique (conditionnelle à r(t)) :
            P(t, T) = A(t, T) * exp(-B(t, T) * r(t))

        Ici :
        - on simule r(t) (distribution sous Q)
        - on applique la formule fermée pour obtenir un échantillon de P(t,T)

        Paramètres
        ----------
        t : float
            Temps courant.
        T : float
            Maturité.

        Retourne
        --------
        ndarray
            Distribution Monte Carlo des prix P(t,T) (taille n_paths).
        """
        # Simule r(t) via distribution exacte
        r_t = self.sim.simulate_short_rate_direct(t)

        # Récupère A(t,T) et B(t,T) du modèle
        A = self.model.A(t, T)
        B = self.model.B(t, T)

        # Prix ZC bond pour chaque scénario
        price = A * np.exp(-B * r_t)
        return price


### FILE: ir\models\hw2f.py
import pandas as pd
import numpy as np


class HullWhite2FModel:
    """
    Modèle Hull–White 2 facteurs (G2++) gaussien — briques analytiques.

    On utilise la dynamique standard des facteurs G2++ sous la mesure risque-neutre :
        dx(t) = -a x(t) dt + sigma dW1(t)
        dy(t) = -b y(t) dt + eta   dW2(t)
        dW1 dW2 = rho dt

    Cette classe se concentre sur les ingrédients *fermés* nécessaires pour :
      - le pricing de caplets via représentation en option sur ZC bond (besoin de v^2(T,S))
      - le pricing de swaptions via approximation gaussienne du swap rate (besoin de I_aa, I_bb, I_ab)

    Notes
    -----
    - La courbe doit fournir P(0,t) et f(0,t) via la même interface que le 1F.
    - Le temps est exprimé en années.
    - Les paramètres sont constants.
    """

    def __init__(self, curve, parameters=None):
        """
        Initialise le modèle HW2F à partir d'une courbe de marché et de paramètres.

        Paramètres
        ----------
        curve : Curve
            Courbe d'actualisation (discount curve) avec discount(t) et inst_forward_rate(t).
        parameters : dict, optionnel
            Paramètres du modèle :
              - a, b : vitesses de mean reversion
              - rho  : corrélation entre les Brownien dW1 et dW2
              - sigma, eta : volatilités des facteurs x et y
              - r0 : taux court initial (souvent f(0,0))
        """
        self.curve = curve

        # Valeurs par défaut (points de départ génériques pour calibration)
        defaults = {
            "a": 0.10,
            "b": 0.02,
            "rho": -0.30,
            "sigma": 0.01,
            "eta": 0.008,
            "r0": curve.inst_forward_rate(0),
        }
        if parameters is None:
            parameters = {}

        self.parameters = {
            "a": float(parameters.get("a", defaults["a"])),
            "b": float(parameters.get("b", defaults["b"])),
            "rho": float(parameters.get("rho", defaults["rho"])),
            "sigma": float(parameters.get("sigma", defaults["sigma"])),
            "eta": float(parameters.get("eta", defaults["eta"])),
            "r0": float(parameters.get("r0", defaults["r0"])),
        }

    # --- interface "courbe" (même esprit que HullWhiteModel 1F) --- #

    def inst_forward_rate(self, t: float) -> float:
        """
        Renvoie le forward instantané f(0,t) via la courbe.

        Paramètre
        ---------
        t : float
            Temps en années.

        Retourne
        --------
        float
            f(0,t).
        """
        return self.curve.inst_forward_rate(t)

    def discount_factor(self, t: float) -> float:
        """
        Renvoie le discount factor P(0,t) via la courbe.

        Paramètre
        ---------
        t : float
            Temps en années.

        Retourne
        --------
        float
            P(0,t).
        """
        return self.curve.discount(t)

    def forward_rate(self, T1: float, T2: float) -> float:
        """
        Renvoie le forward simple implicite entre T1 et T2 via la courbe.

        Paramètres
        ----------
        T1, T2 : float
            Bornes de la période.

        Retourne
        --------
        float
            F(0;T1,T2).
        """
        return self.curve.forward_rate(T1, T2)

    # --- chargements déterministes (loadings) HW2F --- #

    def B_a(self, t: float, T: float) -> float:
        """
        Fonction de chargement B_a(t,T) associée au facteur x(t).

        Formule :
            B_a(t,T) = (1 - exp(-a*(T-t))) / a

        Paramètres
        ----------
        t : float
            Temps courant.
        T : float
            Maturité.

        Retourne
        --------
        float
            B_a(t,T).
        """
        a = self.parameters["a"]
        return (1.0 - np.exp(-a * (T - t))) / a

    def B_b(self, t: float, T: float) -> float:
        """
        Fonction de chargement B_b(t,T) associée au facteur y(t).

        Formule :
            B_b(t,T) = (1 - exp(-b*(T-t))) / b
        """
        b = self.parameters["b"]
        return (1.0 - np.exp(-b * (T - t))) / b

    # ------------------------------------------------------------------
    # Ingrédient caplet : v^2(T,S) pour option sur ZC bond (donc caplet)
    # ------------------------------------------------------------------

    def v2_caplet(self, T: float, S: float) -> float:
        """
        Variance fermée v^2(T,S) intervenant dans la formule d'option sur ZC bond
        (et donc dans le pricing d'un caplet via la représentation standard).

        Avec tau = S - T, et paramètres constants :
            v^2(T,S) =
              (sigma^2/(2a^3)) (1 - e^{-2aT}) (1 - e^{-a tau})^2
            + (eta^2  /(2b^3)) (1 - e^{-2bT}) (1 - e^{-b tau})^2
            + (2 rho sigma eta /(a b (a+b))) (1 - e^{-(a+b)T})
                (1 - e^{-a tau})(1 - e^{-b tau})

        Paramètres
        ----------
        T : float
            Date d'expiry / fixing (T > 0).
        S : float
            Date de paiement / maturité du bond (S > T).

        Retourne
        --------
        float
            Variance v^2(T,S) (sans dimension).
        """
        if S <= T:
            raise ValueError("v2_caplet doit avoir S > T.")

        a = self.parameters["a"]
        b = self.parameters["b"]
        rho = self.parameters["rho"]
        sigma = self.parameters["sigma"]
        eta = self.parameters["eta"]

        tau = S - T

        eaT = np.exp(-2.0 * a * T)
        ebT = np.exp(-2.0 * b * T)
        eabT = np.exp(-(a + b) * T)

        ea_tau = np.exp(-a * tau)
        eb_tau = np.exp(-b * tau)

        # Contribution du facteur x (paramètres a, sigma)
        term_a = (sigma * sigma) / (2.0 * a**3) * (1.0 - eaT) * (1.0 - ea_tau) ** 2

        # Contribution du facteur y (paramètres b, eta)
        term_b = (eta * eta) / (2.0 * b**3) * (1.0 - ebT) * (1.0 - eb_tau) ** 2

        # Terme croisé (corrélation rho entre les deux facteurs)
        term_ab = (
            2.0
            * rho
            * sigma
            * eta
            / (a * b * (a + b))
            * (1.0 - eabT)
            * (1.0 - ea_tau)
            * (1.0 - eb_tau)
        )

        return float(term_a + term_b + term_ab)

    # ------------------------------------------------------------------
    # Ingrédients swaption (approx swap-rate) : intégrales I_aa, I_bb, I_ab
    # ------------------------------------------------------------------

    @staticmethod
    def I_aa(T: float, U: float, V: float, a: float) -> float:
        """
        Calcule l'intégrale fermée :
            I_aa(T;U,V) = ∫_0^T B_a(t,U) B_a(t,V) dt
        avec :
            B_a(t,U) = (1 - exp(-a*(U - t))) / a

        Forme fermée (cas standard U,V >= T) :
            T/a^2
          - (e^{-aU}+e^{-aV})(e^{aT}-1)/a^3
          + e^{-a(U+V)}(e^{2aT}-1)/(2a^3)

        Paramètres
        ----------
        T : float
            Horizon d'intégration (expiry swaption, typiquement).
        U, V : float
            Dates de flux (ou points de grille) intervenant dans l'approx du swap rate.
        a : float
            Mean reversion du facteur x.

        Retourne
        --------
        float
            Valeur de l'intégrale I_aa.

        """
        if a <= 0:
            raise ValueError("a doit être > 0 dans I_aa.")

        return float(
            (T / a**2)
            - ((np.exp(-a * U) + np.exp(-a * V)) * (np.exp(a * T) - 1.0) / a**3)
            + (np.exp(-a * (U + V)) * (np.exp(2.0 * a * T) - 1.0) / (2.0 * a**3))
        )

    @staticmethod
    def I_bb(T: float, U: float, V: float, b: float) -> float:
        """
        Même intégrale que I_aa, mais pour le facteur y (paramètre b).

        Paramètres
        ----------
        T : float
            Horizon d'intégration.
        U, V : float
            Dates / points de grille.
        b : float
            Mean reversion du facteur y.

        Retourne
        --------
        float
            Valeur de I_bb.

        """
        if b <= 0:
            raise ValueError("b doit être > 0 dans I_bb.")

        return float(
            (T / b**2)
            - ((np.exp(-b * U) + np.exp(-b * V)) * (np.exp(b * T) - 1.0) / b**3)
            + (np.exp(-b * (U + V)) * (np.exp(2.0 * b * T) - 1.0) / (2.0 * b**3))
        )

    @staticmethod
    def I_ab(T: float, U: float, V: float, a: float, b: float) -> float:
        """
        Calcule l'intégrale croisée :
            I_ab(T;U,V) = ∫_0^T B_a(t,U) B_b(t,V) dt

        Formule fermée (cas standard U,V >= T) :
            T/(ab)
          - e^{-aU}(e^{aT}-1)/(a^2 b)
          - e^{-bV}(e^{bT}-1)/(a b^2)
          + e^{-(aU+bV)}(e^{(a+b)T}-1)/(ab(a+b))

        Paramètres
        ----------
        T : float
            Horizon d'intégration.
        U : float
            Date/point associé à B_a.
        V : float
            Date/point associé à B_b.
        a : float
            Mean reversion facteur x.
        b : float
            Mean reversion facteur y.

        Retourne
        --------
        float
            Valeur de I_ab.

        """
        if a <= 0 or b <= 0:
            raise ValueError("a,b doit être > 0 dans I_ab.")

        return float(
            (T / (a * b))
            - (np.exp(-a * U) * (np.exp(a * T) - 1.0) / (a**2 * b))
            - (np.exp(-b * V) * (np.exp(b * T) - 1.0) / (a * b**2))
            + (
                np.exp(-(a * U + b * V))
                * (np.exp((a + b) * T) - 1.0)
                / (a * b * (a + b))
            )
        )


### FILE: ir\models\__init__.py


### FILE: ir\pricers\hw1f_pricer.py
import numpy as np
from scipy.stats import norm
from scipy.optimize import brentq
from ir.models.hw1f import HullWhiteCurveBuilder
from ir.models.hw2f import HullWhite2FModel


class HullWhitePricer:
    """
    Moteur de pricing de produits de taux sous Hull–White 1 facteur,
    basé sur une unique instance de HullWhiteCurveBuilder.

    Produits supportés
    -----------------------------------
    - Options sur obligations zéro-coupon (calls & puts)
    - Caplets / Caps et floorlets / Floors (via décomposition en options ZC)
    - Swaps et swaptions (via Jamshidian)
    - Obligations à coupon, FRN, options sur obligations (Jamshidian)

    Attributs
    ---------
    curve_sim : HullWhiteCurveBuilder
        Objet englobant :
          - le modèle HW1F (formules fermées)
          - un moteur de simulation 
          - la courbe d’actualisation
    model : HullWhiteModel
        Modèle HW1F (accès à A(t,T), B(t,T), discount_factor, etc.)
    curve : Curve
        Courbe d’actualisation initiale
    """

    def __init__(self, curve, n_paths=10**5, n_steps=252, seed=2025, hw_params=None):
        """
        Initialise le pricer HW1F.

        Paramètres
        ----------
        curve : Curve
            Courbe d’actualisation P(0,t).
        n_paths : int
            Nombre de scénarios Monte Carlo .
        n_steps : int
        seed : int
            Graine RNG.
        hw_params : dict | None
            Paramètres HW1F : {'a', 'sigma', 'r0'}.
        """
        self.curve = curve

        # CurveBuilder encapsule le modèle HW1F et l'éventuelle simulation
        self.curve_sim = HullWhiteCurveBuilder(
            curve,
            params=hw_params,
            n_paths=n_paths,
            n_steps=n_steps,
            seed=seed,
        )

        self.model = self.curve_sim.model

    def set_simulation(self, n_paths=None, n_steps=None, seed=None):
        """
        Met à jour les paramètres de simulation Monte Carlo *après* l'initialisation.

        Remarques
        ---------
        - Ici, on modifie directement l'objet self.curve_sim.sim.
        - Le reseed se fait via np.random.seed(seed), ce qui affecte le RNG global numpy.

        Paramètres
        ----------
        n_paths : int, optionnel
            Nouveau nombre de scénarios.
        n_steps : int, optionnel
            Nouveau nombre de pas.
        seed : int, optionnel
            Nouvelle graine RNG.
        """
        if n_paths is not None:
            self.curve_sim.sim.n_paths = int(n_paths)
        if n_steps is not None:
            self.curve_sim.sim.n_steps = int(n_steps)
        if seed is not None:
            np.random.seed(seed)

    def zero_bond_put(self, T, S, K, mc=False):
        """
        Prix d'un put européen sur une obligation zéro-coupon P(T,S).

        Contexte
        --------
        Sous HW1F, l'option sur ZC bond a une formule fermée (type Black sur ZC),
        avec une volatilité effective sigma_p dépendant de (a, sigma, T, S).

        Paramètres
        ----------
        T : float
            Expiry de l'option (en années).
        S : float
            Maturité du ZC bond (S > T).
        K : float
            Strike (prix) de l'obligation P(T,S).
        mc : bool

        Retourne
        --------
        float
            PV du put.
        """
        # Cas limite : option qui expire immédiatement
        if T == 0:
            P_0S = self.model.discount_factor(S)
            return max(K - P_0S, 0)

        sigma = self.model.parameters["sigma"]
        a = self.model.parameters["a"]

        # B(T,S) intervient dans la volatilité effective du bond
        B = self.model.B(T, S)

        P_S = self.model.discount_factor(S)
        P_T = self.model.discount_factor(T)

        # Vol effective du log prix du bond (formule standard HW)
        sigma_p = sigma * np.sqrt((1 - np.exp(-2 * a * T)) / (2 * a)) * B

        # Paramètre h de la formule fermée
        h = (1 / sigma_p) * np.log(P_S / (K * P_T)) + 0.5 * sigma_p

        # Formule fermée du put sur ZC bond
        V0 = K * P_T * norm.cdf(-h + sigma_p) - P_S * norm.cdf(-h)
        return V0

    def zero_bond_call(self, T, S, K):
        """
        Prix d'un call européen sur une obligation zéro-coupon P(T,S).

        Paramètres
        ----------
        T : float
            Expiry.
        S : float
            Maturité du bond (S > T).
        K : float
            Strike (prix) du bond.

        Retourne
        --------
        float
            PV du call.
        """
        sigma = self.model.parameters["sigma"]
        a = self.model.parameters["a"]

        B = self.model.B(T, S)
        P_S = self.model.discount_factor(S)
        P_T = self.model.discount_factor(T)

        sigma_p = sigma * np.sqrt((1 - np.exp(-2 * a * T)) / (2 * a)) * B
        h = (1 / sigma_p) * np.log(P_S / (K * P_T)) + 0.5 * sigma_p

        V0 = P_S * norm.cdf(h) - K * P_T * norm.cdf(h - sigma_p)
        return V0

    def caplet(self, T1, T2, N, K, method="js"):
        """
        Prix d'un caplet (sur taux simple) en utilisant la représentation via option sur ZC bond.

        Notations
        ---------
        - Fixing : T1
        - Paiement : T2
        - Delta = T2 - T1
        - Strike "bond" : K_bond = 1 + K*Delta
          (relation entre payoff caplet et prix du ZC bond)

        Paramètres
        ----------
        T1 : float
            Date de fixing.
        T2 : float
            Date de paiement (T2 > T1).
        N : float
            Notional.
        K : float
            Strike du caplet (taux).
        method : str
            - 'js' : méthode Jamshidian via zéro-bond put
            - 'cf' : formule fermée équivalente (directe)

        Retourne
        --------
        float
            PV du caplet.
        """
        Delta = T2 - T1
        K_bond = 1 + K * Delta

        if method == "js":
            # Caplet = N * (1+KΔ) * Put sur ZC bond de strike 1/(1+KΔ)
            put_price = self.zero_bond_put(T1, T2, 1 / K_bond)
            Caplet = K_bond * put_price

        elif method == "cf":
            # Variante "closed-form" explicitée : même résultat en théorie
            sigma = self.model.parameters["sigma"]
            a = self.model.parameters["a"]
            B = self.model.B(T1, T2)
            P_T2 = self.model.discount_factor(T2)
            P_T1 = self.model.discount_factor(T1)

            sigma_p = sigma * np.sqrt((1 - np.exp(-2 * a * T1)) / (2 * a)) * B
            h = (1 / sigma_p) * np.log(P_T2 * K_bond / P_T1) + 0.5 * sigma_p

            Caplet = (P_T1 * norm.cdf(-h + sigma_p) - K_bond * P_T2 * norm.cdf(-h))

        else:
            raise ValueError("method must be 'js' or 'cf'.")

        return N * Caplet

    def cap(self, Tau, N, K):
        """
        Prix d'un cap comme somme de caplets.

        Paramètres
        ----------
        Tau : list[float]
            Dates : [T0, T1, ..., Tn] où chaque caplet est sur (T_{i-1}, T_i).
        N : float
            Notional.
        K : float
            Strike (taux).

        Retourne
        --------
        float
            PV du cap.
        """
        Cap = 0.0

        # Somme des caplets, i=1..n
        for i in range(1, len(Tau)):
            t_prev = Tau[i - 1]
            t_curr = Tau[i]
            Delta = t_curr - t_prev
            K_bond = 1 + K * Delta

            # Put ZC bond par Jamshidian
            put_price = self.zero_bond_put(t_prev, t_curr, 1 / K_bond)
            Cap += K_bond * put_price

        return N * Cap

    def floor(self, Tau, N, K, mc=False):
        """
        Prix d'un floor comme somme de floorlets.

        Dans la représentation ZC bond, un floorlet correspond à un call sur ZC bond.

        Paramètres
        ----------
        Tau : list[float]
            Dates : [T0, T1, ..., Tn].
        N : float
            Notional.
        K : float
            Strike (taux).
        mc : bool

        Retourne
        --------
        float
            PV du floor.
        """
        Floor = 0.0

        for i in range(1, len(Tau)):
            t_prev = Tau[i - 1]
            t_curr = Tau[i]
            Delta = t_curr - t_prev
            K_bond = 1 + K * Delta

            # Call sur ZC bond par Jamshidian
            call_price = self.zero_bond_call(t_prev, t_curr, 1 / K_bond)
            Floor += K_bond * call_price

        return N * Floor

    def swap(self, Tau, N, K, payer=True, mc=False):
        """
        Prix d'un swap vanilla (jambe fixe vs jambe flottante) sous la courbe initiale.

        Convention
        ----------
        PV = N * w * (PV_float - PV_fixed)
        où :
          - w = +1 pour payer swap (payer fixe, recevoir flottant)
          - w = -1 pour receiver swap

        Paramètres
        ----------
        Tau : list[float]
            Dates de paiement jambe fixe : [T0, T1, ..., Tn].
        N : float
            Notional.
        K : float
            Taux fixe.
        payer : bool
            True = payer swap ; False = receiver swap.
        mc : bool

        Retourne
        --------
        float
            PV du swap.
        """
        w = 1 if payer else -1

        # Calcul annuité A0 = sum Δ_i P(0,Ti)
        Annuity = 0.0
        for i in range(1, len(Tau)):
            Delta = Tau[i] - Tau[i - 1]
            P_T = self.model.discount_factor(Tau[i])
            Annuity += Delta * P_T

        # Jambe fixe
        Fixed_leg = Annuity * K

        # Jambe flottante (swap par swap-parity) : P(0,T0) - P(0,Tn)
        Floating_leg = self.model.discount_factor(Tau[0]) - self.model.discount_factor(Tau[-1])

        Swap = N * w * (Floating_leg - Fixed_leg)
        return Swap

    def swaption(self, Tau, N, K, payer=True, mc=False):
        """
        Prix d'une swaption européenne via décomposition de Jamshidian.

        Principe (HW1F)
        --------------
        Le swaption payoff peut être décomposé en portefeuille d'options sur ZC bonds,
        après avoir trouvé le taux court critique r* (solution d'une équation).

        Paramètres
        ----------
        Tau : list[float]
            Dates de paiement jambe fixe : [T0 (= expiry), T1, ..., Tn].
        N : float
            Notional.
        K : float
            Taux fixe (strike).
        payer : bool
            True = payer swaption ; False = receiver swaption.
        mc : bool

        Retourne
        --------
        float
            PV de la swaption.
        """
        # w sert seulement au payoff (mais ici on s'en sert pour sélectionner put/call)
        w = 1 if payer else -1

        T = Tau[0]   # Expiry
        S = Tau[-1]  # Maturité dernière date

        # Étape 1 : trouver r* (taux court critique)
        r_star = self._find_rstar(T, Tau, K)

        # Étape 2 : jambe fixe => somme d'options ZC bond sur chaque date de paiement
        fixed_leg = 0.0
        for i in range(1, len(Tau)):
            T1 = Tau[i - 1]
            T2 = Tau[i]
            Delta = T2 - T1

            # Prix du ZC bond à T pour maturité T2 : P(T,T2) = A(T,T2)*exp(-B(T,T2)*r(T))
            # Jamshidian : on construit un strike K_i = P(T,T2; r*)
            B = self.model.B(T, T2)
            A = self.model.A(T, T2)
            K_i = A * np.exp(-B * r_star)

            # Payer swaption -> puts ; Receiver -> calls (sur ZC bonds)
            option = self.zero_bond_put(T, T2, K_i) if payer else self.zero_bond_call(T, T2, K_i)
            fixed_leg += Delta * K * option

        # Étape 3 : jambe flottante => option sur le ZC bond maturing at S (dernier DF)
        B_N = self.model.B(T, S)
        A_N = self.model.A(T, S)
        K_N = A_N * np.exp(-B_N * r_star)

        floating_leg = self.zero_bond_put(T, S, K_N) if payer else self.zero_bond_call(T, S, K_N)

        # PV swaption = N * (floating_leg + fixed_leg)
        swaption = N * (floating_leg + fixed_leg)
        return swaption

    def coupon_bond(self, Tau, C, N):
        """
        Prix d'une obligation à coupon simple, valorisée sur la courbe initiale.

        Paramètres
        ----------
        Tau : list[float]
            Dates de paiement (T1, T2, ..., TN).
        C : float
            Taux de coupon annualisé.
        N : float
            Notional.

        Retourne
        --------
        float
            PV de l'obligation à coupon.
        """
        bond_price = 0.0

        Delta = (Tau[-1] - Tau[0])

        for i in range(len(Tau)):
            P_T = self.curve.discount(Tau[i])

            # Dernier flux = principal + coupon ; sinon coupon seul
            cashflow = N * (1 + C * Delta) if i == len(Tau) - 1 else N * C * Delta
            bond_price += cashflow * P_T

        return bond_price

    def floating_rate_note(self, Tau, N):
        """
        Prix d'une FRN (Floating Rate Note) simple.

        Paramètres
        ----------
        Tau : list[float]
            Dates de paiement.
        N : float
            Notional.

        Retourne
        --------
        float
            PV de la FRN.
        """
        disc_cf = self.swap(Tau, N, K=0, payer=False, mc=False)

        disc_notional = N * self.model.discount_factor(Tau[-1])

        frn_price = disc_cf + disc_notional
        return frn_price

    def bond_option(self, T, Tau, C, K, N, call=True, mc=False):
        """
        Option européenne sur obligation à coupon, via décomposition de Jamshidian.

        Paramètres
        ----------
        T : float
            Expiry de l'option.
        Tau : list[float]
            Dates de paiement des coupons (T1, ..., TN).
        C : float
            Taux de coupon annualisé.
        K : float
            Strike (prix absolu de l'obligation, pas un %).
        N : float
            Notional.
        call : bool
            True = call ; False = put.
        mc : bool

        Retourne
        --------
        float
            PV de l'option sur obligation.
        """
        # Étape 1 : trouver r* tel que Prix_obligation(T; r*) = K
        r_star = self._find_rstar_bond(T, Tau, C, N, K)

        bond_option = 0.0
        Delta = (Tau[-1] - Tau[0])

        # Étape 2 : décomposition en options sur ZC bonds
        for i in range(len(Tau)):
            B = self.model.B(T, Tau[i])
            A = self.model.A(T, Tau[i])
            K_i = A * np.exp(-B * r_star)  # strike du ZC bond P(T,T_i) au taux r*

            # Option sur ZC bond : call ou put selon option globale
            option = self.zero_bond_call(T, Tau[i], K_i) if call else self.zero_bond_put(T, Tau[i], K_i)

            # Cashflow associé à la date Tau[i]
            cashflow = N * (1 + C * Delta) if i == len(Tau) - 1 else N * C * Delta
            bond_option += cashflow * option

        return bond_option

    # --- Méthodes auxiliaires (Jamshidian decomposition) --- #

    def _jamshidian_root(self, T, Tau, K, r_star):
        """
        Fonction de root-finding pour la swaption (Jamshidian).

        On cherche r* tel que :
          sum_i Δ_i K P(T, T_i; r*) = 1 - P(T, T_n; r*)
        (forme équivalente aux conditions de décomposition)

        Paramètres
        ----------
        T : float
            Expiry.
        Tau : list[float]
            Dates de paiement swap.
        K : float
            Strike (taux fixe).
        r_star : float
            Candidat pour r*.

        Retourne
        --------
        float
            Valeur de l'équation (doit être 0 à la racine).
        """
        root = 0.0

        # Partie jambe fixe : sum Δ_i K P(T,T_i; r*)
        for i in range(1, len(Tau)):
            T1 = Tau[i - 1]
            T2 = Tau[i]
            Delta = T2 - T1

            B = self.model.B(T, T2)
            A = self.model.A(T, T2)
            P_i = A * np.exp(-B * r_star)

            root += Delta * K * P_i

        # Attention : ici, P_i est celui du dernier i de la boucle (donc maturité T_n)
        # Root complet : fixe - (1 - P(T,T_n))
        root = root - (1 - P_i)
        return root

    def _find_rstar(self, T, Tau, K, x_min=-3, x_max=3):
        """
        Recherche du taux court critique r* pour la swaption via Brent.

        Paramètres
        ----------
        T : float
            Expiry.
        Tau : list[float]
            Dates de paiement.
        K : float
            Strike (taux fixe).
        x_min, x_max : float
            Bornes de recherche pour brentq.

        Retourne
        --------
        float
            r*.
        """
        f = lambda r: self._jamshidian_root(T, Tau, K, r)
        r_star = brentq(f, x_min, x_max, xtol=1e-12)
        return r_star

    def _jamshidian_root_bond(self, T, Tau, C, N, K_strike, r_star):
        """
        Fonction de root-finding pour option sur obligation à coupon (Jamshidian).

        On cherche r* tel que :
          sum_i cashflow_i * P(T, T_i; r*) = K_strike

        Paramètres
        ----------
        T : float
            Expiry.
        Tau : list[float]
            Dates coupons.
        C : float
            Coupon annualisé.
        N : float
            Notional.
        K_strike : float
            Strike (prix de l'obligation).
        r_star : float
            Candidat pour r*.

        Retourne
        --------
        float
            (Prix obligation à T au taux r*) - K_strike
        """
        bond_price = 0.0
        Delta = (Tau[-1] - Tau[0])

        for i in range(len(Tau)):
            B = self.model.B(T, Tau[i])
            A = self.model.A(T, Tau[i])
            P_i = A * np.exp(-B * r_star)

            cashflow = N * (1 + C * Delta) if i == len(Tau) - 1 else N * C * Delta
            bond_price += cashflow * P_i

        return bond_price - K_strike

    def _find_rstar_bond(self, T, Tau, C, N, K_strike, x_min=-3, x_max=3):
        """
        Recherche de r* pour option sur obligation à coupon via Brent.

        Paramètres
        ----------
        T : float
            Expiry.
        Tau : list[float]
            Dates coupons.
        C : float
            Coupon annualisé.
        N : float
            Notional.
        K_strike : float
            Strike prix.
        x_min, x_max : float
            Bornes de recherche Brent.

        Retourne
        --------
        float
            r*.
        """
        f = lambda r: self._jamshidian_root_bond(T, Tau, C, N, K_strike, r)
        r_star = brentq(f, x_min, x_max, xtol=1e-12)
        return r_star


### FILE: ir\pricers\hw2f_pricer.py
import numpy as np
from scipy.stats import norm
from scipy.optimize import brentq
from ir.models.hw2f import HullWhite2FModel


class HullWhite2FPricer:
    """
    Moteur de pricing pour caplets et swaptions sous Hull–White 2 facteurs (G2++).

    Fonctionnalités
    ---------------
    - Caplet : via put sur ZC bond avec variance fermée v^2(T,S) (formule d'option sur bond).
    - Swaption : via approximation gaussienne du swap-rate (poids figés) + pricing Bachelier (normal).

    Notes
    -----
    - Hypothèse single-curve : discounting et forwarding via la même courbe.
    - Accruals : Delta_i ≈ Tau[i] - Tau[i-1] (même convention que ton pricer 1F).
    """

    def __init__(self, curve, hw2f_params=None):
        """
        Initialise le pricer 2F.

        Paramètres
        ----------
        curve : Curve
            Courbe d’actualisation P(0,t).
        hw2f_params : dict | None
            Paramètres G2++ : {'a','b','rho','sigma','eta','r0'}.
        """
        self.curve = curve
        self.model = HullWhite2FModel(curve, hw2f_params)

    # -------------------------
    # Helpers (quantités courbe)
    # -------------------------

    def discount_factor(self, t: float) -> float:
        """
        Raccourci : renvoie P(0,t) via le modèle/courbe.

        Paramètre
        ---------
        t : float
            Temps en années.

        Retourne
        --------
        float
            Discount factor P(0,t).
        """
        return self.model.discount_factor(t)

    def _annuity_and_swap_rate_0(self, Tau):
        """
        Calcule l'annuité A0 et le swap rate forward S0 à t=0 pour un schedule fixe.

        Pour Tau = [T0, T1, ..., Tn] :
          - Delta_i = Tau[i] - Tau[i-1]
          - A0 = sum_{i=1..n} Delta_i * P(0,Ti)
          - S0 = (P(0,T0) - P(0,Tn)) / A0

        Paramètres
        ----------
        Tau : list[float]
            Dates de paiement de la jambe fixe, avec T0 = start/expiry et Tn = dernière date.

        Retourne
        --------
        (float, float)
            (A0, S0)

        """
        if len(Tau) < 2:
            raise ValueError("Tau doit contenir au moins [T0, Tn].")

        T0 = float(Tau[0])
        Tn = float(Tau[-1])

        # Annuité A0
        A0 = 0.0
        for i in range(1, len(Tau)):
            Ti = float(Tau[i])
            delta = float(Tau[i] - Tau[i - 1])
            A0 += delta * self.discount_factor(Ti)

        if A0 <= 0:
            raise ValueError("Annuity A0 doit être > 0.")

        # Swap rate forward S0
        S0 = (self.discount_factor(T0) - self.discount_factor(Tn)) / A0
        return float(A0), float(S0)

    def _swaption_weights_frozen(self, Tau):
        """
        Construit les poids figés (frozen weights) c_j pour l'approximation gaussienne du swap-rate.

        Idée
        ----
        On approxime le swap rate comme combinaison linéaire des log-bonds :
          dS(t) ≈ sum_j c_j * (dP(t,U_j)/P(t,U_j))   (à des loadings déterministes près)

        Poids figés (à t=0), avec U_j = Tau[j] :
          - c(T0) +=  P(0,T0) / A0
          - c(Tn) += -P(0,Tn) / A0
          - c(Ti) += -(S0/A0) * Delta_i * P(0,Ti)   pour i=1..n
        (Donc Tn reçoit potentiellement deux contributions : numerator + annuity.)

        Paramètres
        ----------
        Tau : list[float]
            Schedule fixe [T0, T1, ..., Tn] où T0 = expiry/start.

        Retourne
        --------
        (U, c, A0, S0)
            U : list[float] les dates
            c : np.ndarray les poids figés 
            A0 : float annuité
            S0 : float swap rate forward
        """
        A0, S0 = self._annuity_and_swap_rate_0(Tau)

        U = [float(x) for x in Tau]
        m = len(U)
        c = np.zeros(m, dtype=float)

        # Contributions du numérateur (swap parity)
        c[0] += self.discount_factor(U[0]) / A0
        c[-1] += -self.discount_factor(U[-1]) / A0

        # Contribution annuité : -(S0/A0) * Delta_i * P(0,Ti)
        for i in range(1, m):
            Ti = U[i]
            delta = U[i] - U[i - 1]
            c[i] += -(S0 / A0) * delta * self.discount_factor(Ti)

        return U, c, A0, S0

    # ---------------------------------------
    # Options sur ZC bond (fermé via v^2(T,S))
    # ---------------------------------------

    def zero_bond_put_hw2f(self, T: float, S: float, K: float) -> float:
        """
        Put européen sur ZC bond P(T,S) de strike K (strike sur le prix du bond),
        valorisé à t=0 sous HW2F.

        Formule (analogue "Black" sur ZC bond) :
          Put = K P(0,T) N(-d2) - P(0,S) N(-d1)
          d1 = [ln(P(0,S)/(K P(0,T))) + 0.5 v^2] / v
          d2 = d1 - v
        où v^2 = model.v2_caplet(T,S).

        Paramètres
        ----------
        T : float
            Expiry de l'option (en années).
        S : float
            Maturité du bond (S > T).
        K : float
            Strike (prix du bond) > 0.

        Retourne
        --------
        float
            PV du put.
        """
        T = float(T)
        S = float(S)
        K = float(K)

        if S <= T:
            raise ValueError("Bond option doit avoir S > T.")
        if K <= 0:
            raise ValueError("Bond option strike K doit être > 0.")

        P0T = self.discount_factor(T)
        P0S = self.discount_factor(S)

        # Variance v^2(T,S) (fermée) puis vol v
        v2 = self.model.v2_caplet(T, S)
        v = np.sqrt(max(v2, 0.0))

        if v < 1e-16:
            # Cas quasi déterministe : payoff intrinsèque actualisé
            return float(max(K * P0T - P0S, 0.0))

        ln_term = np.log(P0S / (K * P0T))
        d1 = (ln_term + 0.5 * v2) / v
        d2 = d1 - v

        put = K * P0T * norm.cdf(-d2) - P0S * norm.cdf(-d1)
        return float(put)

    def zero_bond_call_hw2f(self, T: float, S: float, K: float) -> float:
        """
        Call européen sur ZC bond P(T,S) de strike K, valorisé à t=0 sous HW2F.

        Formule :
          Call = P(0,S) N(d1) - K P(0,T) N(d2)
        avec d1, d2 définis comme dans zero_bond_put_hw2f.

        Paramètres
        ----------
        T : float
            Expiry.
        S : float
            Maturité (S > T).
        K : float
            Strike > 0.

        Retourne
        --------
        float
            PV du call.
        """
        T = float(T)
        S = float(S)
        K = float(K)

        if S <= T:
            raise ValueError("Bond option doit avoir S > T.")
        if K <= 0:
            raise ValueError("Bond option strike K doit être > 0.")

        P0T = self.discount_factor(T)
        P0S = self.discount_factor(S)

        v2 = self.model.v2_caplet(T, S)
        v = np.sqrt(max(v2, 0.0))

        if v < 1e-16:
            # Cas quasi déterministe : payoff intrinsèque actualisé
            return float(max(P0S - K * P0T, 0.0))

        ln_term = np.log(P0S / (K * P0T))
        d1 = (ln_term + 0.5 * v2) / v
        d2 = d1 - v

        call = P0S * norm.cdf(d1) - K * P0T * norm.cdf(d2)
        return float(call)

    # -----------------------
    # Caplet pricing sous 2F
    # -----------------------

    def caplet_hw2f(self, T1: float, T2: float, N: float, K: float) -> float:
        """
        PV d'un caplet sous HW2F via put sur ZC bond.

        Relation standard :
          Caplet = N * (1 + K*Delta) * PutZC(T1, T2, 1/(1+K*Delta))
        avec Delta = T2 - T1.

        Paramètres
        ----------
        T1 : float
            Fixing (expiry du caplet).
        T2 : float
            Paiement (T2 > T1).
        N : float
            Notional.
        K : float
            Strike en "rate units" (ex: 0.03).

        Retourne
        --------
        float
            PV du caplet.
        """
        T1 = float(T1)
        T2 = float(T2)
        N = float(N)
        K = float(K)

        if T2 <= T1:
            raise ValueError("Caplet doit avoir T2 > T1.")
        if N <= 0:
            raise ValueError("Notional N doit être > 0.")
        if K < 0:
            raise ValueError("Strike K doit être >= 0.")

        Delta = T2 - T1
        K_bond = 1.0 + K * Delta
        if K_bond <= 0:
            raise ValueError("(1 + K*Delta) <= 0 n'est pas valide.")

        # Strike de l'option sur P(T1,T2)
        K_zc = 1.0 / K_bond

        put_zc = self.zero_bond_put_hw2f(T1, T2, K_zc)
        caplet = N * K_bond * put_zc
        return float(caplet)

    # ----------------------------------------------
    # Swaption pricing sous 2F (approx gaussienne)
    # ----------------------------------------------

    def swaption_approx_hw2f(self, Tau, N: float, K: float, payer: bool = True) -> float:
        """
        PV d'une swaption via :
          - approximation gaussienne du swap rate avec poids figés
          - intégrales fermées HW2F : I_aa, I_bb, I_ab
          - pricing Bachelier (normal) sur le swap rate

        Paramètres
        ----------
        Tau : list[float]
            Schedule fixe [T0, T1, ..., Tn] (T0 = expiry / start).
        N : float
            Notional.
        K : float
            Strike en "rate units" (ex: 0.03).
        payer : bool
            True = payer swaption ; False = receiver swaption.

        Retourne
        --------
        float
            PV de la swaption.

        Remarques
        ---------
        - Ici, on utilise S0 (swap rate forward) et A0 (annuité) calculés à t=0.
        - La variance du swap rate à l'expiry T est :
            Var[S(T)] = sigma^2 Qaa + eta^2 Qbb + 2 rho sigma eta Qab
          où Q.. proviennent des doubles sommes sur les poids figés et les intégrales I_.. .
        """
        Tau = [float(x) for x in Tau]
        N = float(N)
        K = float(K)

        # Vérifications d'entrée
        if len(Tau) < 2:
            raise ValueError("Tau doit contenir au moins [T0, Tn].")
        if N <= 0:
            raise ValueError("Notional N doit être > 0.")

        T = Tau[0]  # expiry
        if T <= 0:
            # Cas expiry immédiate non géré par cette approximation
            raise ValueError("Swaption expiry T doit être > 0 pour cette méthode.")

        # Construction des poids figés + A0, S0
        U, c, A0, S0 = self._swaption_weights_frozen(Tau)

        # Paramètres du modèle
        a = self.model.parameters["a"]
        b = self.model.parameters["b"]
        rho = self.model.parameters["rho"]
        sigma = self.model.parameters["sigma"]
        eta = self.model.parameters["eta"]

        # Calcul des Qaa, Qbb, Qab par double somme
        Qaa = 0.0
        Qbb = 0.0
        Qab = 0.0

        for i, Ui in enumerate(U):
            ci = c[i]
            if ci == 0.0:
                continue
            for j, Uj in enumerate(U):
                cj = c[j]
                if cj == 0.0:
                    continue
                Qaa += ci * cj * HullWhite2FModel.I_aa(T, Ui, Uj, a)
                Qbb += ci * cj * HullWhite2FModel.I_bb(T, Ui, Uj, b)
                Qab += ci * cj * HullWhite2FModel.I_ab(T, Ui, Uj, a, b)

        # Variance du swap rate à l'expiry
        varS = (sigma * sigma) * Qaa + (eta * eta) * Qbb + 2.0 * rho * sigma * eta * Qab
        varS = float(max(varS, 0.0))

        # Cas variance quasi nulle : payoff intrinsèque à l'expiry (actualisé via annuité)
        if varS < 1e-30:
            w = 1.0 if payer else -1.0
            return float(N * A0 * max(w * (S0 - K), 0.0))

        # Conversion variance -> vol normal du swap rate (Bachelier) :
        # Var[S(T)] = sigmaN^2 * T  => sigmaN = sqrt(varS / T)
        sigmaN = np.sqrt(varS / T)

        # Pricing Bachelier
        d = (S0 - K) / (sigmaN * np.sqrt(T))
        w = 1.0 if payer else -1.0

        price = N * A0 * (w * (S0 - K) * norm.cdf(w * d) + sigmaN * np.sqrt(T) * norm.pdf(d))
        return float(price)


### FILE: ir\risk\hw2f_sim.py
# -*- coding: utf-8 -*-
"""
hw2f_sim.py

Wrapper Monte Carlo pour Hull–White 2 facteurs (G2++, aka HW2F),
afin de générer des distributions de prix de ZC bonds P(t,T).

"""

from __future__ import annotations
import numpy as np


class HW2FCurveSim:
    """
    Wrapper de simulation pour HW2F.

    Fournit
    --------
    - zero_coupon_bond(t, T) : ndarray des P(t,T) sur n_paths scénarios

    Paramètres
    ----------
    curve :
        Instance de Curve (doit fournir discount(t)).
    model :
        Instance de HullWhite2FModel (doit fournir B_a, B_b, v2_caplet et parameters).
    n_paths :
        Nombre de scénarios Monte Carlo.
    seed :
    """

    def __init__(
        self,
        curve,
        model,
        n_paths: int = 20000,
        seed: int = 2025,
        use_legacy_global_seed: bool = True,
    ):
        # Stockage des objets "marché" et "modèle"
        self.curve = curve
        self.model = model

        # Paramètre Monte Carlo
        self.n_paths = int(n_paths)

        self._use_legacy = bool(use_legacy_global_seed)
        if self._use_legacy:
            np.random.seed(seed)
            self._rng = None
        else:
            self._rng = np.random.default_rng(seed)

    # -------------------------
    # Utilitaires RNG internes
    # -------------------------

    def _normal(self, size: int) -> np.ndarray:
        """
        Tire des normales N(0,1) selon le mode RNG choisi.

        Paramètres
        ----------
        size : int
            Nombre de tirages.

        Retourne
        --------
        np.ndarray
            Tableau de N(0,1) de taille `size`.
        """
        if self._use_legacy:
            # RNG global NumPy
            return np.random.normal(size=size)
        return self._rng.normal(size=size)

    # -------------------------
    # Tirage exact (x_t, y_t)
    # -------------------------

    def _simulate_xy(self, t: float) -> tuple[np.ndarray, np.ndarray]:
        """
        Simulation exacte du couple gaussien (x_t, y_t) sous la mesure risque-neutre Q.

        Dynamique factors (G2++) :
          x_t = sigma ∫_0^t e^{-a(t-s)} dW1(s)
          y_t = eta   ∫_0^t e^{-b(t-s)} dW2(s)
          corr(dW1, dW2) = rho

        On utilise ici le fait que (x_t, y_t) est un vecteur gaussien centré
        dont on connaît variance/covariance en forme fermée.

        Paramètres
        ----------
        t : float
            Horizon de simulation (en années).

        Retourne
        --------
        (x, y) : tuple[np.ndarray, np.ndarray]
            Deux tableaux (n_paths,) correspondant aux tirages de x_t et y_t.
        """
        t = float(t)

        # À t ~ 0 : pas de variance => facteurs nuls
        if t <= 1e-16:
            x = np.zeros(self.n_paths)
            y = np.zeros(self.n_paths)
            return x, y

        # Lecture des paramètres du modèle
        a = float(self.model.parameters["a"])
        b = float(self.model.parameters["b"])
        rho = float(self.model.parameters["rho"])
        sigma = float(self.model.parameters["sigma"])
        eta = float(self.model.parameters["eta"])

        # Variances et covariance fermées pour OU gaussiens corrélés
        vx = (sigma**2 / (2.0 * a)) * (1.0 - np.exp(-2.0 * a * t))
        vy = (eta**2 / (2.0 * b)) * (1.0 - np.exp(-2.0 * b * t))
        cxy = (rho * sigma * eta / (a + b)) * (1.0 - np.exp(-(a + b) * t))

        # Tirage de deux normales indépendantes
        z1 = self._normal(self.n_paths)
        z2 = self._normal(self.n_paths)

        # Construction stable d'un couple corrélé via une factorisation 2x2 :
        # x = sx * z1
        # y = alpha * z1 + beta * z2
        sx = np.sqrt(max(vx, 0.0))
        alpha = cxy / (sx + 1e-18)  
        beta2 = vy - alpha**2       
        beta = np.sqrt(max(beta2, 0.0))

        x = sx * z1
        y = alpha * z1 + beta * z2
        return x, y

    # -------------------------
    # Distribution du ZC bond
    # -------------------------

    def zero_coupon_bond(self, t: float, T: float) -> np.ndarray:
        """
        Distribution de P(t,T) sur n_paths scénarios.

        Forme affine gaussienne (sous G2++) :
          P(t,T) = P(0,T)/P(0,t) * exp( -B_a(t,T) x_t - B_b(t,T) y_t - 0.5 v^2(t,T) )

        - Le ratio P(0,T)/P(0,t) vient de l’ajustement à la courbe initiale.
        - B_a, B_b sont les loadings déterministes des facteurs.
        - Ici v^2(t,T) est pris via model.v2_caplet(expiry=t, maturity=T)

        Paramètres
        ----------
        t : float
            Temps d’évaluation (en années).
        T : float
            Maturité du ZC bond (doit vérifier T >= t).

        Retourne
        --------
        np.ndarray
            Tableau (n_paths,) des prix simulés P(t,T).
.
        """
        t = float(t)
        T = float(T)

        # Vérification : on ne peut pas demander P(t,T) avec T < t
        if T < t - 1e-12:
            raise ValueError("Doit avoir T >= t pour P(t,T).")

        # Si T == t : P(t,t)=1 (ZC bond qui mature instantanément)
        if abs(T - t) < 1e-12:
            return np.ones(self.n_paths)

        # Ratio d'ajustement à la courbe initiale (fit exact à t=0)
        ratio = float(self.curve.discount(T)) / (float(self.curve.discount(t)) + 1e-18)

        # Tirage exact des facteurs (x_t, y_t)
        x, y = self._simulate_xy(t)

        # Loadings déterministes
        Ba = float(self.model.B_a(t, T))
        Bb = float(self.model.B_b(t, T))

        # Terme de variance intégrée (ajustement convexité)
        v2 = float(self.model.v2_caplet(t, T))
        adj = -0.5 * v2

        # Formule affine : ratio * exp( -Ba x_t - Bb y_t + adj )
        return ratio * np.exp(-Ba * x - Bb * y + adj)


### FILE: ir\risk\pfe_plot.py
# -*- coding: utf-8 -*-
"""
pfe_plot.py

Helpers de plotting pour profils PFE/EPE (matplotlib).
"""

from __future__ import annotations
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter


def _human_money(x, pos=None) -> str:
    """
    Formatte un nombre "monétaire" en version lisible.

    Exemples
    --------
    1200      -> "1.2k"
    1200000   -> "1.2M"
    -35000000 -> "-35.0M"

    Paramètres
    ----------
    x : float
        Valeur brute à formater (axe Y).
    pos : int | None
        Position du tick 

    Retourne
    --------
    str
        Chaîne formattée (k, M, B).
    """
    x = float(x)
    ax = abs(x)

    # On applique des suffixes en fonction de l’ordre de grandeur
    if ax >= 1e9:
        return f"{x/1e9:.1f}B"
    if ax >= 1e6:
        return f"{x/1e6:.1f}M"
    if ax >= 1e3:
        return f"{x/1e3:.1f}k"
    return f"{x:.0f}"


def plot_pfe_profile(
    grid,
    pfe,
    epe=None,
    q: float = 0.95,
    title: str = "Profil PFE",
    subtitle: str | None = None,
    xlabel: str = "Temps (Années)",
    ylabel: str = "Exposure",
    show_fill: bool = True,
    annotate_peak: bool = True,
    savepath: str | None = None,
):
    """
    Trace un profil PFE "propre" (et optionnellement EPE).

    Paramètres
    ----------
    grid : array-like
        Grille de temps (en années).
    pfe : array-like
        Valeurs de PFE (même longueur que grid).
    epe : array-like, optionnel
        Valeurs de EPE (même longueur que grid).
    q : float
        Quantile utilisé pour la PFE (ex: 0.95, 0.975, 0.99).
    title : str
        Titre principal du graphique.
    subtitle : str, optionnel
        Ligne d’information additionnelle (détails swap, notional, strike, paramètres modèle...).
    xlabel : str
        Label de l’axe X.
    ylabel : str
        Label de l’axe Y.
    show_fill : bool
        Si True, remplit légèrement sous la courbe PFE (effet visuel).
    annotate_peak : bool
        Si True, met en évidence et annote le maximum de la PFE.
    savepath : str, optionnel
        Si fourni, sauvegarde la figure au format PNG.

    Retourne
    --------
    (fig, ax)
        Objets Matplotlib (figure, axes) pour permettre des ajustements externes.
    """
    # Conversion en tableaux NumPy pour garantir le bon typage
    grid = np.asarray(grid, dtype=float)
    pfe = np.asarray(pfe, dtype=float)
    if epe is not None:
        epe = np.asarray(epe, dtype=float)

    # Création figure/axes (un seul panneau)
    fig, ax = plt.subplots(figsize=(11, 5.5))

    # Courbe PFE (label basé sur le quantile)
    label_pfe = f"PFE ({int(q*100)}%)"
    ax.plot(grid, pfe, marker="o", markersize=3.5, linewidth=2.0, label=label_pfe)

    # Option : remplir sous la courbe (utile visuellement)
    if show_fill:
        ax.fill_between(grid, 0.0, pfe, alpha=0.12)

    # Courbe EPE optionnelle (style différent)
    if epe is not None:
        ax.plot(
            grid,
            epe,
            marker="s",
            markersize=3.2,
            linewidth=1.8,
            linestyle="--",
            label="EPE",
        )

    # Titre + sous-titre optionnel
    ax.set_title(title, fontsize=14, fontweight="bold", pad=10)
    if subtitle:
        ax.text(0.0, 1.02, subtitle, transform=ax.transAxes, fontsize=10, alpha=0.9, va="bottom")

    ax.set_xlabel(xlabel, fontsize=11)
    ax.set_ylabel(ylabel, fontsize=11)
    ax.yaxis.set_major_formatter(FuncFormatter(_human_money))
    ax.grid(True, alpha=0.25)
    ax.set_xlim(grid.min(), grid.max())
    ax.set_ylim(bottom=0.0)

    # Option : annotation du pic (max PFE)
    if annotate_peak and len(pfe) > 0:
        i_max = int(np.argmax(pfe))
        t_max = grid[i_max]
        pfe_max = pfe[i_max]

        ax.scatter([t_max], [pfe_max], s=45, zorder=5)

        ax.annotate(
            f"Peak: {pfe_max:,.0f} at {t_max:.2f}y",
            xy=(t_max, pfe_max),
            xytext=(10, 10),
            textcoords="offset points",
            fontsize=10,
            arrowprops=dict(arrowstyle="->", lw=1.0, alpha=0.8),
        )

    # Légende + mise en page
    ax.legend(frameon=True, fontsize=10, loc="upper right")
    plt.tight_layout()

    # Option : sauvegarde en PNG
    if savepath:
        fig.savefig(savepath, dpi=200, bbox_inches="tight")

    # Affichage 
    plt.show()
    return fig, ax


### FILE: ir\risk\pfe_swap.py
# -*- coding: utf-8 -*-
"""
pfe_swap.py

Utilitaires d'exposition / PFE pour un IRS vanilla (swap) sous un simulateur de courbe.

Compatibilité
-------------
Fonctionne avec :
- HullWhiteCurveBuilder (1F) : l'objet expose zero_coupon_bond(t,T) et sim.n_paths
- HW2FCurveSim (2F)         : l'objet expose zero_coupon_bond(t,T) et n_paths

"""

from __future__ import annotations

import time
from typing import Callable, Optional, Dict, Any

import numpy as np


def _get_n_paths(curve_sim) -> int:
    """
    Déduit le nombre de scénarios Monte Carlo depuis l'objet simulateur.

    Pourquoi ?
    ----------
    Tes deux simulateurs (1F vs 2F) n’exposent pas forcément le même attribut :
    - HW2F : curve_sim.n_paths
    - HW1F : curve_sim.sim.n_paths (via HullWhiteCurveBuilder.sim)

    Retourne
    --------
    int
        Nombre de paths.

    """
    if hasattr(curve_sim, "n_paths"):
        return int(curve_sim.n_paths)
    if hasattr(curve_sim, "sim") and hasattr(curve_sim.sim, "n_paths"):
        return int(curve_sim.sim.n_paths)
    raise AttributeError(
        "Objets attendus : curve_sim.n_paths ou curve_sim.sim.n_paths."
    )


def swap_mtm_distribution_at_t(
    curve_sim,
    t: float,
    Tau,
    K: float,
    N: float,
    payer: bool = True,
    progress_cb: Optional[Callable[[Dict[str, Any]], None]] = None,
    progress_ctx: Optional[Dict[str, Any]] = None,
    inner_progress: bool = False,
    inner_every: int = 3,
) -> np.ndarray:
    """
    Calcule la distribution de V(t) (MTM/PV à la date t) d'un swap vanilla.

    Idée
    ----
    On valorise le swap à la date t sur chaque scénario en utilisant les ZC bonds simulés :
      - Jambe flottante : P(t,T0) - P(t,Tm)
      - Jambe fixe      : K * A(t) où A(t)=∑ Delta_i * P(t,Ti) (annuité)

    Puis :
      V(t) = N * w * (float_leg - fixed_leg)
    où w=+1 (payer) ou -1 (receiver).

    Paramètres
    ----------
    curve_sim :
        Objet expose zero_coupon_bond(t,T) -> ndarray(n_paths,)
    t :
        Date d'évaluation (années).
    Tau :
        Échéancier des paiements [T0, T1, ..., Tm] (T0 = start/expiry côté swap).
    K :
        Taux fixe (en unité de taux, ex 0.03).
    N :
        Notionnel.
    payer :
        True => payer swap (paye fixe, reçoit float).
        False => receiver swap.
    progress_cb :
        Callback optionnel pour mise à jour UI.
    progress_ctx :
        Dict de contexte (ex {"grid_i":..., "grid_n":...}) fusionné dans le payload.
    inner_progress :
        Si True, envoie des updates pendant la boucle d'annuité (cashflows).
    inner_every :
        Fréquence des updates "cashflows" (pour éviter trop d’appels UI).

    Retourne
    --------
    np.ndarray
        V(t) sur n_paths scénarios.
    """
    # Signe selon le sens du swap
    w = 1.0 if payer else -1.0

    t = float(t)
    K = float(K)
    N = float(N)

    # On garde uniquement les dates >= t (on "raccourcit" le swap à partir de t)
    Tau_rem = [float(Ti) for Ti in Tau if float(Ti) >= t - 1e-12]
    if len(Tau_rem) < 2:
        # Si le swap est "terminé" (plus de cashflows), MTM = 0 sur tous les scénarios
        return np.zeros(_get_n_paths(curve_sim), dtype=float)

    ctx = dict(progress_ctx or {})
    ctx.update({"t": t})

    # Bornes de la jambe flottante : T0 (start) et Tm (dernier paiement)
    T0 = Tau_rem[0]
    Tm = Tau_rem[-1]

    # ZC bonds simulés pour les deux bornes de la jambe flottante
    P_t_T0 = curve_sim.zero_coupon_bond(t, T0)
    P_t_Tm = curve_sim.zero_coupon_bond(t, Tm)

    # Calcul de l'annuité A(t) = ∑ Delta_i P(t,Ti)
    annuity = 0.0
    n_cf = max(len(Tau_rem) - 1, 0)

    for i in range(1, len(Tau_rem)):
        Ti = Tau_rem[i]
        Delta = Tau_rem[i] - Tau_rem[i - 1]

        # P(t,Ti) simulé (ndarray)
        P_t_Ti = curve_sim.zero_coupon_bond(t, Ti)

        # Contribution du cashflow à l'annuité
        annuity += Delta * P_t_Ti

        if inner_progress and progress_cb is not None and n_cf > 0:
            is_last = (i == len(Tau_rem) - 1)
            if is_last or (inner_every > 0 and (i % inner_every == 0)):
                payload = {
                    **ctx,
                    "stage": "cashflows",
                    "cf_i": int(i),
                    "cf_n": int(n_cf),
                    "Ti": float(Ti),
                }
                progress_cb(payload)

    # Jambe flottante en valeur (sur chaque scénario)
    float_leg = P_t_T0 - P_t_Tm

    # Jambe fixe en valeur (sur chaque scénario)
    fixed_leg = K * annuity

    # MTM du swap sur chaque path
    V_t = N * w * (float_leg - fixed_leg)
    return V_t


def pfe_profile_swap(
    curve_sim,
    grid,
    Tau,
    K: float,
    N: float,
    payer: bool = True,
    q: float = 0.95,
    progress_cb: Optional[Callable[[Dict[str, Any]], None]] = None,
    inner_progress: bool = False,
    inner_every: int = 3,
) -> tuple[np.ndarray, np.ndarray]:
    """
    Calcule un profil PFE_q(t) et EPE(t) sur une grille de temps.

    Définitions (sur V(t)^+ = max(V(t),0))
    --------------------------------------
    - PFE_q(t) = quantile_q(V(t)^+)
    - EPE(t)   = E[V(t)^+]

    Paramètres
    ----------
    curve_sim :
        Simulateur exposant zero_coupon_bond(t,T) -> ndarray.
    grid :
        Grille des dates (années) où on calcule l'exposition.
    Tau :
        Échéancier swap.
    K, N, payer :
        Spécifications du swap.
    q :
        Niveau de quantile (ex 0.95).
    progress_cb :
    inner_progress :
    inner_every :

    Retourne
    --------
    (pfe, epe) : tuple[np.ndarray, np.ndarray]
        Deux tableaux alignés avec grid.
    """
    # Chrono global (utile pour ETA)
    t0 = time.perf_counter()

    grid = np.asarray(grid, dtype=float)

    # Sorties
    pfe = np.zeros(len(grid), dtype=float)
    epe = np.zeros(len(grid), dtype=float)

    total_steps = int(len(grid))
    n_paths = _get_n_paths(curve_sim)

    # Boucle principale : un point de grille = un calcul de distribution V(t)
    for j, t in enumerate(grid, start=1):
        # Contexte de progression au niveau du nœud de grille
        ctx = {"grid_i": int(j), "grid_n": int(total_steps), "n_paths": int(n_paths)}

        # Distribution MTM du swap à t (ndarray n_paths)
        V_t = swap_mtm_distribution_at_t(
            curve_sim,
            float(t),
            Tau,
            K,
            N,
            payer=payer,
            progress_cb=progress_cb,
            progress_ctx=ctx,
            inner_progress=inner_progress,
            inner_every=inner_every,
        )

        # Exposition positive
        V_pos = np.maximum(V_t, 0.0)

        # PFE et EPE au temps t
        pfe_t = float(np.quantile(V_pos, q))
        epe_t = float(np.mean(V_pos))

        # Stockage
        pfe[j - 1] = pfe_t
        epe[j - 1] = epe_t

        if progress_cb is not None:
            elapsed = time.perf_counter() - t0
            pct = j / max(total_steps, 1)
            eta = (elapsed / pct - elapsed) if pct > 1e-12 else None

            progress_cb(
                {
                    "stage": "grid",
                    "grid_i": int(j),
                    "grid_n": int(total_steps),
                    "t": float(t),
                    "done": int(j),
                    "total": int(total_steps),
                    "pct": float(pct),
                    "elapsed_s": float(elapsed),
                    "eta_s": (float(eta) if eta is not None and np.isfinite(eta) else None),
                    "pfe_t": float(pfe_t),
                    "epe_t": float(epe_t),
                    "n_paths": int(n_paths),
                }
            )

    return pfe, epe


### FILE: streamlit_app\app.py
from __future__ import annotations

import sys
from pathlib import Path
import streamlit as st

# Ensure project root is importable (so "import ir...." works)
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from streamlit_app.ui.db import init_db

st.set_page_config(
    page_title="IR Lab | Hull-White",
    page_icon="📈",
    layout="wide",
    initial_sidebar_state="expanded",
)

init_db()

# --- Global sidebar ---
with st.sidebar:
    st.markdown("## IR Lab")
    st.caption("Hull–White 1F / 2F • Calibration • PFE • Tracking")

    tracking = st.toggle("📌 Portfolio tracking mode", value=True)
    st.session_state["tracking_mode"] = tracking

    st.divider()
    st.markdown("### Quick tips")
    st.markdown(
        "- Calibre dans **HW1F** ou **HW2F**\n"
        "- Va dans **PFE Swap** pour lancer l’expo\n"
        "- Sauvegarde un run dans **Portfolio Tracking**"
    )

st.title("📈 IR Lab — Hull–White Playground")
st.write(
    "Utilise le menu de gauche (pages) pour naviguer : calibration 1F/2F, PFE, tracking, explorer."
)

st.info(
    "Pages disponibles : Overview • Calibration HW1F • Calibration HW2F • PFE Swap • Portfolio Tracking • Project Explorer",
    icon="ℹ️",
)


### FILE: streamlit_app\__init__.py


### FILE: streamlit_app\pages\1_Overview.py
import streamlit as st

st.markdown("# Overview")
st.write(
    "Cette app expose :\n"
    "- Calibration Hull–White **1F** (a, sigma)\n"
    "- Calibration Hull–White **2F (G2++)** (a,b,rho) + inner (sigma,eta)\n"
    "- **PFE / EPE** swap via Monte Carlo (1F et 2F)\n"
    "- **Portfolio tracking** : historique de runs, comparaison, export\n"
    "- **Project explorer** : navigation dans le code"
)

st.success("Astuce : commence par `Calibration HW1F` ou `Calibration HW2F`, puis va sur `PFE Swap`.", icon="✅")


### FILE: streamlit_app\pages\2_Calibration_HW1F.py
from __future__ import annotations

from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st

from streamlit_app.ui.io import load_curve_and_swaption_from_upload
from streamlit_app.ui.capture import capture_stdout
from streamlit_app.ui.plotting import fig_curve, fig_prices_by_tenor, fig_vols_by_tenor

from ir.market.loaders_excel import load_curve_xlsx, load_swaption_template_xlsx
from ir.pricers.hw1f_pricer import HullWhitePricer
from ir.calibration.hw1f_calibration import HullWhiteCalibrator
from ir.calibration.vol import black_normal_vol
from streamlit_app.ui.db import save_run, curve_to_dict


# -----------------------------
# FICHIER PAR DÉFAUT (dans le repo)
# -----------------------------
# On définit un template local à utiliser si l’utilisateur n’upload rien dans l’UI.
ROOT = Path(__file__).resolve().parents[2]  # racine du projet
DEFAULT_REL = Path("Calibration_Templates") / "SWPN_Calibration_Template_30092025_USD.xlsx"
DEFAULT_XLSX = ROOT / DEFAULT_REL


def ensure_expiry_tenor(df: pd.DataFrame, dates_col="Payment_Dates"):
    """
    S'assure que le DataFrame contient des colonnes "Expiry" et "Tenor".

    - Expiry = T0 (première date de la schedule Tau)
    - Tenor  = Tn - T0 (maturité du swap sous-jacent)
    """
    if "Expiry" not in df.columns:
        df["Expiry"] = df[dates_col].apply(lambda L: float(L[0]))
    if "Tenor" not in df.columns:
        df["Tenor"] = df[dates_col].apply(lambda L: float(L[-1]) - float(L[0]))


def par_rate(curve, Tau):
    """
    Calcule (A0, S0) pour un échéancier fixe Tau=[T0,T1,...,Tn].

    - A0 : annuité à t=0, A0 = ∑ Delta_i * P(0,Ti)
    - S0 : swap rate par, S0 = (P(0,T0) - P(0,Tn)) / A0

    """
    Tau = [float(x) for x in Tau]
    T0, Tn = Tau[0], Tau[-1]

    A0 = 0.0
    for i in range(1, len(Tau)):
        Ti = Tau[i]
        d = Tau[i] - Tau[i - 1]
        A0 += d * float(curve.discount(Ti))

    S0 = (float(curve.discount(T0)) - float(curve.discount(Tn))) / (A0 + 1e-18)
    return A0, S0


def add_implied_normal_vols_forward_premium(
    df: pd.DataFrame,
    curve,
    price_col="Price",
    model_col="Model_Price",
    strike_col="Strike",
    dates_col="Payment_Dates",
):
    """
    Ajoute au DataFrame des volatilities implicites normales (Bachelier),
    calculées à partir :
      - du prix marché (price_col)  -> Market_Vol (Bps)
      - du prix modèle (model_col)  -> Model_Vol (Bps)

    Conventions (importantes)
    -------------------------
    Ici on suppose que les prix sont des "forward premiums" :
      - On calcule l'annuité "forward" : A_fwd = A0 / DF(T0)
      - forward_pct = 100 * S0   (en %)
      - strike_pct  = Strike     (déjà en % dans le template)

    Puis on inverse la formule de Bachelier via black_normal_vol().
    """
    mkt_vol, mdl_vol = [], []

    for _, row in df.iterrows():
        Tau = row[dates_col]
        T0 = float(Tau[0])

        # DF(0,T0) sert à transformer l'annuité en "annuité forward"
        DF0 = float(curve.discount(T0))

        # (A0,S0) à t=0 pour obtenir forward swap rate
        A0, S0 = par_rate(curve, Tau)
        annuity_fwd = A0 / (DF0 + 1e-18)

        # Le template est en % (Strike). On convertit aussi le forward en %.
        strike_pct = float(row[strike_col])     # %
        forward_pct = 100.0 * float(S0)         # %
        notional = float(row.get("Notional", 1.0))

        # Prix (forward premium) marché / modèle
        p_mkt = float(row[price_col])
        p_mdl = float(row[model_col])

        # Inversion Bachelier -> vol normale implicite (en bps)
        mkt_vol.append(black_normal_vol(p_mkt, forward_pct, strike_pct, T0, notional, annuity_fwd))
        mdl_vol.append(black_normal_vol(p_mdl, forward_pct, strike_pct, T0, notional, annuity_fwd))

    df["Market_Vol (Bps)"] = mkt_vol
    df["Model_Vol (Bps)"] = mdl_vol


# =============================
# UI STREAMLIT : PAGE CALIBRATION
# =============================
st.markdown("# Calibration — Hull–White 1F")
st.caption("Calibrage sur swaptions (forward premium) + plots + sauvegarde en session.")

# Mise en page: colonne gauche = inputs, colonne droite = visualisation + résultats
colL, colR = st.columns([1.0, 1.2], gap="large")

with colL:
    # Upload du template Excel : si absent, on utilisera DEFAULT_XLSX si présent
    uploaded = st.file_uploader("Upload SWPN calibration template (.xlsx)", type=["xlsx"])
    st.caption(
        f"Si aucun fichier n’est uploadé, l’app utilise par défaut : `{DEFAULT_REL.as_posix()}`"
        if DEFAULT_XLSX.exists()
        else "Aucun fichier par défaut trouvé dans `Calibration_Templates/`."
    )

    curve_sheet = st.text_input("Curve sheet", value="Curve")
    template_sheet = st.text_input("Template sheet", value="Template")
    smooth = st.number_input("Curve smoothing", value=1e-7, format="%.1e")

    st.divider()
    st.subheader("Calibration settings")

    # Initialisation de l'optimisation (point de départ)
    init_a = st.number_input("init a", value=0.01, format="%.6f")
    init_sigma = st.number_input("init sigma", value=0.01, format="%.6f")
    method = st.selectbox("Optimizer", ["L-BFGS-B", "Nelder-Mead"], index=0)

    do_calibrate = st.button("🚀 Run calibration (HW1F)", type="primary", use_container_width=True)

with colR:
    # -----------------------------
    # CHARGEMENT : upload OU fichier par défaut
    # -----------------------------
    if uploaded is not None:
        source_path, curve, swpn = load_curve_and_swaption_from_upload(
            uploaded, curve_sheet=curve_sheet, template_sheet=template_sheet, smooth=smooth
        )
        source_name = uploaded.name
    else:
        if not DEFAULT_XLSX.exists():
            st.info("Upload un fichier .xlsx pour commencer (template par défaut introuvable).", icon="📄")
            st.stop()

        st.info(
            f"Aucun fichier uploadé — utilisation du template par défaut : `{DEFAULT_REL.as_posix()}`",
            icon="📄",
        )
        source_path = str(DEFAULT_XLSX)
        source_name = DEFAULT_XLSX.name
        curve = load_curve_xlsx(source_path, sheet=curve_sheet, smooth=float(smooth))
        swpn = load_swaption_template_xlsx(source_path, sheet=template_sheet)

    st.session_state["last_source_file"] = source_name

    # Affichage courbe marché
    st.subheader("Courbe de Marché")
    st.pyplot(fig_curve(curve, title_prefix="Marché"), clear_figure=True)

    # Aperçu du template de calibration swaptions
    st.subheader("Aperçu du template de calibration")
    st.dataframe(swpn.df.head(15), use_container_width=True, height=260)

    status_ph = st.empty()
    progress_ph = st.empty()

    if do_calibrate:
        st.session_state["hw1f_progress_rows"] = []

        def progress_cb(d: dict):
            """
            Callback appelée à chaque itération de l'optimiseur (par le calibrator).
            - Met à jour un petit "status" texte
            - Affiche les 20 dernières itérations dans un tableau
            """
            rows = st.session_state.get("hw1f_progress_rows", [])
            rows.append(d)
            st.session_state["hw1f_progress_rows"] = rows

            status_ph.markdown(
                f"**Calibration en cours** — itération **{d['iter']}**  \n"
                f"`a={d['a']:.6f}`  |  `sigma={d['sigma']:.6f}`  |  `RMSRE={d['rmsre']:.2e}`"
            )

            dfp = pd.DataFrame(rows)
            progress_ph.dataframe(
                dfp.tail(20),
                use_container_width=True,
                hide_index=True,
                height=240,
            )

        # Exécution "longue" : on affiche un spinner et on capture les prints du calibrator
        with st.spinner("Calibration HW1F en cours..."):
            pricer_1f = HullWhitePricer(curve, n_paths=20000, seed=2025)

            # Conversion QuoteSet -> dict attendu par le calibrator
            mkt_dict = swpn.to_market_dict()

            cal = HullWhiteCalibrator(
                pricer_1f,
                mkt_dict,
                calibrate_to="Swaptions",
                progress_cb=progress_cb,
            )

            result_obj, logs = capture_stdout(
                cal.calibrate,
                init_a=init_a,
                init_sigma=init_sigma,
                method=method,
            )

            # On stocke les objets utiles en session pour les autres pages
            st.session_state["hw1f_pricer"] = pricer_1f
            st.session_state["hw1f_logs"] = logs
            st.session_state["hw1f_result"] = result_obj

        # Message final de statut (avec paramètres et RMSRE si possible)
        try:
            final_a = float(pricer_1f.model.parameters.get("a", np.nan))
            final_sigma = float(pricer_1f.model.parameters.get("sigma", np.nan))
            final_rmsre = float(getattr(result_obj, "fun", np.nan))
            status_ph.success(
                f"Calibration terminée ✅  |  a={final_a:.6f}  sigma={final_sigma:.6f}  RMSRE={final_rmsre:.2e}",
                icon="✅",
            )
        except Exception:
            status_ph.success("Calibration terminée ✅", icon="✅")

    # -----------------------------
    # SECTION "POST-RUN" : affichage des résultats si la calibration a déjà été lancée
    # -----------------------------
    if "hw1f_pricer" in st.session_state:
        pricer_1f = st.session_state["hw1f_pricer"]

        st.subheader("Calibration logs")
        with st.expander("Voir logs (print calibrator)", expanded=False):
            st.code(st.session_state.get("hw1f_logs", ""), language="text")

        rows = st.session_state.get("hw1f_progress_rows", [])
        if rows:
            with st.expander("Progress (itérations)", expanded=False):
                st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True, height=260)

        # Comparaison marché vs modèle (forward premium)
        st.subheader("Market vs Model")
        df_1f = swpn.with_model_prices_1f(pricer_1f, forward_premium=True)
        ensure_expiry_tenor(df_1f)

        st.dataframe(
            df_1f[["Expiry", "Tenor", "Strike", "Price", "Model_Price", "Rel_Error"]].head(30),
            use_container_width=True,
            height=260,
        )

        # Plot term structure des prix (par tenor)
        st.pyplot(
            fig_prices_by_tenor(df_1f, mkt_col="Price", model_col="Model_Price", ylabel="Forward Premium"),
            clear_figure=True,
        )

        # Calcul vol implicite (Bachelier) marché vs modèle, puis plot par tenor
        with st.spinner("Implied vols (Bachelier) ..."):
            dfv = df_1f.copy()
            add_implied_normal_vols_forward_premium(dfv, curve)

        st.pyplot(
            fig_vols_by_tenor(dfv, mkt_col="Market_Vol (Bps)", model_col="Model_Vol (Bps)"),
            clear_figure=True,
        )

        # Snapshot des paramètres calibrés + métrique d'erreur
        params = dict(pricer_1f.model.parameters)
        try:
            rmsre = float(getattr(st.session_state.get("hw1f_result", None), "fun", np.nan))
        except Exception:
            rmsre = None

        # On sauvegarde aussi un snapshot de courbe pour pouvoir relancer d'autres pages (PFE etc.)
        curve_snapshot = curve_to_dict(curve)
        st.session_state["last_curve_snapshot"] = curve_snapshot

        st.session_state["last_run"] = {
            "model": "HW1F",
            "source_file": st.session_state.get("last_source_file"),
            "params": params,
            "rmsre": rmsre,
            "artifacts": {},
            "curve_snapshot": curve_snapshot,
        }

        st.info("Tu peux maintenant aller sur **PFE Swap** (page 4).", icon="➡️")


### FILE: streamlit_app\pages\3_Calibration_HW2F.py
from __future__ import annotations

from pathlib import Path

import pandas as pd
import streamlit as st

from streamlit_app.ui.io import load_curve_and_swaption_from_upload
from streamlit_app.ui.capture import capture_stdout
from streamlit_app.ui.plotting import fig_curve, fig_prices_by_tenor, fig_vols_by_tenor

from ir.market.loaders_excel import load_curve_xlsx, load_swaption_template_xlsx
from ir.pricers.hw2f_pricer import HullWhite2FPricer
from ir.calibration.hw2f_profile import HullWhite2FProfileCalibrator
from ir.calibration.vol import black_normal_vol
from streamlit_app.ui.db import curve_to_dict


# -----------------------------
# FICHIER PAR DÉFAUT (dans le repo)
# -----------------------------
# Si l’utilisateur n’upload rien, on charge ce template local (si présent).
ROOT = Path(__file__).resolve().parents[2]  # racine du projet
DEFAULT_REL = Path("Calibration_Templates") / "SWPN_Calibration_Template_30092025_USD.xlsx"
DEFAULT_XLSX = ROOT / DEFAULT_REL


def ensure_expiry_tenor(df: pd.DataFrame, dates_col="Payment_Dates"):
    """
    Ajoute (si absentes) les colonnes :
      - Expiry = T0 (début de la schedule de paiement)
      - Tenor  = Tn - T0 (maturité du swap sous-jacent)

    Utile pour trier/plotter par (Expiry, Tenor) ensuite.
    """
    if "Expiry" not in df.columns:
        df["Expiry"] = df[dates_col].apply(lambda L: float(L[0]))
    if "Tenor" not in df.columns:
        df["Tenor"] = df[dates_col].apply(lambda L: float(L[-1]) - float(L[0]))


def par_rate(curve, Tau):
    """
    Calcule (A0, S0) à t=0 pour un échéancier fixe Tau=[T0, T1, ..., Tn].

    - A0 : annuité, A0 = ∑_{i=1..n} Delta_i * P(0,Ti)
    - S0 : taux swap par, S0 = (P(0,T0) - P(0,Tn)) / A0

    Retour :
      (A0, S0) en unités "rate" (S0 ~ 0.03)
    """
    Tau = [float(x) for x in Tau]
    T0, Tn = Tau[0], Tau[-1]

    A0 = 0.0
    for i in range(1, len(Tau)):
        Ti = Tau[i]
        d = Tau[i] - Tau[i - 1]
        A0 += d * float(curve.discount(Ti))

    S0 = (float(curve.discount(T0)) - float(curve.discount(Tn))) / (A0 + 1e-18)
    return A0, S0


def add_implied_normal_vols_forward_premium(
    df: pd.DataFrame,
    curve,
    price_col="Price",
    model_col="Model_Price",
    strike_col="Strike",
    dates_col="Payment_Dates",
):
    """
    Calcule des vols implicites normales (Bachelier) à partir des prix (forward premium).

    Hypothèse/convention :
      - Les prix comparés sont des "forward premiums" (PV/DF(T0)).
      - Pour l'inversion Bachelier, on utilise une "annuité forward" :
            annuity_fwd = A0 / DF(T0)

    Ajoute deux colonnes :
      - Market_Vol (Bps)
      - Model_Vol (Bps)
    """
    mkt_vol, mdl_vol = [], []

    for _, row in df.iterrows():
        Tau = row[dates_col]
        T0 = float(Tau[0])

        # DF0 sert à passer de l’annuité "PV" à une annuité "forward"
        DF0 = float(curve.discount(T0))

        # (A0,S0) pour calculer forward swap rate et annuity_fwd
        A0, S0 = par_rate(curve, Tau)
        annuity_fwd = A0 / (DF0 + 1e-18)

        # Strike du template en % ; forward en % aussi (pour black_normal_vol)
        strike_pct = float(row[strike_col])
        forward_pct = 100.0 * float(S0)

        # Notional : pris dans la ligne si existant, sinon 1.0
        notional = float(row.get("Notional", 1.0))

        # Prix forward premium (marché vs modèle)
        p_mkt = float(row[price_col])
        p_mdl = float(row[model_col])

        # Inversion Bachelier -> vols normales implicites en bps
        mkt_vol.append(black_normal_vol(p_mkt, forward_pct, strike_pct, T0, notional, annuity_fwd))
        mdl_vol.append(black_normal_vol(p_mdl, forward_pct, strike_pct, T0, notional, annuity_fwd))

    df["Market_Vol (Bps)"] = mkt_vol
    df["Model_Vol (Bps)"] = mdl_vol


# =============================
# UI STREAMLIT : PAGE HW2F
# =============================
st.markdown("# Calibration — Hull–White 2F (G2++)")
st.caption("Profile calibration : outer (a,b,rho) + inner (sigma,eta) + live progress.")

# Colonne gauche = inputs ; colonne droite = visualisation/résultats
colL, colR = st.columns([1.0, 1.2], gap="large")

with colL:
    # Upload du template excel
    uploaded = st.file_uploader("Upload SWPN calibration template (.xlsx)", type=["xlsx"], key="hw2f_upload")
    st.caption(
        f"Si aucun fichier n’est uploadé, l’app utilise par défaut : `{DEFAULT_REL.as_posix()}`"
        if DEFAULT_XLSX.exists()
        else "Aucun fichier par défaut trouvé dans `Calibration_Templates/`."
    )

    curve_sheet = st.text_input("Curve sheet", value="Curve", key="hw2f_curve_sheet")
    template_sheet = st.text_input("Template sheet", value="Template", key="hw2f_template_sheet")
    smooth = st.number_input("Curve smoothing", value=1e-7, format="%.1e", key="hw2f_smooth")

    st.divider()
    st.subheader("Outer grid (coarse)")

    # Grille grossière de recherche sur (a,b,rho) (profile calibration)
    grid_a = st.text_input("grid_a", value="0.01,0.02,0.05,0.10,0.20")
    grid_b = st.text_input("grid_b", value="0.001,0.003,0.01,0.02,0.05")
    grid_rho = st.text_input("grid_rho", value="-0.8,-0.5,-0.2,0.0,0.2")

    st.subheader("Inner init")
    init_sigma = st.number_input("init sigma", value=0.01, format="%.6f", key="hw2f_init_sigma")
    init_eta = st.number_input("init eta", value=0.008, format="%.6f", key="hw2f_init_eta")

    verbose_inner = st.checkbox("Verbose inner prints", value=False)
    top_k = st.number_input("top_k candidates printed", value=3, step=1, min_value=1)

    do_calibrate = st.button("🚀 Run profile calibration (HW2F)", type="primary", use_container_width=True)

with colR:
    # -----------------------------
    # CHARGEMENT : upload OU fichier par défaut
    # -----------------------------
    if uploaded is not None:
        source_path, curve, swpn = load_curve_and_swaption_from_upload(
            uploaded, curve_sheet=curve_sheet, template_sheet=template_sheet, smooth=smooth
        )
        source_name = uploaded.name
    else:
        if not DEFAULT_XLSX.exists():
            st.info("Upload un fichier .xlsx pour commencer (template par défaut introuvable).", icon="📄")
            st.stop()

        st.info(
            f"Aucun fichier uploadé — utilisation du template par défaut : `{DEFAULT_REL.as_posix()}`",
            icon="📄",
        )
        source_path = str(DEFAULT_XLSX)
        source_name = DEFAULT_XLSX.name
        curve = load_curve_xlsx(source_path, sheet=curve_sheet, smooth=float(smooth))
        swpn = load_swaption_template_xlsx(source_path, sheet=template_sheet)

    st.session_state["last_source_file"] = source_name

    # Affichage de la courbe
    st.subheader("Courbe de Marché")
    st.pyplot(fig_curve(curve, title_prefix="Marché"), clear_figure=True)

    # Aperçu du template
    st.subheader("Aperçu du template de calibration")
    st.dataframe(swpn.df.head(15), use_container_width=True, height=260)

    # Placeholders pour retour visuel (status + barre + tableau)
    status_ph = st.empty()
    bar_ph = st.progress(0)
    progress_ph = st.empty()

    if do_calibrate:
        st.session_state["hw2f_progress_rows"] = []

        def _parse_list(s: str):
            """
            Parse une chaîne "0.01,0.02,0.05" -> [0.01, 0.02, 0.05]
            """
            return [float(x.strip()) for x in s.split(",") if x.strip()]

        ga = _parse_list(grid_a)
        gb = _parse_list(grid_b)
        gr = _parse_list(grid_rho)

        def progress_cb(d: dict):
            """
            Callback appelée par le calibrator HW2F pendant la boucle outer.

            - Met à jour une barre de progression basée sur outer_idx/outer_total
            - Affiche un statut texte (candidat courant + best RMSRE)
            - Affiche un tableau "dernier historique" (tail 25)
            """
            rows = st.session_state.get("hw2f_progress_rows", [])
            rows.append(d)
            st.session_state["hw2f_progress_rows"] = rows

            outer_idx = int(d.get("outer_idx", 0) or 0)
            outer_total = int(d.get("outer_total", 0) or 0)
            pct = 0
            if outer_total > 0:
                pct = int(round(100 * outer_idx / max(outer_total, 1)))
            bar_ph.progress(min(max(pct, 0), 100))

            # Informations candidates
            stage = d.get("stage", "")
            a = d.get("a", None)
            b = d.get("b", None)
            rho = d.get("rho", None)
            cand_rmsre = d.get("cand_rmsre", None)
            best_rmsre = d.get("best_rmsre", None)
            improved = d.get("improved", False)

            # Message de statut selon étape
            if stage == "outer_start":
                status_ph.markdown(
                    f"**HW2F calibration en cours** — candidat **{outer_idx}/{outer_total}** ({pct}%)  \n"
                    f"`a={a:.6f}` | `b={b:.6f}` | `rho={rho:.3f}`  \n"
                    f"Best RMSRE so far: `{(best_rmsre if best_rmsre is not None else float('nan')):.2e}`"
                )
            elif stage == "outer_done":
                status_ph.markdown(
                    f"**HW2F calibration en cours** — candidat **{outer_idx}/{outer_total}** ({pct}%)  \n"
                    f"`a={a:.6f}` | `b={b:.6f}` | `rho={rho:.3f}`  \n"
                    f"Cand RMSRE: `{(cand_rmsre if cand_rmsre is not None else float('nan')):.2e}`  |  "
                    f"Best: `{(best_rmsre if best_rmsre is not None else float('nan')):.2e}`"
                    + ("  ✅ **NEW BEST**" if improved else "")
                )
            else:
                status_ph.markdown(f"**HW2F calibration** — {outer_idx}/{outer_total} ({pct}%)")

            # Tableau des dernières lignes de progression
            dfp = pd.DataFrame(rows)
            cols = [
                c
                for c in [
                    "stage",
                    "outer_idx",
                    "outer_total",
                    "a",
                    "b",
                    "rho",
                    "cand_rmsre",
                    "best_rmsre",
                    "improved",
                ]
                if c in dfp.columns
            ]
            progress_ph.dataframe(
                dfp[cols].tail(25) if cols else dfp.tail(25),
                use_container_width=True,
                hide_index=True,
                height=260,
            )

        # Lancement calibration (avec spinner) et capture des prints
        with st.spinner("Calibration HW2F (profile) en cours..."):
            # Pricer 2F : ici analytique (approx swap-rate) / ZC options
            pricer_2f = HullWhite2FPricer(curve)

            # QuoteSet -> dict marché attendu par le calibrator
            mkt_dict = swpn.to_market_dict()

            # Calibrator profile (outer grid + inner optimization)
            cal = HullWhite2FProfileCalibrator(
                pricer_2f,
                mkt_dict,
                use_forward_premium=True,
                progress_cb=progress_cb,
            )

            # Exécute et récupère (résultat, logs)
            res, logs = capture_stdout(
                cal.calibrate_profile,
                grid_a=ga,
                grid_b=gb,
                grid_rho=gr,
                init_sigma=init_sigma,
                init_eta=init_eta,
                verbose_inner=verbose_inner,
                top_k=int(top_k),
            )

            st.session_state["hw2f_pricer"] = pricer_2f
            st.session_state["hw2f_logs"] = logs
            st.session_state["hw2f_profile_res"] = res

        # Message final (si possible avec best rmsre)
        try:
            best = (res or {}).get("best", {}) if isinstance(res, dict) else {}
            bar_ph.progress(100)
            status_ph.success(
                f"Calibration terminée ✅  |  Best RMSRE={(best.get('rmsre', float('nan'))):.2e}",
                icon="✅",
            )
        except Exception:
            bar_ph.progress(100)
            status_ph.success("Calibration terminée ✅", icon="✅")

    # -----------------------------
    # SECTION "POST-RUN" : affichage résultats si un run existe en session
    # -----------------------------
    if "hw2f_pricer" in st.session_state:
        pricer_2f = st.session_state["hw2f_pricer"]
        res = st.session_state.get("hw2f_profile_res", {})
        best = (res or {}).get("best", {})

        st.subheader("Calibration logs")
        with st.expander("Voir logs (print calibrator)", expanded=False):
            st.code(st.session_state.get("hw2f_logs", ""), language="text")

        # Historique candidats outer 
        rows = st.session_state.get("hw2f_progress_rows", [])
        if rows:
            with st.expander("Progress (candidats outer)", expanded=False):
                st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True, height=320)

        # Paramètres best (a,b,rho,sigma,eta,rmsre) renvoyés par le calibrator
        st.subheader("Best parameters")
        st.json(best)

        # Comparaison mkt vs modèle : pricing 2F (swaption approx) sur tout le template
        st.subheader("Market vs Model")
        df_2f = swpn.with_model_prices_2f(pricer_2f, forward_premium=True)
        ensure_expiry_tenor(df_2f)

        st.dataframe(
            df_2f[["Expiry", "Tenor", "Strike", "Price", "Model_Price", "Rel_Error"]].head(30),
            use_container_width=True,
            height=260,
        )

        # Plots prix et vols vs expiries (par tenor)
        st.pyplot(
            fig_prices_by_tenor(df_2f, mkt_col="Price", model_col="Model_Price", ylabel="Forward Premium"),
            clear_figure=True,
        )

        with st.spinner("Implied vols (Bachelier) ..."):
            dfv = df_2f.copy()
            add_implied_normal_vols_forward_premium(dfv, curve)

        st.pyplot(
            fig_vols_by_tenor(dfv, mkt_col="Market_Vol (Bps)", model_col="Model_Vol (Bps)"),
            clear_figure=True,
        )

        params = dict(pricer_2f.model.parameters)
        rmsre = best.get("rmsre", None)

        curve_snapshot = curve_to_dict(curve)
        st.session_state["last_curve_snapshot"] = curve_snapshot

        st.session_state["last_run"] = {
            "model": "HW2F",
            "source_file": st.session_state.get("last_source_file"),
            "params": params,
            "rmsre": rmsre,
            "artifacts": {},
            "curve_snapshot": curve_snapshot,
        }

        st.info("Tu peux maintenant aller sur **PFE Swap** (page 4).", icon="➡️")


### FILE: streamlit_app\pages\4_PFE_Swap.py
# streamlit_app/pages/4_PFE_Swap.py
from __future__ import annotations

import numpy as np
import pandas as pd
import streamlit as st

from streamlit_app.ui.plotting import fig_pfe
from streamlit_app.ui.db import list_runs, get_run, format_run_label, curve_from_dict

from ir.risk.pfe_swap import pfe_profile_swap
from ir.risk.hw2f_sim import HW2FCurveSim
from ir.pricers.hw1f_pricer import HullWhitePricer
from ir.pricers.hw2f_pricer import HullWhite2FPricer


# =============================
# PAGE : PFE SWAP
# =============================
st.markdown("# PFE Swap")
st.caption("Calcule PFE/EPE pour un swap vanilla, en réutilisant un run (session ou DB) sans recalibrer.")

# -------------------------
# 1) Sélection de la source du run
# -------------------------
# Objectif : récupérer (modèle, params, courbe) depuis :
#   - Session (last_run) : résultat de la calibration HW1F/HW2F en session
#   - Database : runs sauvegardés en base (via pages calibration)
st.subheader("Run source")

src = st.radio(
    "Choix des paramètres modèle/courbe",
    ["Session (last calibration)", "Database (saved runs)"],
    horizontal=True,
)

selected_run = None
run_model = None
run_params = None
run_curve = None

if src.startswith("Session"):
    last_run = st.session_state.get("last_run", None)
    if last_run is None:
        st.warning(
            "Aucun `last_run` en session. Va d’abord sur Calibration HW1F/HW2F (pages 2/3) ou charge un run DB.",
            icon="⚠️",
        )
    else:
        selected_run = last_run
        run_model = last_run.get("model")
        run_params = last_run.get("params")
        run_curve = None  
        st.info(f"Run session détecté: model={run_model}, source={last_run.get('source_file')}", icon="🧠")

else:
    # Cas DB : on liste les runs sauvegardés et on en charge un
    runs = list_runs(limit=200)
    if not runs:
        st.warning("Aucun run en DB. Sauvegarde un run depuis Calibration HW1F/HW2F.", icon="⚠️")
    else:
        options = {format_run_label(r): r["id"] for r in runs}
        label = st.selectbox("Sélectionne un run", list(options.keys()))
        rid = int(options[label])
        db_run = get_run(rid)
        if db_run is None:
            st.error("Run introuvable en DB (id invalide).")
        else:
            if not db_run.get("curve") or not db_run.get("params"):
                st.error("Run DB incomplet: il manque `curve` ou `params`. Re-sauvegarde un run avec la version patchée.")
            else:
                selected_run = db_run
                run_model = db_run.get("model")
                run_params = db_run.get("params")
                run_curve = curve_from_dict(db_run.get("curve"))  # reconstruction Curve depuis dict JSON
                st.success(f"Run DB chargé ✅  (id={rid}, model={run_model})", icon="✅")

st.divider()

# -------------------------
# 2) Inputs du swap + paramètres Monte Carlo
# -------------------------
# On définit le swap (notional, K, schedule Tau) + la grille de temps pour calculer PFE/EPE
st.subheader("Swap inputs")

col1, col2, col3, col4 = st.columns(4)

with col1:
    q = st.slider("Quantile q", min_value=0.90, max_value=0.995, value=0.95, step=0.005)
    payer = st.checkbox("Payer swap", value=True)

with col2:
    notional = st.number_input("Notional", value=1_000_000.0, step=100_000.0)
    K = st.number_input("Fixed rate K (rate units)", value=0.03, format="%.6f")

with col3:
    grid_n = st.number_input("Grid points", value=21, min_value=5, step=1)
    tau_str = st.text_input("Tau schedule (years)", value="0.0,0.5,1.0,1.5,2.0,2.5,3.0,3.5,4.0,4.5,5.0")

with col4:
    # Paramètres MC génériques (valables 1F et 2F côté simulateur)
    n_paths = st.number_input("MC paths", value=20000, min_value=1000, step=1000)
    seed = st.number_input("Seed", value=2025, step=1)
    n_steps_1f = st.number_input("HW1F steps (Euler)", value=252, min_value=50, step=10)


def _parse_tau(s: str):
    """Parse '0.0,0.5,1.0' -> [0.0,0.5,1.0]."""
    return [float(x.strip()) for x in s.split(",") if x.strip()]


Tau = _parse_tau(tau_str)
grid = np.linspace(0.0, float(Tau[-1]), int(grid_n))

st.divider()

# -------------------------
# 3) Options d'affichage de la progression
# -------------------------
# pfe_profile_swap a été patché pour accepter un progress_cb optionnel,
# avec un mode détaillé (par cashflow) quand la schedule est longue.
st.subheader("Run controls")

colA, colB, colC = st.columns([1.0, 1.0, 1.2])

with colA:
    inner_progress = st.checkbox(
        "Show detailed progress (per cashflow)",
        value=False,
        help="Affiche une progression plus fine (à l'intérieur de chaque point de grille). Peut être un peu plus lent côté UI.",
    )

with colB:
    inner_every = st.number_input(
        "Update frequency (cashflows)",
        value=3,
        min_value=1,
        step=1,
        help="Si le mode détaillé est activé: update toutes les N cashflows.",
    )

with colC:
    show_table = st.checkbox(
        "Show progress table",
        value=True,
        help="Affiche un mini tableau des derniers updates (utile pour diagnostiquer si ça bloque).",
    )

status_ph = st.empty()
bar_ph = st.empty()
table_ph = st.empty()


def _run_with_progress(curve_sim, title: str):
    """
    Lance pfe_profile_swap en branchant un callback Streamlit pour :
      - barre de progression
      - statut texte (grid/cashflows)
      - mini table des events
    """
    st.session_state["pfe_progress_rows"] = []
    prog = bar_ph.progress(0, text="Initialisation Monte Carlo...")

    def progress_cb(d: dict):
        rows = st.session_state.get("pfe_progress_rows", [])
        rows.append(d)
        st.session_state["pfe_progress_rows"] = rows

        stage = d.get("stage", "grid")
        pct = d.get("pct", None)

        if pct is not None:
            pct_int = int(max(0, min(100, round(100 * float(pct)))))
            prog.progress(pct_int, text=f"{title} — {pct_int}%")
        else:
            prog.progress(0, text=f"{title} — ...")

        if stage == "cashflows":
            gi = d.get("grid_i", "?")
            gn = d.get("grid_n", "?")
            cf_i = d.get("cf_i", "?")
            cf_n = d.get("cf_n", "?")
            t = d.get("t", None)
            Ti = d.get("Ti", None)
            status_ph.markdown(
                f"**{title} — simulation en cours**  \n"
                f"- Grid: **{gi}/{gn}** (t={float(t):.4f})  \n"
                f"- Cashflows: **{cf_i}/{cf_n}** (Ti={float(Ti):.4f})"
            )
        else:
            gi = d.get("grid_i", "?")
            gn = d.get("grid_n", "?")
            t = d.get("t", None)
            pfe_t = d.get("pfe_t", None)
            epe_t = d.get("epe_t", None)
            status_ph.markdown(
                f"**{title} — grid {gi}/{gn}** (t={float(t):.4f})  \n"
                f"- PFE={float(pfe_t):,.0f}  |  EPE={float(epe_t):,.0f}"
            )

        if show_table and rows:
            tail = pd.DataFrame(rows).tail(25)
            table_ph.dataframe(tail, use_container_width=True, hide_index=True, height=240)

    pfe, epe = pfe_profile_swap(
        curve_sim=curve_sim,
        grid=grid,
        Tau=Tau,
        K=float(K),
        N=float(notional),
        payer=bool(payer),
        q=float(q),
        progress_cb=progress_cb,
        inner_progress=bool(inner_progress),
        inner_every=int(inner_every),
    )
    prog.progress(100, text=f"{title} — done ✅")
    return pfe, epe


# -------------------------
# 4) Reconstruction d'un "curve_sim" à partir du run sélectionné
# -------------------------
# Ici on évite TOTALEMENT la recalibration :
#   - HW1F: on construit un HullWhitePricer avec params + curve -> curve_sim (HullWhiteCurveBuilder)
#   - HW2F: on construit un HullWhite2FPricer (analytique) + un HW2FCurveSim (MC sur x,y)
def _build_curve_sim_from_selected_run():
    if selected_run is None:
        return None, None

    model = (run_model or "").strip()

    # --- Courbe ---
    # DB : déjà reconstruite via curve_from_dict
    # Session : on essaie (a) snapshot de courbe dans last_run, sinon (b) pricer en session_state
    if run_curve is not None:
        curve = run_curve
    else:
        snap = selected_run.get("curve", None)
        if snap:
            curve = curve_from_dict(snap)
        else:
            if model == "HW1F" and "hw1f_pricer" in st.session_state:
                curve = st.session_state["hw1f_pricer"].curve
            elif model == "HW2F" and "hw2f_pricer" in st.session_state:
                curve = st.session_state["hw2f_pricer"].curve
            else:
                st.error("Impossible de reconstruire la courbe: ni snapshot `curve`, ni pricer en session.")
                return None, None

    # --- Paramètres ---
    params = run_params or selected_run.get("params", None)
    if not isinstance(params, dict):
        st.error("Paramètres modèle manquants/incohérents dans le run.")
        return None, None

    # --- Construction simulateur selon modèle ---
    if model == "HW1F":
        # On (re)crée un pricer 1F uniquement pour récupérer curve_sim (et le model params)
        pricer = HullWhitePricer(
            curve,
            n_paths=int(n_paths),
            n_steps=int(n_steps_1f),
            seed=int(seed),
            hw_params=params,
        )
        return pricer.curve_sim, {"curve": curve, "model": "HW1F", "params": pricer.model.parameters}

    if model == "HW2F":
        # Pricer 2F -> fournit model (paramètres + fonctions fermées)
        pricer2 = HullWhite2FPricer(curve, hw2f_params=params)

        # Simu 2F : distribution de P(t,T) via tirages (x_t, y_t)
        curve_sim_2f = HW2FCurveSim(
            curve=curve,
            model=pricer2.model,
            n_paths=int(n_paths),
            seed=int(seed),
            use_legacy_global_seed=True, 
        )
        return curve_sim_2f, {"curve": curve, "model": "HW2F", "params": pricer2.model.parameters}

    st.error(f"Model inconnu dans le run: {model!r}")
    return None, None


# -------------------------
# 5) Bouton "Run" + affichage résultats
# -------------------------
do_run = st.button("🚀 Run PFE (no recalibration)", type="primary", use_container_width=True)

if do_run:
    curve_sim, info = _build_curve_sim_from_selected_run()
    if curve_sim is None:
        st.stop()

    st.subheader("Run info")
    st.json(
        {
            "model": info["model"],
            "params": info["params"],
            "mc": {"n_paths": int(n_paths), "seed": int(seed), "n_steps_1f": int(n_steps_1f)},
            "swap": {"payer": bool(payer), "N": float(notional), "K": float(K), "Tau": Tau},
            "grid_n": int(grid_n),
            "q": float(q),
        }
    )

    # Lancement PFE/EPE + UI progress
    with st.spinner("PFE en cours..."):
        title = f"{info['model']} | PFE swap"
        pfe, epe = _run_with_progress(curve_sim, title=title)

    st.success("Terminé ✅", icon="✅")

    # Affichage des résultats + export
    st.subheader("Results")
    df_out = pd.DataFrame({"t": grid, "PFE": pfe, "EPE": epe})
    st.dataframe(df_out, use_container_width=True, height=260)

    st.pyplot(fig_pfe(grid, pfe, epe=epe, q=float(q), title=title), clear_figure=True)

    st.download_button(
        "⬇️ Download results (CSV)",
        data=df_out.to_csv(index=False).encode("utf-8"),
        file_name="pfe_swap.csv",
        mime="text/csv",
        use_container_width=True,
    )


### FILE: streamlit_app\pages\5_Portfolio_Tracking.py
from __future__ import annotations

import pandas as pd
import streamlit as st

# DB helpers (SQLite local) :
# - list_runs()   : liste des runs disponibles (métadonnées)
# - save_run(...) : sauvegarde un run (params + curve snapshot + artifacts + notes)
# - get_run(id)   : charge un run complet
# - delete_run(id): supprime un run
from streamlit_app.ui.db import list_runs, save_run, get_run, delete_run

# =============================
# PAGE : PORTFOLIO TRACKING
# =============================
st.markdown("# Portfolio Tracking")
st.caption("Historique des calibrations/PFE (local SQLite). Comparaison simple et export.")

# On récupère ce qui a été produit dans la session par les pages Calibration / PFE
# last_run : dict avec model, params, rmsre, curve_snapshot, etc.
# last_pfe : éventuel artefact PFE (stocké en session quand on lance la page PFE)
last_run = st.session_state.get("last_run", None)
last_pfe = st.session_state.get("last_pfe", None)

# Mise en page : gauche = sauvegarde session ; droite = historique + comparaison
colA, colB = st.columns([1.0, 1.2], gap="large")

# -------------------------
# 1) Sauvegarder le run courant (session -> DB)
# -------------------------
with colA:
    st.subheader("Save current session run")

    # S'il n'y a pas de calibration récente, rien à sauver
    if last_run is None:
        st.info("Aucun run en session (calibre d’abord HW1F/HW2F).", icon="ℹ️")
    else:
        default_label = f"{last_run['model']} | {last_run.get('source_file','')}"
        label = st.text_input("Label", value=default_label)
        notes = st.text_area("Notes", value="", height=120)
        artifacts = dict(last_run.get("artifacts", {}) or {})
        if last_pfe is not None:
            artifacts["pfe"] = last_pfe

        curve_snapshot = last_run.get("curve_snapshot", None) or st.session_state.get("last_curve_snapshot", None)

        if st.button("💾 Save run", type="primary", use_container_width=True):
            if curve_snapshot is None:
                st.error(
                    "Impossible de sauver : curve_snapshot absent. "
                    "Relance une calibration (HW1F/HW2F) après avoir appliqué le patch.",
                    icon="⚠️",
                )
            else:
                # Sauvegarde DB
                run_id = save_run(
                    label=label,
                    model=last_run["model"],
                    source_file=last_run.get("source_file"),
                    rmsre=last_run.get("rmsre"),
                    curve_snapshot=curve_snapshot,
                    params=last_run.get("params", {}),
                    artifacts=artifacts,
                    notes=notes,
                    meta={},  
                )
                st.success(f"Saved ✅ (id={run_id})", icon="✅")
                st.rerun()

# -------------------------
# 2) Historique des runs (DB) + comparaison A/B + suppression
# -------------------------
with colB:
    st.subheader("Runs history")

    # Liste brute des runs (métadonnées) -> dataframe
    runs = list_runs()
    df = pd.DataFrame(runs)
    st.dataframe(df, use_container_width=True, height=260)

    # Si DB vide : on stoppe la page ici
    if df.empty:
        st.stop()

    # Sélection simple (IDs)
    ids = df["id"].astype(int).tolist()
    pick1 = st.selectbox("Select run A", ids, index=0)
    pick2 = st.selectbox("Select run B (optional)", [None] + ids, index=0)

    # --- Run A ---
    runA = get_run(int(pick1))
    st.markdown("### Run A")
    # Affichage résumé (métadonnées clés)
    st.json({k: runA.get(k) for k in ["id", "created_at", "label", "model", "source_file", "rmsre"]})
    # Paramètres modèle (a/sigma/... ou a,b,rho,sigma,eta,...)
    st.json(runA.get("params", {}))

    # --- Run B (optionnel) + diff ---
    if pick2 is not None:
        runB = get_run(int(pick2))
        st.markdown("### Run B")
        st.json({k: runB.get(k) for k in ["id", "created_at", "label", "model", "source_file", "rmsre"]})
        st.json(runB.get("params", {}))

        st.markdown("### Diff (params)")
        keys = sorted(set(runA.get("params", {}).keys()) | set(runB.get("params", {}).keys()))
        rows = []
        for k in keys:
            a = runA.get("params", {}).get(k, None)
            b = runB.get("params", {}).get(k, None)
            rows.append({"param": k, "A": a, "B": b})
        st.dataframe(pd.DataFrame(rows), use_container_width=True, height=260)

    st.divider()

    # Suppression du run A (action destructive => bouton dédié)
    if st.button("🗑️ Delete run A"):
        delete_run(int(pick1))
        st.warning("Deleted run A.", icon="🗑️")
        st.rerun()


### FILE: streamlit_app\pages\6_Documentation.py
from __future__ import annotations

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import streamlit as st

# Panneau de doc "manuel" + registry JSON 
from streamlit_app.ui.code_docs import render_doc_panel, load_docs_registry

ROOT = Path(__file__).resolve().parents[2]

# Extensions que l’on sait "prévisualiser proprement" 
TEXT_EXTS = {
    ".py": "python",
    ".ipynb": "ipynb",
    ".md": "markdown",
    ".txt": "text",
    ".json": "json",
    ".yaml": "yaml",
    ".yml": "yaml",
    ".toml": "toml",
    ".ini": "ini",
    ".cfg": "ini",
}

# Limite de preview (pour éviter de faire exploser la mémoire / UI)
MAX_PREVIEW_BYTES = 1_200_000  # ~1.2MB

# Options UI 
SHOW_META = True
WRAP_LINES = False  


# -------------------------
# Helpers formatting
# -------------------------
def _fmt_bytes(n: int) -> str:
    """Affichage lisible d'une taille en octets."""
    if n < 1024:
        return f"{n} B"
    if n < 1024 * 1024:
        return f"{n/1024:.1f} KB"
    return f"{n/(1024*1024):.2f} MB"


def _fmt_dt(ts: float) -> str:
    """Affichage lisible d'un timestamp (mtime)."""
    return datetime.fromtimestamp(ts).strftime("%Y-%m-%d %H:%M:%S")


def _read_text_safely(path: Path, max_bytes: int = MAX_PREVIEW_BYTES) -> Tuple[str, bool]:
    """
    Lit un fichier en bytes puis décode UTF-8 (avec replacement).
    Retourne (text, truncated) où truncated=True si on a coupé à max_bytes.
    """
    b = path.read_bytes()
    truncated = False
    if len(b) > max_bytes:
        b = b[:max_bytes]
        truncated = True
    text = b.decode("utf-8", errors="replace")
    return text, truncated


# -------------------------
# Notebook rendering (.ipynb)
# -------------------------
def _render_notebook(path: Path) -> None:
    """
    Rend un .ipynb en mode "lecture" :
      - cellules markdown via st.markdown
      - cellules code via st.code
    """
    raw, truncated = _read_text_safely(path)
    if truncated:
        st.warning(
            f"Notebook trop volumineux : preview tronquée à {_fmt_bytes(MAX_PREVIEW_BYTES)}. "
            "Tu peux le télécharger pour l’ouvrir complet.",
            icon="⚠️",
        )

    # Le .ipynb est du JSON
    try:
        nb = json.loads(raw)
    except Exception:
        st.error("Impossible de parser ce .ipynb (JSON invalide).", icon="❌")
        st.code(raw, language="json")
        return

    cells = nb.get("cells", [])
    if not isinstance(cells, list):
        st.error("Format .ipynb inattendu (cells manquant).", icon="❌")
        st.code(raw, language="json")
        return

    # Toggle simple pour éviter de spammer l’UI
    show_outputs = st.checkbox("Afficher outputs", value=False)
    st.divider()

    for i, cell in enumerate(cells, start=1):
        cell_type = cell.get("cell_type", "")
        src = cell.get("source", "")

        if isinstance(src, list):
            src_text = "".join(src)
        else:
            src_text = str(src)

        if cell_type == "markdown":
            if src_text.strip():
                st.markdown(src_text)

        elif cell_type == "code":
            st.markdown(f"**In [{i}]**")
            st.code(src_text, language="python")

            if show_outputs:
                outs = cell.get("outputs", [])
                if isinstance(outs, list) and outs:
                    for out in outs:
                        otype = out.get("output_type", "")

                        if otype == "stream":
                            txt = out.get("text", "")
                            if isinstance(txt, list):
                                txt = "".join(txt)
                            st.code(str(txt), language="text")

                        elif otype in ("execute_result", "display_data"):
                            data = out.get("data", {})
                            txt = None
                            if isinstance(data, dict):
                                txt = data.get("text/plain", None)
                            if txt is not None:
                                if isinstance(txt, list):
                                    txt = "".join(txt)
                                st.code(str(txt), language="text")

                        elif otype == "error":
                            tb = out.get("traceback", [])
                            if isinstance(tb, list):
                                st.code("\n".join(tb), language="text")

        else:
            continue


def _language_for(path: Path) -> str:
    """Retourne le langage (string) pour st.code en fonction de l'extension."""
    ext = path.suffix.lower()
    if ext == ".ipynb":
        return "json"
    return TEXT_EXTS.get(ext, "text")


def _meta_for_rel(rel: str) -> Optional[Dict]:
    """
    Construit une petite fiche meta sur un fichier relpath depuis ROOT.
    Retourne None si:
      - fichier inexistant
      - extension non supportée
      - erreur I/O
    """
    p = ROOT / rel
    if not p.exists() or not p.is_file():
        return None

    ext = p.suffix.lower()
    if ext not in TEXT_EXTS:
        return None

    try:
        stt = p.stat()
        size = int(stt.st_size)
        mtime = float(stt.st_mtime)
    except OSError:
        return None

    n_lines: Optional[int] = None
    if ext != ".ipynb" and size <= 400_000:
        try:
            txt = p.read_text(encoding="utf-8", errors="ignore")
            n_lines = txt.count("\n") + 1 if txt else 0
        except Exception:
            n_lines = None

    return {
        "rel": rel,
        "path": str(p),
        "ext": ext,
        "size": size,
        "mtime": mtime,
        "lines": n_lines,
    }


# =============================
# UI
# =============================
st.markdown("# Documentation")
st.caption("Affiche la documentation des fichiers principaux du projet.")

# 1) On charge la registry (JSON) : c’est la source de vérité des fichiers documentés
registry = load_docs_registry()
registry_rels = sorted([k for k in registry.keys() if isinstance(k, str) and k.strip()])

if not registry_rels:
    st.error("docs_registry.json est vide (aucun fichier référencé).", icon="❌")
    st.stop()

all_files: List[Dict] = []
missing: List[str] = []
skipped: List[str] = []

for rel in registry_rels:
    m = _meta_for_rel(rel)
    if m is None:
        p = ROOT / rel
        if not p.exists():
            missing.append(rel)
        else:
            skipped.append(rel)
        continue
    all_files.append(m)

# Messages "diagnostic" si registry contient des entrées non affichables
if missing:
    st.warning(
        "Certains fichiers sont référencés dans docs_registry.json mais introuvables sur disque :\n"
        + "\n".join([f"- {x}" for x in missing]),
        icon="⚠️",
    )

if skipped:
    st.info(
        "Certains fichiers référencés sont ignorés (extension non supportée pour preview) :\n"
        + "\n".join([f"- {x}" for x in skipped]),
        icon="ℹ️",
    )

if not all_files:
    st.error("Aucun fichier affichable (tous manquants ou ignorés).", icon="❌")
    st.stop()

rels = [d["rel"] for d in all_files]

# -------------------------
# Sélection + navigation (Prev / Next)
# -------------------------
if "px_choice" not in st.session_state:
    st.session_state["px_choice"] = rels[0]
if st.session_state["px_choice"] not in rels:
    st.session_state["px_choice"] = rels[0]

nav1, nav2, nav3, nav4 = st.columns([0.18, 0.18, 1.0, 0.28], gap="small")

with nav1:
    if st.button("⬅️ Prev", use_container_width=True):
        i = rels.index(st.session_state["px_choice"])
        st.session_state["px_choice"] = rels[max(0, i - 1)]

with nav2:
    if st.button("Next ➡️", use_container_width=True):
        i = rels.index(st.session_state["px_choice"])
        st.session_state["px_choice"] = rels[min(len(rels) - 1, i + 1)]

with nav4:
    st.caption(f"{rels.index(st.session_state['px_choice']) + 1} / {len(rels)}")

choice = st.selectbox(
    "Select file",
    rels,
    index=rels.index(st.session_state["px_choice"]),
)
st.session_state["px_choice"] = choice

path = ROOT / choice
meta = next(d for d in all_files if d["rel"] == choice)

# -------------------------
# Header + actions
# -------------------------
st.write(f"**{choice}**")

if SHOW_META:
    st.caption(
        f"Ext: `{meta['ext']}`  |  Size: {_fmt_bytes(meta['size'])}  |  "
        f"Modified: {_fmt_dt(meta['mtime'])}"
        + (f"  |  Lines: {meta['lines']}" if meta.get("lines") is not None else "")
    )

# Bouton de download (utile si preview tronquée)
try:
    file_bytes = path.read_bytes()
    st.download_button(
        "⬇️ Download file",
        data=file_bytes,
        file_name=path.name,
        mime="text/plain",
        use_container_width=False,
    )
except Exception:
    st.warning("Impossible de préparer le téléchargement (droits/IO).", icon="⚠️")

# -------------------------
# Preview + doc panel
# -------------------------
ext = path.suffix.lower()

# Layout : à gauche preview, à droite doc manuelle (docs_registry + annotations)
left, right = st.columns([1.35, 0.85], gap="large")

with left:
    st.subheader("Preview")

    # Cas notebook : soit rendu, soit JSON brut
    if ext == ".ipynb":
        view_mode = st.radio("Notebook view", ["Rendered", "Raw JSON"], horizontal=True, index=0)
        if view_mode == "Rendered":
            _render_notebook(path)
        else:
            raw, truncated = _read_text_safely(path)
            if truncated:
                st.warning(
                    f"Preview tronquée à {_fmt_bytes(MAX_PREVIEW_BYTES)} (notebook trop volumineux).",
                    icon="⚠️",
                )
            st.code(raw, language="json")

    # Cas fichiers texte : preview direct
    else:
        try:
            content, truncated = _read_text_safely(path)
            if truncated:
                st.warning(
                    f"Preview tronquée à {_fmt_bytes(MAX_PREVIEW_BYTES)} (fichier volumineux).",
                    icon="⚠️",
                )

            lang = _language_for(path)

            st.code(content, language=lang)

        except Exception as e:
            st.error(f"Erreur de lecture : {e}", icon="❌")

with right:
    render_doc_panel(choice, path)


### FILE: streamlit_app\ui\capture.py
from __future__ import annotations

from contextlib import redirect_stdout
from io import StringIO

def capture_stdout(fn, *args, **kwargs) -> tuple[object, str]:
    buf = StringIO()
    with redirect_stdout(buf):
        out = fn(*args, **kwargs)
    return out, buf.getvalue()


### FILE: streamlit_app\ui\code_docs.py
# streamlit_app/ui/code_docs.py
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Optional

import streamlit as st

# -----------------------------------------------------------------------------
# Objectif de ce module
# -----------------------------------------------------------------------------
# Ce fichier centralise la logique de "documentation manuelle" des fichiers du projet.
# L’idée : un JSON (docs_registry.json) contient, pour chaque fichier (relpath),
# une fiche courte (title / summary / usage / notes / tags).
#
# Cette brique est utilisée par :
# - Documentation (ou pages de navigation/preview)
# - Page Documentation
# - Toute page Streamlit qui veut afficher un panneau de doc à droite
# -----------------------------------------------------------------------------

# Racine du projet (à adapter si la structure change)
ROOT = Path(__file__).resolve().parents[2]

# Emplacement du registry (JSON) : stocké côté app, pas à la racine
REGISTRY_PATH = ROOT / "streamlit_app" / "data" / "docs_registry.json"


def load_docs_registry() -> Dict[str, Any]:
    """
    Charge le fichier docs_registry.json et le retourne sous forme de dict.

    - Clé : relpath du fichier (ex: "ir/pricers/hw1f_pricer.py")
    - Valeur : dict de métadonnées (title/tags/summary/usage/notes)

    Le chargement est mis en cache via st.cache_data car Streamlit rerun souvent.
    """

    @st.cache_data(show_spinner=False)
    def _load(p: str) -> Dict[str, Any]:
        """
        Fonction interne cachée (st.cache_data impose une fonction pure-ish).
        """
        path = Path(p)
        if not path.exists():
            # Si le registry n’existe pas, on retourne un dict vide (pas d’erreur bloquante)
            return {}

        try:
            obj = json.loads(path.read_text(encoding="utf-8"))
            # On impose un dict en sortie (sinon on ignore)
            return obj if isinstance(obj, dict) else {}
        except Exception:
            # JSON invalide / erreur de lecture : on évite de casser l’app
            return {}

    return _load(str(REGISTRY_PATH))


def manual_doc_for(relpath: str) -> Optional[Dict[str, Any]]:
    """
    Retourne la fiche de doc manuelle d’un fichier (si présente dans le registry).

    Parameters
    ----------
    relpath : str
        Chemin relatif du fichier (clé dans docs_registry.json).

    Returns
    -------
    dict | None
        dict si trouvé, sinon None.
    """
    reg = load_docs_registry()
    d = reg.get(relpath, None)
    if isinstance(d, dict):
        return d
    return None


def render_doc_panel(relpath: str, path: Path) -> None:
    """
    Affiche le panneau de documentation (côté UI).

    Notes
    -----
    - Ce panneau est volontairement "léger" : pas d’analyse AST, pas d’auto-doc ici.
      Il affiche uniquement ce que tu as écrit dans docs_registry.json.
    - `path` n’est pas utilisé pour le moment
    """
    st.subheader("Documentation")

    manual = manual_doc_for(relpath)

    # Cas où aucune fiche n’existe
    if manual is None:
        st.info(
            "Pas de fiche manuelle pour ce fichier. (Ajoute une entrée dans docs_registry.json)",
            icon="ℹ️",
        )
        return

    # Champs attendus 
    title = manual.get("title", relpath)
    tags = manual.get("tags", [])
    summary = manual.get("summary", "")
    usage = manual.get("usage", "")
    notes = manual.get("notes", "")

    # Rendu UI
    st.markdown(f"### {title}")

    if tags:
        # Affichage compact de tags en monospace
        st.caption(" • ".join([f"`{t}`" for t in tags]))

    if summary:
        st.markdown(summary)

    if usage:
        st.markdown("#### Usage")
        st.markdown(usage)

    if notes:
        st.markdown("#### Notes")
        st.markdown(notes)


### FILE: streamlit_app\ui\db.py
# streamlit_app/ui/db.py
from __future__ import annotations

import json
import sqlite3
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

import streamlit as st

# -----------------------------------------------------------------------------
# Objectif de ce module
# -----------------------------------------------------------------------------
# Ce fichier fournit une mini couche "persistence" via SQLite pour :
# - sauvegarder des runs (calibration HW1F/HW2F, PFE, artefacts, etc.)
# - relister / relire / supprimer des runs
# - sérialiser/désérialiser la courbe (Curve) afin de pouvoir reconstruire un run
#
# Points clés :
# - DB locale dans streamlit_app/data/irlab.db
# - list_runs est cache_data pour accélérer l’UI => on invalide le cache après écriture.
# -----------------------------------------------------------------------------

# Project root: .../streamlit_app/ui/db.py -> parents[2] = project root
ROOT = Path(__file__).resolve().parents[2]
DATA_DIR = ROOT / "streamlit_app" / "data"
DB_PATH = DATA_DIR / "irlab.db"


def _utc_now_iso() -> str:
    """Timestamp ISO en UTC (secondes) pour stocker un created_at stable."""
    return datetime.now(timezone.utc).isoformat(timespec="seconds")


def _connect() -> sqlite3.Connection:
    """
    Ouvre une connexion SQLite.
    """
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn


def _table_columns(conn: sqlite3.Connection, table: str) -> set[str]:
    """Retourne l’ensemble des colonnes d’une table (via PRAGMA table_info)."""
    cur = conn.cursor()
    cur.execute(f"PRAGMA table_info({table})")
    rows = cur.fetchall()
    return {str(r["name"]) for r in rows}


def init_db() -> None:
    """
    Initialise la base (idempotent) et applique des "soft migrations".

    - Crée la table runs si absente
    - Ajoute des colonnes manquantes si DB plus ancienne
    - Crée quelques index utiles pour l’UI
    """
    conn = _connect()
    cur = conn.cursor()

    # Table de base 
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS runs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at TEXT NOT NULL,
            label TEXT,
            model TEXT NOT NULL,                 -- "HW1F" / "HW2F"
            source_file TEXT,                    -- nom du xlsx uploadé (info)
            rmsre REAL,
            curve_json TEXT NOT NULL,            -- snapshot Curve sérialisé
            params_json TEXT NOT NULL,           -- paramètres modèle sérialisés
            artifacts_json TEXT,                 -- optionnel: PFE, etc.
            notes TEXT,                          -- optionnel: notes user
            meta_json TEXT                        -- optionnel: metadata extensible
        )
        """
    )

    cols = _table_columns(conn, "runs")

    def _add_col(name: str, ddl: str):
        if name not in cols:
            cur.execute(f"ALTER TABLE runs ADD COLUMN {ddl}")

    _add_col("label", "label TEXT")
    _add_col("artifacts_json", "artifacts_json TEXT")
    _add_col("notes", "notes TEXT")
    _add_col("meta_json", "meta_json TEXT")

    # Index (améliore la vitesse des listages/filtrages)
    cur.execute("CREATE INDEX IF NOT EXISTS idx_runs_created_at ON runs(created_at)")
    cur.execute("CREATE INDEX IF NOT EXISTS idx_runs_model ON runs(model)")
    conn.commit()
    conn.close()


# -------------------------
# Curve serialization helpers
# -------------------------

def curve_to_dict(curve) -> dict:
    """
    Snapshot minimal pour reconstruire ir.market.curve.Curve.

    Hypothèses:
    - curve.time : array-like de maturités (années)
    - curve.discount_factors : array-like de DF
    - curve.smooth : paramètre de lissage spline (optionnel)
    """
    return {
        "time": [float(x) for x in getattr(curve, "time")],
        "discount_factors": [float(x) for x in getattr(curve, "discount_factors")],
        "smooth": float(getattr(curve, "smooth", 1e-7)),
    }


def curve_from_dict(d: dict):
    """
    Reconstruit un objet Curve à partir du snapshot dict.
    Import local pour éviter les soucis d’import au démarrage Streamlit.
    """
    from ir.market.curve import Curve  

    time = d.get("time", None)
    disc = d.get("discount_factors", None)
    smooth = d.get("smooth", 1e-7)

    if time is None or disc is None:
        raise ValueError("Invalid curve snapshot: missing 'time' or 'discount_factors'.")

    return Curve(time, disc, smooth=float(smooth))


# -------------------------
# Cache helpers
# -------------------------

def _clear_runs_cache() -> None:
    """
    Invalidation du cache list_runs (Streamlit cache_data).
    """
    try:
        list_runs.clear()  # type: ignore[attr-defined]
    except Exception:
        # fallback global
        try:
            st.cache_data.clear()
        except Exception:
            pass


# -------------------------
# Runs API
# -------------------------

def save_run(
    *,
    model: str,
    curve_snapshot: dict,
    params: dict,
    source_file: Optional[str] = None,
    rmsre: Optional[float] = None,
    label: Optional[str] = None,
    artifacts: Optional[dict] = None,
    notes: Optional[str] = None,
    meta: Optional[dict] = None,
) -> int:
    """
    Insère un run en base et retourne son id.

    """
    model = str(model).strip()
    if model not in ("HW1F", "HW2F"):
        raise ValueError("Le modèle doit être be 'HW1F' ou 'HW2F'.")

    if curve_snapshot is None:
        raise ValueError(
            "curve_snapshot est requis (run une première calibration, ou assurer que last_curve_snapshot is validé)."
        )

    created_at = _utc_now_iso()

    # Sérialisation JSON "safe" (UTF-8)
    curve_json = json.dumps(curve_snapshot, ensure_ascii=False)
    params_json = json.dumps(params or {}, ensure_ascii=False)
    artifacts_json = json.dumps(artifacts or {}, ensure_ascii=False)
    notes_txt = "" if notes is None else str(notes)

    meta_out = dict(meta or {})
    if label is not None:
        meta_out.setdefault("label", str(label))
    if artifacts is not None:
        meta_out.setdefault("artifacts", artifacts)
    if notes is not None:
        meta_out.setdefault("notes", notes_txt)
    meta_json = json.dumps(meta_out, ensure_ascii=False)

    conn = _connect()
    cols = _table_columns(conn, "runs")
    cur = conn.cursor()

    ins_cols = ["created_at", "model", "source_file", "rmsre", "curve_json", "params_json"]
    ins_vals = [created_at, model, source_file, rmsre, curve_json, params_json]

    if "label" in cols:
        ins_cols.append("label")
        ins_vals.append(label)
    if "artifacts_json" in cols:
        ins_cols.append("artifacts_json")
        ins_vals.append(artifacts_json)
    if "notes" in cols:
        ins_cols.append("notes")
        ins_vals.append(notes_txt)
    if "meta_json" in cols:
        ins_cols.append("meta_json")
        ins_vals.append(meta_json)

    placeholders = ",".join(["?"] * len(ins_cols))
    colnames = ",".join(ins_cols)

    cur.execute(
        f"""
        INSERT INTO runs({colnames})
        VALUES ({placeholders})
        """,
        tuple(ins_vals),
    )
    conn.commit()
    run_id = int(cur.lastrowid)
    conn.close()

    _clear_runs_cache()
    return run_id


@st.cache_data(show_spinner=False)
def list_runs(limit: int = 200) -> list[dict]:
    """
    Liste les runs (ordre décroissant created_at) et retourne une liste de dicts.

    Important:
    - Cache Streamlit : accélère le rendu UI
    """
    conn = _connect()
    cur = conn.cursor()
    cur.execute(
        """
        SELECT *
        FROM runs
        ORDER BY created_at DESC
        LIMIT ?
        """,
        (int(limit),),
    )
    rows = cur.fetchall()
    conn.close()

    out: list[dict] = []
    for r in rows:
        meta = {}
        try:
            meta = json.loads(r["meta_json"]) if ("meta_json" in r.keys() and r["meta_json"]) else {}
        except Exception:
            meta = {}

        label = None
        if "label" in r.keys():
            label = r["label"]
        if not label:
            label = meta.get("label", None)

        artifacts = {}
        if "artifacts_json" in r.keys() and r["artifacts_json"]:
            try:
                artifacts = json.loads(r["artifacts_json"])
            except Exception:
                artifacts = {}
        else:
            artifacts = meta.get("artifacts", {}) or {}

        notes = ""
        if "notes" in r.keys() and r["notes"]:
            notes = str(r["notes"])
        else:
            notes = str(meta.get("notes", ""))

        out.append(
            {
                "id": int(r["id"]),
                "created_at": str(r["created_at"]),
                "label": label,
                "model": str(r["model"]),
                "source_file": r["source_file"],
                "rmsre": r["rmsre"],
                "curve": json.loads(r["curve_json"]) if r["curve_json"] else None,
                "params": json.loads(r["params_json"]) if r["params_json"] else {},
                "artifacts": artifacts,
                "notes": notes,
                "meta": meta,
            }
        )
    return out


def get_run(run_id: int) -> Optional[dict]:
    """
    Récupère un run par id (retourne le même format que list_runs, mais pour 1 seul).
    """
    conn = _connect()
    cur = conn.cursor()
    cur.execute("SELECT * FROM runs WHERE id = ?", (int(run_id),))
    r = cur.fetchone()
    conn.close()

    if r is None:
        return None

    meta = {}
    try:
        meta = json.loads(r["meta_json"]) if ("meta_json" in r.keys() and r["meta_json"]) else {}
    except Exception:
        meta = {}

    label = None
    if "label" in r.keys():
        label = r["label"]
    if not label:
        label = meta.get("label", None)

    artifacts = {}
    if "artifacts_json" in r.keys() and r["artifacts_json"]:
        try:
            artifacts = json.loads(r["artifacts_json"])
        except Exception:
            artifacts = {}
    else:
        artifacts = meta.get("artifacts", {}) or {}

    notes = ""
    if "notes" in r.keys() and r["notes"]:
        notes = str(r["notes"])
    else:
        notes = str(meta.get("notes", ""))

    return {
        "id": int(r["id"]),
        "created_at": str(r["created_at"]),
        "label": label,
        "model": str(r["model"]),
        "source_file": r["source_file"],
        "rmsre": r["rmsre"],
        "curve": json.loads(r["curve_json"]) if r["curve_json"] else None,
        "params": json.loads(r["params_json"]) if r["params_json"] else {},
        "artifacts": artifacts,
        "notes": notes,
        "meta": meta,
    }


def delete_run(run_id: int) -> bool:
    """
    Supprime un run par id.

    Returns
    -------
    bool
        True si au moins une ligne supprimée, False sinon.
    """
    conn = _connect()
    cur = conn.cursor()
    cur.execute("DELETE FROM runs WHERE id = ?", (int(run_id),))
    conn.commit()
    deleted = (cur.rowcount or 0) > 0
    conn.close()

    _clear_runs_cache()
    return deleted


def format_run_label(run: dict) -> str:
    """
    Formate une ligne "lisible" pour afficher un run dans un selectbox Streamlit.
    """
    rid = run.get("id", "?")
    ts = run.get("created_at", "")
    model = run.get("model", "?")
    src = run.get("source_file") or "unknown"
    label = run.get("label", None)
    rmsre = run.get("rmsre", None)

    head = f"#{rid} | {model} | {ts}"
    if label:
        head += f" | {label}"
    if rmsre is not None:
        head += f" | RMSRE={float(rmsre):.2e}"
    head += f" | {src}"
    return head


### FILE: streamlit_app\ui\io.py
from __future__ import annotations

import tempfile
from dataclasses import dataclass
from pathlib import Path

import streamlit as st

from ir.market.loaders_excel import (
    load_curve_xlsx,
    load_swaption_template_xlsx,
    load_caplet_template_xlsx,
)


# -----------------------------------------------------------------------------
# Objectif de ce module
# -----------------------------------------------------------------------------
# Ce fichier centralise le Streamlit pour :
# - récupérer un fichier .xlsx uploadé via st.file_uploader (objet en mémoire)
# - l’écrire en fichier temporaire sur disque (car pandas.read_excel attend un path)
# - appeler les loaders Excel "propres" (ir.market.loaders_excel) pour construire :
#     * Curve
#     * SwaptionQuoteSet
#     * CapletQuoteSet
#
# Points importants :
# - On cache l’écriture disque via st.cache_data pour éviter de réécrire le même upload
#   à chaque rerun Streamlit.
# - Le fichier temporaire est créé avec delete=False : il reste sur disque après fermeture.
# -----------------------------------------------------------------------------


@dataclass
class UploadedXlsx:
    """
    Petit conteneur "propre" pour tracer un upload sauvegardé en temporaire.

    Attributes
    ----------
    name : str
        Nom original du fichier uploadé (filename côté client).
    path : str
        Chemin local du fichier temporaire sur disque.
    """
    name: str
    path: str


@st.cache_data(show_spinner=False)
def _write_tmp_xlsx(file_bytes: bytes, filename: str) -> UploadedXlsx:
    """
    Écrit les bytes d’un fichier uploadé dans un fichier temporaire.

    """
    suffix = Path(filename).suffix if filename else ".xlsx"
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(file_bytes)
        tmp.flush()
        # On renvoie un objet "UploadedXlsx" avec le nom + le chemin du tmp
        return UploadedXlsx(name=filename, path=tmp.name)


def load_curve_and_swaption_from_upload(
    uploaded,
    *,
    curve_sheet: str = "Curve",
    template_sheet: str = "Template",
    smooth: float = 1e-7,
):
    """
    Chargement standard calibration swaptions :
    - écrire l’upload sur disque (tmp)
    - lire la courbe (sheet curve_sheet)
    - lire le template swaption (sheet template_sheet)

    Returns
    -------
    (source_name, curve, swpn)
        source_name : str (nom du fichier uploadé)
        curve : Curve
        swpn : SwaptionQuoteSet
    """
    file_bytes = uploaded.getvalue()
    tmp = _write_tmp_xlsx(file_bytes, uploaded.name)

    curve = load_curve_xlsx(tmp.path, sheet=curve_sheet, smooth=smooth)
    swpn = load_swaption_template_xlsx(tmp.path, sheet=template_sheet)
    return tmp.name, curve, swpn


def load_curve_only_from_upload(uploaded, *, curve_sheet: str = "Curve", smooth: float = 1e-7):
    """
    Chargement "curve only" :
    utile si une page a seulement besoin de la courbe (sans template swaption/caplet).

    Returns
    -------
    (source_name, curve)
    """
    file_bytes = uploaded.getvalue()
    tmp = _write_tmp_xlsx(file_bytes, uploaded.name)
    curve = load_curve_xlsx(tmp.path, sheet=curve_sheet, smooth=smooth)
    return tmp.name, curve


def load_caplet_template_from_upload(uploaded, *, sheet: str = "Template"):
    """
    Chargement d’un template caplets (calibration caps/caplets) depuis un upload.

    Returns
    -------
    (source_name, caplets)
        caplets : CapletQuoteSet
    """
    file_bytes = uploaded.getvalue()
    tmp = _write_tmp_xlsx(file_bytes, uploaded.name)
    caplets = load_caplet_template_xlsx(tmp.path, sheet=sheet)
    return tmp.name, caplets


### FILE: streamlit_app\ui\plotting.py
from __future__ import annotations

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter


# -----------------------------------------------------------------------------
# But du module
# -----------------------------------------------------------------------------
# Ce fichier regroupe des fonctions "fig_*" qui construisent des figures Matplotlib
# prêtes à être affichées dans Streamlit via:
#   st.pyplot(fig, clear_figure=True)
# -----------------------------------------------------------------------------


def _human_money(x, pos=None) -> str:
    """
    Formatte un nombre en "human readable" (k, M, B).

    Exemple:
      1200    -> "1.2k"
      1200000 -> "1.2M"
    """
    x = float(x)
    ax = abs(x)
    if ax >= 1e9:
        return f"{x/1e9:.1f}B"
    if ax >= 1e6:
        return f"{x/1e6:.1f}M"
    if ax >= 1e3:
        return f"{x/1e3:.1f}k"
    return f"{x:.0f}"


def fig_curve(curve, t_max: float = 30.0, n: int = 300, title_prefix: str = "Marché"):
    """
    Figure 2 panneaux pour visualiser :
      - la courbe d'actualisation P(0,t)
      - le forward instantané f(0,t)

    Paramètres
    ----------
    curve:
        Objet de type Curve (ou compatible) exposant:
          - discount(t)
          - inst_forward_rate(t)
    t_max:
        Horizon max en années (ex: 30y)
    n:
        Nombre de points sur la grille pour l'affichage
    title_prefix:
        Préfixe du titre (ex: "Marché", "Modèle", ...)

    Returns
    -------
    fig : matplotlib.figure.Figure
        La figure Matplotlib.
    """
    t = np.linspace(0.01, float(t_max), int(n))
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    # Panneau 1 : discount factors
    axes[0].plot(t, curve.discount(t), linewidth=2)
    axes[0].set_title(f"{title_prefix} Courbe d'actualisation", fontsize=13, fontweight="bold")
    axes[0].set_xlabel("Temps (Années)")
    axes[0].set_ylabel("Facteur d'actualisation")
    axes[0].grid(alpha=0.25)

    # Panneau 2 : forward instantané
    axes[1].plot(t, curve.inst_forward_rate(t), linewidth=2)
    axes[1].set_title(f"{title_prefix} Taux forward instantané", fontsize=13, fontweight="bold")
    axes[1].set_xlabel("Temps (Années)")
    axes[1].set_ylabel("Taux")
    axes[1].grid(alpha=0.25)

    plt.tight_layout()
    return fig


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


def _pro_axes_style(ax):
    ax.grid(True, alpha=0.18, linewidth=0.8)
    # alléger les bordures
    ax.spines["top"].set_alpha(0.25)
    ax.spines["right"].set_alpha(0.25)
    ax.spines["left"].set_alpha(0.35)
    ax.spines["bottom"].set_alpha(0.35)
    ax.tick_params(axis="both", labelsize=9)


def fig_prices_by_tenor(
    df: pd.DataFrame,
    *,
    tenors=(5.0, 10.0, 20.0, 30.0),
    tenor_col="Tenor",
    x_col="Expiry",
    mkt_col="Price",
    model_col="Model_Price",
    ylabel="Forward Premium",
    title="Courbe (Prix swaptions)",
    subtitle: str | None = None,
    show_error_band: bool = False,
):

    # --- layout
    n_panels = min(len(tenors), 4)
    if n_panels <= 0:
        raise ValueError("Doit contenir au moins deux tenors.")

    fig, axes = plt.subplots(
        2, 2,
        figsize=(12.5, 8.2),
        sharex=True,
        constrained_layout=False
    )
    axes = axes.flatten()

    handles_global = None
    labels_global = None

    for idx, tenor in enumerate(tenors):
        if idx >= len(axes):
            break

        ax = axes[idx]
        dft = df[df[tenor_col] == tenor].copy()
        if dft.empty:
            ax.set_axis_off()
            continue

        dft = dft.sort_values(x_col)

        x = dft[x_col].to_numpy(dtype=float)
        y_mkt = dft[mkt_col].to_numpy(dtype=float)
        y_mdl = dft[model_col].to_numpy(dtype=float)

        # Courbes (markers + traits plus nets)
        h1 = ax.plot(x, y_mkt, marker="o", markersize=4, linewidth=2.0, label="Marché")[0]
        h2 = ax.plot(x, y_mdl, marker="s", markersize=4, linewidth=2.0, linestyle="--", label="Modèle")[0]

        # Style axes
        _pro_axes_style(ax)

        # Titre panel
        ax.set_title(f"{int(tenor)}Y tenor", fontsize=11, fontweight="bold", pad=8)
        ax.set_ylabel(ylabel, fontsize=10)

        # Option: petit “résidu” (Model - Market)
        if show_error_band:
            # on crée un petit axe en-dessous du subplot principal
            from mpl_toolkits.axes_grid1.inset_locator import inset_axes

            ax_err = inset_axes(ax, width="100%", height="28%", loc="lower left",
                                bbox_to_anchor=(0, -0.38, 1, 1),
                                bbox_transform=ax.transAxes, borderpad=0)
            err = y_mdl - y_mkt
            ax_err.plot(x, err, linewidth=1.6, marker=".", markersize=4)
            ax_err.axhline(0.0, linewidth=1.0, alpha=0.5)
            ax_err.grid(True, alpha=0.15)
            ax_err.tick_params(axis="both", labelsize=8)
            ax_err.set_ylabel("Δ", fontsize=9)
            ax_err.set_xlabel("Maturité (années)", fontsize=9)

        # stocker handles pour légende globale (une seule fois)
        if handles_global is None:
            handles_global = [h1, h2]
            labels_global = ["Marché", "Modèle"]

    # masquer axes inutilisés si tenors < 4
    for j in range(n_panels, len(axes)):
        axes[j].set_axis_off()

    # Labels x sur la dernière ligne uniquement
    for ax in axes[-2:]:
        if ax.has_data():
            ax.set_xlabel("Maturité (années)", fontsize=10)

    # Titre global + sous-titre
    fig.suptitle(title, fontsize=14, fontweight="bold", y=0.98)
    if subtitle:
        fig.text(0.5, 0.955, subtitle, ha="center", va="top", fontsize=10, alpha=0.85)

    # Légende globale en haut à droite
    if handles_global is not None:
        fig.legend(handles_global, labels_global, loc="upper right", frameon=True, fontsize=10)

    fig.tight_layout(rect=[0, 0, 1, 0.94])
    return fig


def fig_vols_by_tenor(
    df: pd.DataFrame,
    *,
    tenors=(5.0, 10.0, 20.0, 30.0),
    tenor_col="Tenor",
    x_col="Expiry",
    mkt_col="Market_Vol (Bps)",
    model_col="Model_Vol (Bps)",
    ylabel="Volatilité (Bps)",
    title="Courbe (Vol swaptions)",
    subtitle: str | None = None,
    show_error_band: bool = False,
):

    n_panels = min(len(tenors), 4)
    if n_panels <= 0:
        raise ValueError("Doit contenir au moins deux tenors.")

    fig, axes = plt.subplots(
        2, 2,
        figsize=(12.5, 8.2),
        sharex=True,
        constrained_layout=False
    )
    axes = axes.flatten()

    handles_global = None
    labels_global = None

    for idx, tenor in enumerate(tenors):
        if idx >= len(axes):
            break

        ax = axes[idx]
        dft = df[df[tenor_col] == tenor].copy()
        if dft.empty:
            ax.set_axis_off()
            continue

        dft = dft.sort_values(x_col)

        x = dft[x_col].to_numpy(dtype=float)
        y_mkt = dft[mkt_col].to_numpy(dtype=float)
        y_mdl = dft[model_col].to_numpy(dtype=float)

        h1 = ax.plot(x, y_mkt, marker="o", markersize=4, linewidth=2.0, label="Marché")[0]
        h2 = ax.plot(x, y_mdl, marker="s", markersize=4, linewidth=2.0, linestyle="--", label="Modèle")[0]

        _pro_axes_style(ax)

        ax.set_title(f"{int(tenor)}Y tenor", fontsize=11, fontweight="bold", pad=8)
        ax.set_ylabel(ylabel, fontsize=10)

        if show_error_band:
            from mpl_toolkits.axes_grid1.inset_locator import inset_axes

            ax_err = inset_axes(ax, width="100%", height="28%", loc="lower left",
                                bbox_to_anchor=(0, -0.38, 1, 1),
                                bbox_transform=ax.transAxes, borderpad=0)
            err = y_mdl - y_mkt
            ax_err.plot(x, err, linewidth=1.6, marker=".", markersize=4)
            ax_err.axhline(0.0, linewidth=1.0, alpha=0.5)
            ax_err.grid(True, alpha=0.15)
            ax_err.tick_params(axis="both", labelsize=8)
            ax_err.set_ylabel("Δ", fontsize=9)
            ax_err.set_xlabel("Maturité (années)", fontsize=9)

        if handles_global is None:
            handles_global = [h1, h2]
            labels_global = ["Marché", "Modèle"]

    for j in range(n_panels, len(axes)):
        axes[j].set_axis_off()

    for ax in axes[-2:]:
        if ax.has_data():
            ax.set_xlabel("Maturité (années)", fontsize=10)

    fig.suptitle(title, fontsize=14, fontweight="bold", y=0.98)
    if subtitle:
        fig.text(0.5, 0.955, subtitle, ha="center", va="top", fontsize=10, alpha=0.85)

    if handles_global is not None:
        fig.legend(handles_global, labels_global, loc="upper right", frameon=True, fontsize=10)

    fig.tight_layout(rect=[0, 0, 1, 0.94])
    return fig


def fig_pfe(grid, pfe, epe=None, q: float = 0.95, title: str = "Profil PFE", subtitle: str | None = None):
    """
    Figure PFE/EPE.

    Paramètres
    ----------
    grid:
        Grille temps (années).
    pfe:
        Série PFE (même longueur que grid).
    epe:
        Série EPE (optionnelle).
    q:
        Quantile affiché dans la légende (ex 0.95).
    title / subtitle:
        Titres affichés sur la figure.

    Returns
    -------
    fig : matplotlib.figure.Figure
    """
    grid = np.asarray(grid, dtype=float)
    pfe = np.asarray(pfe, dtype=float)
    epe = None if epe is None else np.asarray(epe, dtype=float)

    fig, ax = plt.subplots(figsize=(11, 5.5))

    # Courbe PFE + zone remplie (visuel "propre")
    ax.plot(grid, pfe, marker="o", markersize=3.5, linewidth=2.0, label=f"PFE ({int(q*100)}%)")
    ax.fill_between(grid, 0.0, pfe, alpha=0.12)

    # Courbe EPE (optionnelle)
    if epe is not None:
        ax.plot(grid, epe, marker="s", markersize=3.2, linewidth=1.8, linestyle="--", label="EPE")

    ax.set_title(title, fontsize=14, fontweight="bold", pad=10)
    if subtitle:
        ax.text(0.0, 1.02, subtitle, transform=ax.transAxes, fontsize=10, alpha=0.9, va="bottom")

    ax.set_xlabel("Temps (Années)")
    ax.set_ylabel("Exposure")
    ax.yaxis.set_major_formatter(FuncFormatter(_human_money))

    ax.grid(alpha=0.25)
    ax.set_xlim(grid.min(), grid.max())
    ax.set_ylim(bottom=0.0)
    ax.legend(loc="upper right")

    plt.tight_layout()
    return fig


### FILE: streamlit_app\ui\__init__.py


